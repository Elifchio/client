{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3dbf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dff50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data/merged_df.csv')\n",
    "# for for this quick test ill drop nans but this shouldnt be here after succesfull data prep\n",
    "df = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "923bac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SIGNAL TEST RESULTS ===\n",
      "AUC-ROC Score: 0.749\n",
      "✅ GOOD NEWS: Your features contain useful signal!\n",
      "We can proceed with imbalance fixing strategies.\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "\n",
    "target_column = 'netcontractsigned'\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler() # important for logistic regressor\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a simple logistic regression (NO imbalance handling yet)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Check if there's any signal\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\n=== SIGNAL TEST RESULTS ===\")\n",
    "print(f\"AUC-ROC Score: {auc_score:.3f}\")\n",
    "if auc_score > 0.5:\n",
    "    print(\"✅ GOOD NEWS: Your features contain useful signal!\")\n",
    "    print(\"We can proceed with imbalance fixing strategies.\")\n",
    "else:\n",
    "    print(\"❌ BAD NEWS: No signal detected. Features need work first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25cc718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DETAILED SIGNAL ANALYSIS ===\n",
      "AUC-ROC: 0.749\n",
      "AUC-PR: 0.149\n",
      "Random baseline AUC-PR: 0.042\n",
      "Improvement over random: 3.5x\n",
      "\n",
      "With 0.5 threshold:\n",
      "Predicted positives: 3\n",
      "Actual positives: 66.0\n",
      "\n",
      "Top 10% analysis:\n",
      "Threshold for top 10%: 0.092\n",
      "Conversion rate in top 10%: 0.154\n",
      "That's 3.6x better than average!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate AUC-PR (more reliable for imbalanced data)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Random baseline for comparison\n",
    "random_baseline = y_test.mean()  # 0.023\n",
    "\n",
    "print(\"\\n=== DETAILED SIGNAL ANALYSIS ===\")\n",
    "print(f\"AUC-ROC: {auc_score:.3f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "print(f\"Random baseline AUC-PR: {random_baseline:.3f}\")\n",
    "print(f\"Improvement over random: {auc_pr/random_baseline:.1f}x\")\n",
    "\n",
    "# Look at actual predictions with default 0.5 threshold\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "print(f\"\\nWith 0.5 threshold:\")\n",
    "print(f\"Predicted positives: {y_pred.sum()}\")\n",
    "print(f\"Actual positives: {y_test.sum()}\")\n",
    "\n",
    "# Check top 10% of predictions\n",
    "top_10_percent_threshold = np.percentile(y_pred_proba, 90)\n",
    "print(f\"\\nTop 10% analysis:\")\n",
    "print(f\"Threshold for top 10%: {top_10_percent_threshold:.3f}\")\n",
    "top_10_mask = y_pred_proba >= top_10_percent_threshold\n",
    "print(f\"Conversion rate in top 10%: {y_test[top_10_mask].mean():.3f}\")\n",
    "print(f\"That's {y_test[top_10_mask].mean()/y_test.mean():.1f}x better than average!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f758cb4",
   "metadata": {},
   "source": [
    "#### First Strategy\n",
    "\n",
    "Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b7e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTING CLASS WEIGHTS ===\n",
      "Calculated positive class weight: 22.4\n",
      "\n",
      "Class Weights Results:\n",
      "AUC-ROC: 0.742\n",
      "AUC-PR: 0.136\n",
      "Improvement over baseline: 0.91x\n",
      "At 0.1 threshold: 1457 predicted positive, 0.045 precision\n",
      "At 0.2 threshold: 1233 predicted positive, 0.052 precision\n",
      "At 0.3 threshold: 1000 predicted positive, 0.056 precision\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test class weights with your strong signal\n",
    "print(\"\\n=== TESTING CLASS WEIGHTS ===\")\n",
    "\n",
    "# Calculate balanced class weight\n",
    "pos_weight = (1 - y_train.mean()) / y_train.mean()  # About 42 for your data\n",
    "print(f\"Calculated positive class weight: {pos_weight:.1f}\")\n",
    "\n",
    "# Train with class weights\n",
    "lr_weighted = LogisticRegression(\n",
    "    class_weight={0: 1, 1: pos_weight},\n",
    "    random_state=42, \n",
    "    max_iter=1000\n",
    ")\n",
    "lr_weighted.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_weighted = lr_weighted.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "precision_w, recall_w, _ = precision_recall_curve(y_test, y_pred_weighted)\n",
    "auc_pr_weighted = auc(recall_w, precision_w)\n",
    "auc_roc_weighted = roc_auc_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(f\"\\nClass Weights Results:\")\n",
    "print(f\"AUC-ROC: {auc_roc_weighted:.3f}\")\n",
    "print(f\"AUC-PR: {auc_pr_weighted:.3f}\")\n",
    "print(f\"Improvement over baseline: {auc_pr_weighted/auc_pr:.2f}x\")\n",
    "\n",
    "# Check different thresholds\n",
    "for thresh in [0.1, 0.2, 0.3]:\n",
    "    pred_at_thresh = (y_pred_weighted >= thresh).astype(int)\n",
    "    if pred_at_thresh.sum() > 0:\n",
    "        precision_at_thresh = (y_test[pred_at_thresh == 1]).mean()\n",
    "        print(f\"At {thresh} threshold: {pred_at_thresh.sum()} predicted positive, {precision_at_thresh:.3f} precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f549f2",
   "metadata": {},
   "source": [
    "Class weights actually made things slightly worse (AUC-PR dropped from 0.174 to 0.158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea0c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== THRESHOLD OPTIMIZATION ===\n",
      "Using original model (no class weights)\n",
      "Threshold 0.01: 1305 flagged (83.9%), Precision 0.050, Recall 0.985, F1 0.095\n",
      "Threshold 0.02: 1017 flagged (65.4%), Precision 0.055, Recall 0.848, F1 0.103\n",
      "Threshold 0.03:  751 flagged (48.3%), Precision 0.071, Recall 0.803, F1 0.130\n",
      "Threshold 0.04:  554 flagged (35.6%), Precision 0.088, Recall 0.742, F1 0.158\n",
      "Threshold 0.05:  431 flagged (27.7%), Precision 0.107, Recall 0.697, F1 0.185\n",
      "Threshold 0.06:  329 flagged (21.1%), Precision 0.109, Recall 0.545, F1 0.182\n",
      "Threshold 0.07:  246 flagged (15.8%), Precision 0.126, Recall 0.470, F1 0.199\n",
      "Threshold 0.08:  189 flagged (12.1%), Precision 0.138, Recall 0.394, F1 0.204\n",
      "Threshold 0.09:  158 flagged (10.2%), Precision 0.152, Recall 0.364, F1 0.214\n",
      "Threshold 0.10:  142 flagged ( 9.1%), Precision 0.169, Recall 0.364, F1 0.231\n"
     ]
    }
   ],
   "source": [
    "# checking the difference thresholds make\n",
    "\n",
    "# Use the original (better) model predictions\n",
    "print(\"=== THRESHOLD OPTIMIZATION ===\")\n",
    "print(\"Using original model (no class weights)\")\n",
    "\n",
    "# Try many different thresholds\n",
    "thresholds = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    pred_at_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    \n",
    "    if pred_at_thresh.sum() > 0:\n",
    "        precision = (y_test[pred_at_thresh == 1]).mean()\n",
    "        recall = (y_test * pred_at_thresh).sum() / y_test.sum()\n",
    "        \n",
    "        if precision > 0 and recall > 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "            \n",
    "        results.append({\n",
    "            'threshold': thresh,\n",
    "            'predicted_positive': pred_at_thresh.sum(),\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'percent_flagged': pred_at_thresh.sum() / len(y_test) * 100\n",
    "        })\n",
    "\n",
    "# Show results\n",
    "for r in results:\n",
    "    print(f\"Threshold {r['threshold']:.2f}: {r['predicted_positive']:4d} flagged ({r['percent_flagged']:4.1f}%), \"\n",
    "          f\"Precision {r['precision']:.3f}, Recall {r['recall']:.3f}, F1 {r['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594fb36a",
   "metadata": {},
   "source": [
    "#### Second Strategy\n",
    "\n",
    "Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e38d4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        ce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        alpha_t = y_true * self.alpha + (1 - y_true) * (1 - self.alpha)\n",
    "        focal_loss = alpha_t * tf.pow((1 - p_t), self.gamma) * ce_loss\n",
    "        return tf.reduce_mean(focal_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce4819",
   "metadata": {},
   "source": [
    "#### Third Strategy\n",
    "\n",
    "Smoteen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e261b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE-ENN: (6223, 40), {0.0: 5957, 1.0: 266}\n",
      "After SMOTE-ENN: (11705, 40), {0.0: 5957, 1.0: 5748}\n",
      "\n",
      "Positive samples: 266.0 → 5748.0 (added 5482.0)\n",
      "Negative samples: 5957.0 → 5957.0 (removed 0.0)\n",
      "\n",
      "==================================================\n",
      "TRAINING MODEL WITH SMOTE-ENN\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - AUC: 0.7606 - accuracy: 0.7158 - loss: 0.5542 - precision: 0.6535 - recall: 0.4661 - val_AUC: 0.0000e+00 - val_accuracy: 0.6455 - val_loss: 0.6254 - val_precision: 1.0000 - val_recall: 0.6455 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.8339 - accuracy: 0.7599 - loss: 0.4789 - precision: 0.7066 - recall: 0.5817 - val_AUC: 0.0000e+00 - val_accuracy: 0.6288 - val_loss: 0.6412 - val_precision: 1.0000 - val_recall: 0.6288 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - AUC: 0.8569 - accuracy: 0.7769 - loss: 0.4485 - precision: 0.7127 - recall: 0.6481 - val_AUC: 0.0000e+00 - val_accuracy: 0.6215 - val_loss: 0.6309 - val_precision: 1.0000 - val_recall: 0.6215 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.8762 - accuracy: 0.7949 - loss: 0.4201 - precision: 0.7299 - recall: 0.6924 - val_AUC: 0.0000e+00 - val_accuracy: 0.7612 - val_loss: 0.5197 - val_precision: 1.0000 - val_recall: 0.7612 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.8901 - accuracy: 0.8110 - loss: 0.3970 - precision: 0.7397 - recall: 0.7414 - val_AUC: 0.0000e+00 - val_accuracy: 0.7856 - val_loss: 0.5197 - val_precision: 1.0000 - val_recall: 0.7856 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9020 - accuracy: 0.8198 - loss: 0.3760 - precision: 0.7432 - recall: 0.7714 - val_AUC: 0.0000e+00 - val_accuracy: 0.8689 - val_loss: 0.4252 - val_precision: 1.0000 - val_recall: 0.8689 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9066 - accuracy: 0.8248 - loss: 0.3675 - precision: 0.7461 - recall: 0.7857 - val_AUC: 0.0000e+00 - val_accuracy: 0.8817 - val_loss: 0.4307 - val_precision: 1.0000 - val_recall: 0.8817 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9141 - accuracy: 0.8344 - loss: 0.3532 - precision: 0.7579 - recall: 0.8004 - val_AUC: 0.0000e+00 - val_accuracy: 0.8684 - val_loss: 0.4202 - val_precision: 1.0000 - val_recall: 0.8684 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9188 - accuracy: 0.8375 - loss: 0.3443 - precision: 0.7623 - recall: 0.8039 - val_AUC: 0.0000e+00 - val_accuracy: 0.9090 - val_loss: 0.3868 - val_precision: 1.0000 - val_recall: 0.9090 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9247 - accuracy: 0.8482 - loss: 0.3328 - precision: 0.7709 - recall: 0.8295 - val_AUC: 0.0000e+00 - val_accuracy: 0.9274 - val_loss: 0.3602 - val_precision: 1.0000 - val_recall: 0.9274 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9309 - accuracy: 0.8541 - loss: 0.3176 - precision: 0.7769 - recall: 0.8403 - val_AUC: 0.0000e+00 - val_accuracy: 0.9077 - val_loss: 0.3592 - val_precision: 1.0000 - val_recall: 0.9077 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9345 - accuracy: 0.8569 - loss: 0.3107 - precision: 0.7826 - recall: 0.8400 - val_AUC: 0.0000e+00 - val_accuracy: 0.9381 - val_loss: 0.2816 - val_precision: 1.0000 - val_recall: 0.9381 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9396 - accuracy: 0.8627 - loss: 0.2971 - precision: 0.7878 - recall: 0.8521 - val_AUC: 0.0000e+00 - val_accuracy: 0.9402 - val_loss: 0.2991 - val_precision: 1.0000 - val_recall: 0.9402 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9421 - accuracy: 0.8688 - loss: 0.2927 - precision: 0.7966 - recall: 0.8585 - val_AUC: 0.0000e+00 - val_accuracy: 0.9389 - val_loss: 0.2810 - val_precision: 1.0000 - val_recall: 0.9389 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9459 - accuracy: 0.8716 - loss: 0.2825 - precision: 0.8007 - recall: 0.8618 - val_AUC: 0.0000e+00 - val_accuracy: 0.9487 - val_loss: 0.2557 - val_precision: 1.0000 - val_recall: 0.9487 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.9491 - accuracy: 0.8774 - loss: 0.2741 - precision: 0.8109 - recall: 0.8647 - val_AUC: 0.0000e+00 - val_accuracy: 0.9483 - val_loss: 0.2533 - val_precision: 1.0000 - val_recall: 0.9483 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9519 - accuracy: 0.8805 - loss: 0.2665 - precision: 0.8143 - recall: 0.8700 - val_AUC: 0.0000e+00 - val_accuracy: 0.9551 - val_loss: 0.2515 - val_precision: 1.0000 - val_recall: 0.9551 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9525 - accuracy: 0.8811 - loss: 0.2661 - precision: 0.8163 - recall: 0.8688 - val_AUC: 0.0000e+00 - val_accuracy: 0.9633 - val_loss: 0.2205 - val_precision: 1.0000 - val_recall: 0.9633 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9543 - accuracy: 0.8846 - loss: 0.2598 - precision: 0.8176 - recall: 0.8788 - val_AUC: 0.0000e+00 - val_accuracy: 0.9415 - val_loss: 0.2665 - val_precision: 1.0000 - val_recall: 0.9415 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9571 - accuracy: 0.8887 - loss: 0.2510 - precision: 0.8273 - recall: 0.8773 - val_AUC: 0.0000e+00 - val_accuracy: 0.9398 - val_loss: 0.2484 - val_precision: 1.0000 - val_recall: 0.9398 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9618 - accuracy: 0.8934 - loss: 0.2372 - precision: 0.8306 - recall: 0.8882 - val_AUC: 0.0000e+00 - val_accuracy: 0.9346 - val_loss: 0.2515 - val_precision: 1.0000 - val_recall: 0.9346 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9587 - accuracy: 0.8874 - loss: 0.2483 - precision: 0.8186 - recall: 0.8873 - val_AUC: 0.0000e+00 - val_accuracy: 0.9628 - val_loss: 0.2186 - val_precision: 1.0000 - val_recall: 0.9628 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9624 - accuracy: 0.8957 - loss: 0.2354 - precision: 0.8355 - recall: 0.8882 - val_AUC: 0.0000e+00 - val_accuracy: 0.9509 - val_loss: 0.2090 - val_precision: 1.0000 - val_recall: 0.9509 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9631 - accuracy: 0.8942 - loss: 0.2335 - precision: 0.8319 - recall: 0.8888 - val_AUC: 0.0000e+00 - val_accuracy: 0.9569 - val_loss: 0.2047 - val_precision: 1.0000 - val_recall: 0.9569 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9630 - accuracy: 0.8991 - loss: 0.2336 - precision: 0.8389 - recall: 0.8943 - val_AUC: 0.0000e+00 - val_accuracy: 0.9539 - val_loss: 0.2243 - val_precision: 1.0000 - val_recall: 0.9539 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9651 - accuracy: 0.9053 - loss: 0.2264 - precision: 0.8486 - recall: 0.9002 - val_AUC: 0.0000e+00 - val_accuracy: 0.9607 - val_loss: 0.1952 - val_precision: 1.0000 - val_recall: 0.9607 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9659 - accuracy: 0.9031 - loss: 0.2241 - precision: 0.8468 - recall: 0.8958 - val_AUC: 0.0000e+00 - val_accuracy: 0.9517 - val_loss: 0.2009 - val_precision: 1.0000 - val_recall: 0.9517 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9676 - accuracy: 0.9075 - loss: 0.2180 - precision: 0.8507 - recall: 0.9046 - val_AUC: 0.0000e+00 - val_accuracy: 0.9577 - val_loss: 0.1867 - val_precision: 1.0000 - val_recall: 0.9577 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9687 - accuracy: 0.9062 - loss: 0.2144 - precision: 0.8494 - recall: 0.9023 - val_AUC: 0.0000e+00 - val_accuracy: 0.9411 - val_loss: 0.2236 - val_precision: 1.0000 - val_recall: 0.9411 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9708 - accuracy: 0.9108 - loss: 0.2069 - precision: 0.8578 - recall: 0.9049 - val_AUC: 0.0000e+00 - val_accuracy: 0.9697 - val_loss: 0.1491 - val_precision: 1.0000 - val_recall: 0.9697 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9701 - accuracy: 0.9101 - loss: 0.2093 - precision: 0.8494 - recall: 0.9152 - val_AUC: 0.0000e+00 - val_accuracy: 0.9692 - val_loss: 0.1517 - val_precision: 1.0000 - val_recall: 0.9692 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9703 - accuracy: 0.9139 - loss: 0.2076 - precision: 0.8618 - recall: 0.9093 - val_AUC: 0.0000e+00 - val_accuracy: 0.9556 - val_loss: 0.1763 - val_precision: 1.0000 - val_recall: 0.9556 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9716 - accuracy: 0.9118 - loss: 0.2031 - precision: 0.8570 - recall: 0.9093 - val_AUC: 0.0000e+00 - val_accuracy: 0.9671 - val_loss: 0.1577 - val_precision: 1.0000 - val_recall: 0.9671 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9708 - accuracy: 0.9119 - loss: 0.2064 - precision: 0.8537 - recall: 0.9146 - val_AUC: 0.0000e+00 - val_accuracy: 0.9868 - val_loss: 0.1390 - val_precision: 1.0000 - val_recall: 0.9868 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9728 - accuracy: 0.9141 - loss: 0.1993 - precision: 0.8569 - recall: 0.9172 - val_AUC: 0.0000e+00 - val_accuracy: 0.9735 - val_loss: 0.1760 - val_precision: 1.0000 - val_recall: 0.9735 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9740 - accuracy: 0.9181 - loss: 0.1947 - precision: 0.8648 - recall: 0.9184 - val_AUC: 0.0000e+00 - val_accuracy: 0.9842 - val_loss: 0.1406 - val_precision: 1.0000 - val_recall: 0.9842 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9752 - accuracy: 0.9203 - loss: 0.1889 - precision: 0.8699 - recall: 0.9184 - val_AUC: 0.0000e+00 - val_accuracy: 0.9769 - val_loss: 0.1430 - val_precision: 1.0000 - val_recall: 0.9769 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9746 - accuracy: 0.9163 - loss: 0.1927 - precision: 0.8622 - recall: 0.9163 - val_AUC: 0.0000e+00 - val_accuracy: 0.9833 - val_loss: 0.1351 - val_precision: 1.0000 - val_recall: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9761 - accuracy: 0.9207 - loss: 0.1884 - precision: 0.8708 - recall: 0.9181 - val_AUC: 0.0000e+00 - val_accuracy: 0.9838 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9838 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9743 - accuracy: 0.9186 - loss: 0.1947 - precision: 0.8675 - recall: 0.9163 - val_AUC: 0.0000e+00 - val_accuracy: 0.9645 - val_loss: 0.1558 - val_precision: 1.0000 - val_recall: 0.9645 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9746 - accuracy: 0.9201 - loss: 0.1910 - precision: 0.8668 - recall: 0.9222 - val_AUC: 0.0000e+00 - val_accuracy: 0.9906 - val_loss: 0.1160 - val_precision: 1.0000 - val_recall: 0.9906 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9760 - accuracy: 0.9191 - loss: 0.1854 - precision: 0.8674 - recall: 0.9178 - val_AUC: 0.0000e+00 - val_accuracy: 0.9804 - val_loss: 0.1337 - val_precision: 1.0000 - val_recall: 0.9804 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9771 - accuracy: 0.9252 - loss: 0.1816 - precision: 0.8750 - recall: 0.9269 - val_AUC: 0.0000e+00 - val_accuracy: 0.9812 - val_loss: 0.1129 - val_precision: 1.0000 - val_recall: 0.9812 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9754 - accuracy: 0.9193 - loss: 0.1874 - precision: 0.8644 - recall: 0.9228 - val_AUC: 0.0000e+00 - val_accuracy: 0.9825 - val_loss: 0.1351 - val_precision: 1.0000 - val_recall: 0.9825 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9768 - accuracy: 0.9282 - loss: 0.1829 - precision: 0.8795 - recall: 0.9301 - val_AUC: 0.0000e+00 - val_accuracy: 0.9846 - val_loss: 0.1120 - val_precision: 1.0000 - val_recall: 0.9846 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9789 - accuracy: 0.9266 - loss: 0.1746 - precision: 0.8767 - recall: 0.9290 - val_AUC: 0.0000e+00 - val_accuracy: 0.9765 - val_loss: 0.1309 - val_precision: 1.0000 - val_recall: 0.9765 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9768 - accuracy: 0.9218 - loss: 0.1836 - precision: 0.8663 - recall: 0.9284 - val_AUC: 0.0000e+00 - val_accuracy: 0.9782 - val_loss: 0.1270 - val_precision: 1.0000 - val_recall: 0.9782 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9795 - accuracy: 0.9288 - loss: 0.1724 - precision: 0.8835 - recall: 0.9263 - val_AUC: 0.0000e+00 - val_accuracy: 0.9808 - val_loss: 0.1258 - val_precision: 1.0000 - val_recall: 0.9808 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9794 - accuracy: 0.9295 - loss: 0.1729 - precision: 0.8814 - recall: 0.9316 - val_AUC: 0.0000e+00 - val_accuracy: 0.9846 - val_loss: 0.1127 - val_precision: 1.0000 - val_recall: 0.9846 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9796 - accuracy: 0.9223 - loss: 0.1726 - precision: 0.8709 - recall: 0.9231 - val_AUC: 0.0000e+00 - val_accuracy: 0.9838 - val_loss: 0.1179 - val_precision: 1.0000 - val_recall: 0.9838 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9770 - accuracy: 0.9255 - loss: 0.1804 - precision: 0.8741 - recall: 0.9290 - val_AUC: 0.0000e+00 - val_accuracy: 0.9821 - val_loss: 0.1265 - val_precision: 1.0000 - val_recall: 0.9821 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9801 - accuracy: 0.9314 - loss: 0.1694 - precision: 0.8814 - recall: 0.9378 - val_AUC: 0.0000e+00 - val_accuracy: 0.9671 - val_loss: 0.1564 - val_precision: 1.0000 - val_recall: 0.9671 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9815 - accuracy: 0.9317 - loss: 0.1634 - precision: 0.8851 - recall: 0.9334 - val_AUC: 0.0000e+00 - val_accuracy: 0.9838 - val_loss: 0.1156 - val_precision: 1.0000 - val_recall: 0.9838 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9798 - accuracy: 0.9324 - loss: 0.1694 - precision: 0.8874 - recall: 0.9325 - val_AUC: 0.0000e+00 - val_accuracy: 0.9774 - val_loss: 0.1218 - val_precision: 1.0000 - val_recall: 0.9774 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m288/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9790 - accuracy: 0.9286 - loss: 0.1734 - precision: 0.8791 - recall: 0.9301\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9803 - accuracy: 0.9308 - loss: 0.1682 - precision: 0.8835 - recall: 0.9328 - val_AUC: 0.0000e+00 - val_accuracy: 0.9778 - val_loss: 0.1252 - val_precision: 1.0000 - val_recall: 0.9778 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9826 - accuracy: 0.9350 - loss: 0.1582 - precision: 0.8923 - recall: 0.9340 - val_AUC: 0.0000e+00 - val_accuracy: 0.9902 - val_loss: 0.0999 - val_precision: 1.0000 - val_recall: 0.9902 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9836 - accuracy: 0.9374 - loss: 0.1539 - precision: 0.8924 - recall: 0.9416 - val_AUC: 0.0000e+00 - val_accuracy: 0.9816 - val_loss: 0.1064 - val_precision: 1.0000 - val_recall: 0.9816 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9841 - accuracy: 0.9398 - loss: 0.1508 - precision: 0.8999 - recall: 0.9389 - val_AUC: 0.0000e+00 - val_accuracy: 0.9838 - val_loss: 0.1061 - val_precision: 1.0000 - val_recall: 0.9838 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9855 - accuracy: 0.9427 - loss: 0.1425 - precision: 0.9024 - recall: 0.9445 - val_AUC: 0.0000e+00 - val_accuracy: 0.9752 - val_loss: 0.1150 - val_precision: 1.0000 - val_recall: 0.9752 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - AUC: 0.9858 - accuracy: 0.9425 - loss: 0.1424 - precision: 0.9065 - recall: 0.9389 - val_AUC: 0.0000e+00 - val_accuracy: 0.9872 - val_loss: 0.0867 - val_precision: 1.0000 - val_recall: 0.9872 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9857 - accuracy: 0.9438 - loss: 0.1419 - precision: 0.9034 - recall: 0.9469 - val_AUC: 0.0000e+00 - val_accuracy: 0.9897 - val_loss: 0.0887 - val_precision: 1.0000 - val_recall: 0.9897 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9866 - accuracy: 0.9411 - loss: 0.1389 - precision: 0.9015 - recall: 0.9407 - val_AUC: 0.0000e+00 - val_accuracy: 0.9889 - val_loss: 0.0886 - val_precision: 1.0000 - val_recall: 0.9889 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9862 - accuracy: 0.9433 - loss: 0.1395 - precision: 0.9064 - recall: 0.9413 - val_AUC: 0.0000e+00 - val_accuracy: 0.9880 - val_loss: 0.0870 - val_precision: 1.0000 - val_recall: 0.9880 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9865 - accuracy: 0.9433 - loss: 0.1387 - precision: 0.9037 - recall: 0.9448 - val_AUC: 0.0000e+00 - val_accuracy: 0.9876 - val_loss: 0.0902 - val_precision: 1.0000 - val_recall: 0.9876 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9867 - accuracy: 0.9421 - loss: 0.1394 - precision: 0.9055 - recall: 0.9389 - val_AUC: 0.0000e+00 - val_accuracy: 0.9838 - val_loss: 0.0961 - val_precision: 1.0000 - val_recall: 0.9838 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9861 - accuracy: 0.9429 - loss: 0.1409 - precision: 0.9045 - recall: 0.9425 - val_AUC: 0.0000e+00 - val_accuracy: 0.9842 - val_loss: 0.1042 - val_precision: 1.0000 - val_recall: 0.9842 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9866 - accuracy: 0.9452 - loss: 0.1378 - precision: 0.9060 - recall: 0.9478 - val_AUC: 0.0000e+00 - val_accuracy: 0.9902 - val_loss: 0.0834 - val_precision: 1.0000 - val_recall: 0.9902 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9873 - accuracy: 0.9472 - loss: 0.1339 - precision: 0.9081 - recall: 0.9513 - val_AUC: 0.0000e+00 - val_accuracy: 0.9897 - val_loss: 0.0857 - val_precision: 1.0000 - val_recall: 0.9897 - learning_rate: 5.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9870 - accuracy: 0.9475 - loss: 0.1353 - precision: 0.9100 - recall: 0.9495 - val_AUC: 0.0000e+00 - val_accuracy: 0.9846 - val_loss: 0.0981 - val_precision: 1.0000 - val_recall: 0.9846 - learning_rate: 5.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9873 - accuracy: 0.9462 - loss: 0.1331 - precision: 0.9092 - recall: 0.9466 - val_AUC: 0.0000e+00 - val_accuracy: 0.9885 - val_loss: 0.0869 - val_precision: 1.0000 - val_recall: 0.9885 - learning_rate: 5.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - AUC: 0.9872 - accuracy: 0.9454 - loss: 0.1342 - precision: 0.9079 - recall: 0.9460 - val_AUC: 0.0000e+00 - val_accuracy: 0.9923 - val_loss: 0.0775 - val_precision: 1.0000 - val_recall: 0.9923 - learning_rate: 5.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9869 - accuracy: 0.9475 - loss: 0.1344 - precision: 0.9086 - recall: 0.9513 - val_AUC: 0.0000e+00 - val_accuracy: 0.9880 - val_loss: 0.0822 - val_precision: 1.0000 - val_recall: 0.9880 - learning_rate: 5.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9883 - accuracy: 0.9486 - loss: 0.1279 - precision: 0.9103 - recall: 0.9527 - val_AUC: 0.0000e+00 - val_accuracy: 0.9897 - val_loss: 0.0783 - val_precision: 1.0000 - val_recall: 0.9897 - learning_rate: 5.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9887 - accuracy: 0.9515 - loss: 0.1251 - precision: 0.9170 - recall: 0.9530 - val_AUC: 0.0000e+00 - val_accuracy: 0.9906 - val_loss: 0.0785 - val_precision: 1.0000 - val_recall: 0.9906 - learning_rate: 5.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9884 - accuracy: 0.9490 - loss: 0.1266 - precision: 0.9099 - recall: 0.9542 - val_AUC: 0.0000e+00 - val_accuracy: 0.9876 - val_loss: 0.0784 - val_precision: 1.0000 - val_recall: 0.9876 - learning_rate: 5.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9879 - accuracy: 0.9484 - loss: 0.1300 - precision: 0.9107 - recall: 0.9516 - val_AUC: 0.0000e+00 - val_accuracy: 0.9910 - val_loss: 0.0819 - val_precision: 1.0000 - val_recall: 0.9910 - learning_rate: 5.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.9865 - accuracy: 0.9449 - loss: 0.1376 - precision: 0.9059 - recall: 0.9469 - val_AUC: 0.0000e+00 - val_accuracy: 0.9859 - val_loss: 0.0949 - val_precision: 1.0000 - val_recall: 0.9859 - learning_rate: 5.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - AUC: 0.9895 - accuracy: 0.9508 - loss: 0.1228 - precision: 0.9152 - recall: 0.9530 - val_AUC: 0.0000e+00 - val_accuracy: 0.9897 - val_loss: 0.0818 - val_precision: 1.0000 - val_recall: 0.9897 - learning_rate: 5.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - AUC: 0.9870 - accuracy: 0.9486 - loss: 0.1346 - precision: 0.9107 - recall: 0.9522 - val_AUC: 0.0000e+00 - val_accuracy: 0.9923 - val_loss: 0.0798 - val_precision: 1.0000 - val_recall: 0.9923 - learning_rate: 5.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9897 - accuracy: 0.9534 - loss: 0.1204 - precision: 0.9238 - recall: 0.9504 - val_AUC: 0.0000e+00 - val_accuracy: 0.9957 - val_loss: 0.0638 - val_precision: 1.0000 - val_recall: 0.9957 - learning_rate: 5.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9870 - accuracy: 0.9470 - loss: 0.1355 - precision: 0.9083 - recall: 0.9504 - val_AUC: 0.0000e+00 - val_accuracy: 0.9893 - val_loss: 0.0810 - val_precision: 1.0000 - val_recall: 0.9893 - learning_rate: 5.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - AUC: 0.9872 - accuracy: 0.9459 - loss: 0.1334 - precision: 0.9068 - recall: 0.9486 - val_AUC: 0.0000e+00 - val_accuracy: 0.9940 - val_loss: 0.0680 - val_precision: 1.0000 - val_recall: 0.9940 - learning_rate: 5.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - AUC: 0.9879 - accuracy: 0.9490 - loss: 0.1292 - precision: 0.9099 - recall: 0.9542 - val_AUC: 0.0000e+00 - val_accuracy: 0.9944 - val_loss: 0.0735 - val_precision: 1.0000 - val_recall: 0.9944 - learning_rate: 5.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9894 - accuracy: 0.9501 - loss: 0.1220 - precision: 0.9157 - recall: 0.9504 - val_AUC: 0.0000e+00 - val_accuracy: 0.9919 - val_loss: 0.0728 - val_precision: 1.0000 - val_recall: 0.9919 - learning_rate: 5.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9893 - accuracy: 0.9525 - loss: 0.1228 - precision: 0.9181 - recall: 0.9545 - val_AUC: 0.0000e+00 - val_accuracy: 0.9932 - val_loss: 0.0676 - val_precision: 1.0000 - val_recall: 0.9932 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - AUC: 0.9880 - accuracy: 0.9496 - loss: 0.1308 - precision: 0.9121 - recall: 0.9533 - val_AUC: 0.0000e+00 - val_accuracy: 0.9825 - val_loss: 0.0941 - val_precision: 1.0000 - val_recall: 0.9825 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9899 - accuracy: 0.9521 - loss: 0.1202 - precision: 0.9211 - recall: 0.9495 - val_AUC: 0.0000e+00 - val_accuracy: 0.9893 - val_loss: 0.0824 - val_precision: 1.0000 - val_recall: 0.9893 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - AUC: 0.9880 - accuracy: 0.9481 - loss: 0.1294 - precision: 0.9111 - recall: 0.9501 - val_AUC: 0.0000e+00 - val_accuracy: 0.9970 - val_loss: 0.0681 - val_precision: 1.0000 - val_recall: 0.9970 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9881 - accuracy: 0.9477 - loss: 0.1278 - precision: 0.9087 - recall: 0.9519 - val_AUC: 0.0000e+00 - val_accuracy: 0.9897 - val_loss: 0.0793 - val_precision: 1.0000 - val_recall: 0.9897 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m288/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9889 - accuracy: 0.9485 - loss: 0.1246 - precision: 0.9178 - recall: 0.9454\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9892 - accuracy: 0.9511 - loss: 0.1221 - precision: 0.9155 - recall: 0.9536 - val_AUC: 0.0000e+00 - val_accuracy: 0.9949 - val_loss: 0.0686 - val_precision: 1.0000 - val_recall: 0.9949 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9897 - accuracy: 0.9554 - loss: 0.1189 - precision: 0.9197 - recall: 0.9613 - val_AUC: 0.0000e+00 - val_accuracy: 0.9962 - val_loss: 0.0616 - val_precision: 1.0000 - val_recall: 0.9962 - learning_rate: 2.5000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - AUC: 0.9907 - accuracy: 0.9546 - loss: 0.1138 - precision: 0.9212 - recall: 0.9571 - val_AUC: 0.0000e+00 - val_accuracy: 0.9953 - val_loss: 0.0616 - val_precision: 1.0000 - val_recall: 0.9953 - learning_rate: 2.5000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9899 - accuracy: 0.9560 - loss: 0.1155 - precision: 0.9217 - recall: 0.9607 - val_AUC: 0.0000e+00 - val_accuracy: 0.9846 - val_loss: 0.0795 - val_precision: 1.0000 - val_recall: 0.9846 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9908 - accuracy: 0.9589 - loss: 0.1115 - precision: 0.9297 - recall: 0.9595 - val_AUC: 0.0000e+00 - val_accuracy: 0.9966 - val_loss: 0.0635 - val_precision: 1.0000 - val_recall: 0.9966 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.9908 - accuracy: 0.9545 - loss: 0.1146 - precision: 0.9233 - recall: 0.9542 - val_AUC: 0.0000e+00 - val_accuracy: 0.9944 - val_loss: 0.0646 - val_precision: 1.0000 - val_recall: 0.9944 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - AUC: 0.9911 - accuracy: 0.9547 - loss: 0.1114 - precision: 0.9212 - recall: 0.9574 - val_AUC: 0.0000e+00 - val_accuracy: 0.9940 - val_loss: 0.0638 - val_precision: 1.0000 - val_recall: 0.9940 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - AUC: 0.9916 - accuracy: 0.9564 - loss: 0.1085 - precision: 0.9254 - recall: 0.9574 - val_AUC: 0.0000e+00 - val_accuracy: 0.9936 - val_loss: 0.0653 - val_precision: 1.0000 - val_recall: 0.9936 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - AUC: 0.9915 - accuracy: 0.9591 - loss: 0.1064 - precision: 0.9310 - recall: 0.9586 - val_AUC: 0.0000e+00 - val_accuracy: 0.9936 - val_loss: 0.0582 - val_precision: 1.0000 - val_recall: 0.9936 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - AUC: 0.9913 - accuracy: 0.9591 - loss: 0.1095 - precision: 0.9286 - recall: 0.9615 - val_AUC: 0.0000e+00 - val_accuracy: 0.9932 - val_loss: 0.0634 - val_precision: 1.0000 - val_recall: 0.9932 - learning_rate: 2.5000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9907 - accuracy: 0.9553 - loss: 0.1122 - precision: 0.9206 - recall: 0.9598 - val_AUC: 0.0000e+00 - val_accuracy: 0.9940 - val_loss: 0.0650 - val_precision: 1.0000 - val_recall: 0.9940 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "\n",
      "==================================================\n",
      "EVALUATION ON ORIGINAL TEST SET\n",
      "==================================================\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "AUC-ROC: 0.675\n",
      "AUC-PR: 0.104\n",
      "Random baseline AUC-PR: 0.042\n",
      "Improvement over random: 2.4x\n",
      "\n",
      "=== THRESHOLD ANALYSIS (RECALL-FOCUSED) ===\n",
      "Threshold 0.01:  301 flagged (19.3%), Precision 0.093, Recall 0.424, F1 0.153\n",
      "Threshold 0.02:  265 flagged (17.0%), Precision 0.098, Recall 0.394, F1 0.157\n",
      "Threshold 0.03:  244 flagged (15.7%), Precision 0.107, Recall 0.394, F1 0.168\n",
      "Threshold 0.04:  221 flagged (14.2%), Precision 0.109, Recall 0.364, F1 0.167\n",
      "Threshold 0.05:  206 flagged (13.2%), Precision 0.107, Recall 0.333, F1 0.162\n",
      "Threshold 0.06:  193 flagged (12.4%), Precision 0.109, Recall 0.318, F1 0.162\n",
      "Threshold 0.07:  188 flagged (12.1%), Precision 0.106, Recall 0.303, F1 0.157\n",
      "Threshold 0.08:  183 flagged (11.8%), Precision 0.109, Recall 0.303, F1 0.161\n",
      "Threshold 0.09:  178 flagged (11.4%), Precision 0.112, Recall 0.303, F1 0.164\n",
      "Threshold 0.10:  175 flagged (11.2%), Precision 0.114, Recall 0.303, F1 0.166\n",
      "Threshold 0.15:  157 flagged (10.1%), Precision 0.121, Recall 0.288, F1 0.170\n",
      "Threshold 0.20:  144 flagged ( 9.3%), Precision 0.125, Recall 0.273, F1 0.171\n",
      "Threshold 0.30:  120 flagged ( 7.7%), Precision 0.142, Recall 0.258, F1 0.183\n",
      "Threshold 0.50:   90 flagged ( 5.8%), Precision 0.156, Recall 0.212, F1 0.179\n",
      "\n",
      "Best threshold for recall: 0.01 (Recall: 0.424)\n",
      "\n",
      "=== COMPARISON WITH PREVIOUS APPROACHES ===\n",
      "SMOTE-ENN vs Previous Results:\n",
      "Best recall achieved: 0.424 (vs ~0.35 from class weights)\n",
      "AUC-PR: 0.104 (vs 0.174 from no modification)\n",
      "\n",
      "Top 5 thresholds by RECALL (your priority):\n",
      " threshold  flagged_pct  precision   recall       f1\n",
      "      0.01    19.344473   0.093023 0.424242 0.152589\n",
      "      0.02    17.030848   0.098113 0.393939 0.157100\n",
      "      0.03    15.681234   0.106557 0.393939 0.167742\n",
      "      0.04    14.203085   0.108597 0.363636 0.167247\n",
      "      0.05    13.239075   0.106796 0.333333 0.161765\n",
      "\n",
      "Top 5 balanced recall-precision options:\n",
      " threshold  flagged_pct  precision   recall       f1\n",
      "      0.03    15.681234   0.106557 0.393939 0.167742\n",
      "      0.04    14.203085   0.108597 0.363636 0.167247\n",
      "      0.01    19.344473   0.093023 0.424242 0.152589\n",
      "      0.02    17.030848   0.098113 0.393939 0.157100\n",
      "      0.30     7.712082   0.141667 0.257576 0.182796\n",
      "\n",
      "==================================================\n",
      "SMOTE-ENN ANALYSIS COMPLETE\n",
      "==================================================\n",
      "Key takeaways:\n",
      "1. SMOTE-ENN created 5482.0 synthetic positive samples\n",
      "2. Best recall achieved: 0.424\n",
      "3. For your use case (capture more buyers), consider threshold around 0.01\n",
      "4. Ready to compare with ensemble methods next\n"
     ]
    }
   ],
   "source": [
    "# Configure SMOTE-ENN\n",
    "smote_enn = SMOTEENN(\n",
    "    smote=SMOTE(random_state=42, k_neighbors=3),  # Reduced neighbors for small minority class\n",
    "    enn=EditedNearestNeighbours(n_neighbors=3),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply resampling\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Before SMOTE-ENN: {X_train_scaled.shape}, {y_train.value_counts().to_dict()}\")\n",
    "print(f\"After SMOTE-ENN: {X_train_resampled.shape}, {pd.Series(y_train_resampled).value_counts().to_dict()}\")\n",
    "\n",
    "# Calculate the change\n",
    "original_pos = y_train.sum()\n",
    "resampled_pos = pd.Series(y_train_resampled).sum()\n",
    "original_neg = len(y_train) - original_pos\n",
    "resampled_neg = len(y_train_resampled) - resampled_pos\n",
    "\n",
    "print(f\"\\nPositive samples: {original_pos} → {resampled_pos} (added {resampled_pos - original_pos})\")\n",
    "print(f\"Negative samples: {original_neg} → {resampled_neg} (removed {original_neg - resampled_neg})\")\n",
    "\n",
    "# 5. CREATE MODEL\n",
    "def create_model(input_dim, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall', 'AUC']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 6. TRAIN MODEL WITH SMOTE-ENN DATA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING MODEL WITH SMOTE-ENN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_smoteenn = create_model(X_train_resampled.shape[1])\n",
    "\n",
    "# Train on resampled data\n",
    "history_smoteenn = model_smoteenn.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # Split from resampled data\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. EVALUATE ON ORIGINAL TEST SET\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION ON ORIGINAL TEST SET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "y_test_pred_proba = model_smoteenn.predict(X_test_scaled)\n",
    "y_test_pred_proba = y_test_pred_proba.flatten()\n",
    "\n",
    "# Calculate PR-AUC and ROC-AUC\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_test_pred_proba)\n",
    "pr_auc = auc(recall_vals, precision_vals)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "random_baseline = y_test.sum() / len(y_test)\n",
    "\n",
    "print(f\"AUC-ROC: {roc_auc:.3f}\")\n",
    "print(f\"AUC-PR: {pr_auc:.3f}\")\n",
    "print(f\"Random baseline AUC-PR: {random_baseline:.3f}\")\n",
    "print(f\"Improvement over random: {pr_auc/random_baseline:.1f}x\")\n",
    "\n",
    "# 8. THRESHOLD ANALYSIS (focusing on recall for your use case)\n",
    "print(f\"\\n=== THRESHOLD ANALYSIS (RECALL-FOCUSED) ===\")\n",
    "thresholds = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.15, 0.20, 0.30, 0.50]\n",
    "\n",
    "best_recall = 0\n",
    "best_threshold = 0\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_test_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    if y_pred.sum() > 0:  # Avoid division by zero\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        flagged_count = y_pred.sum()\n",
    "        flagged_pct = flagged_count / len(y_test) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'flagged': flagged_count,\n",
    "            'flagged_pct': flagged_pct,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"Threshold {threshold:.2f}: {flagged_count:4d} flagged ({flagged_pct:4.1f}%), \"\n",
    "              f\"Precision {precision:.3f}, Recall {recall:.3f}, F1 {f1:.3f}\")\n",
    "        \n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest threshold for recall: {best_threshold} (Recall: {best_recall:.3f})\")\n",
    "\n",
    "# 9. COMPARE WITH YOUR PREVIOUS RESULTS\n",
    "print(f\"\\n=== COMPARISON WITH PREVIOUS APPROACHES ===\")\n",
    "print(\"SMOTE-ENN vs Previous Results:\")\n",
    "print(f\"Best recall achieved: {best_recall:.3f} (vs ~0.35 from class weights)\")\n",
    "print(f\"AUC-PR: {pr_auc:.3f} (vs 0.174 from no modification)\")\n",
    "\n",
    "# 10. TOP PERFORMERS ANALYSIS\n",
    "results_df = pd.DataFrame(results)\n",
    "# Sort by recall (since that's your priority)\n",
    "top_recall = results_df.nlargest(5, 'recall')\n",
    "print(f\"\\nTop 5 thresholds by RECALL (your priority):\")\n",
    "print(top_recall[['threshold', 'flagged_pct', 'precision', 'recall', 'f1']].to_string(index=False))\n",
    "\n",
    "# Also show balanced options\n",
    "results_df['recall_precision_product'] = results_df['recall'] * results_df['precision']\n",
    "balanced_options = results_df.nlargest(5, 'recall_precision_product')\n",
    "print(f\"\\nTop 5 balanced recall-precision options:\")\n",
    "print(balanced_options[['threshold', 'flagged_pct', 'precision', 'recall', 'f1']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"SMOTE-ENN ANALYSIS COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"Key takeaways:\")\n",
    "print(f\"1. SMOTE-ENN created {resampled_pos - original_pos} synthetic positive samples\")\n",
    "print(f\"2. Best recall achieved: {best_recall:.3f}\")\n",
    "print(f\"3. For your use case (capture more buyers), consider threshold around {best_threshold}\")\n",
    "print(\"4. Ready to compare with ensemble methods next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780af1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
