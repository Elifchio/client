{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3dbf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dff50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data/merged_df_net_sc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63d0acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12280 entries, 0 to 12279\n",
      "Data columns (total 41 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   gross_fu                        12280 non-null  int64  \n",
      " 1   gross_sc                        12280 non-null  int64  \n",
      " 2   net_fu                          12280 non-null  float64\n",
      " 3   net_sc                          12280 non-null  float64\n",
      " 4   time_first_sc_to_first_net_fu   12280 non-null  float64\n",
      " 5   electricitybill                 12280 non-null  float64\n",
      " 6   heatingbill                     12280 non-null  float64\n",
      " 7   grosscontractsigned             12280 non-null  float64\n",
      " 8   selfipa_done                    12280 non-null  int64  \n",
      " 9   zipregion_missing               12280 non-null  int64  \n",
      " 10  evaluationtime_missing          12280 non-null  int64  \n",
      " 11  desiredinstallationend_missing  12280 non-null  int64  \n",
      " 12  electricitybill_missing         12280 non-null  int64  \n",
      " 13  heatingbill_missing             12280 non-null  int64  \n",
      " 14  aggregated_missing              12280 non-null  int64  \n",
      " 15  desiredinstallationend_encoded  12280 non-null  int64  \n",
      " 16  mktg_high                       12280 non-null  bool   \n",
      " 17  mktg_low                        12280 non-null  bool   \n",
      " 18  mktg_medium                     12280 non-null  bool   \n",
      " 19  region_high_performer           12280 non-null  bool   \n",
      " 20  region_large_solid              12280 non-null  bool   \n",
      " 21  region_lower                    12280 non-null  bool   \n",
      " 22  region_medium                   12280 non-null  bool   \n",
      " 23  total_bc_attempts               12280 non-null  int64  \n",
      " 24  total_bc_outcomes               12280 non-null  int64  \n",
      " 25  lead_to_first_bc_days           12280 non-null  float64\n",
      " 26  bc_duration_days                12280 non-null  float64\n",
      " 27  bc_frequency                    12280 non-null  float64\n",
      " 28  positive_outcomes_count         12280 non-null  int64  \n",
      " 29  negative_outcomes_count         12280 non-null  int64  \n",
      " 30  noshow_outcomes_count           12280 non-null  int64  \n",
      " 31  positive_outcome_ratio          12280 non-null  float64\n",
      " 32  negative_outcome_ratio          12280 non-null  float64\n",
      " 33  noshow_outcome_ratio            12280 non-null  float64\n",
      " 34  reachability_score              12280 non-null  float64\n",
      " 35  outcome_trend                   12280 non-null  int64  \n",
      " 36  persistence_after_negative      12280 non-null  int64  \n",
      " 37  engagement_score                12280 non-null  float64\n",
      " 38  efficiency_score                12280 non-null  float64\n",
      " 39  last_bc_outcome_encoded         12280 non-null  int64  \n",
      " 40  first_bc_outcome_encoded        12280 non-null  int64  \n",
      "dtypes: bool(7), float64(15), int64(19)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923bac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SIGNAL TEST RESULTS ===\n",
      "AUC-ROC Score: 0.808\n",
      "✅ GOOD NEWS: Your features contain useful signal!\n",
      "We can proceed with imbalance fixing strategies.\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "\n",
    "target_column = 'grosscontractsigned'\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler() # important for logistic regressor\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a simple logistic regression (NO imbalance handling yet)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Check if there's any signal\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\n=== SIGNAL TEST RESULTS ===\")\n",
    "print(f\"AUC-ROC Score: {auc_score:.3f}\")\n",
    "if auc_score > 0.5:\n",
    "    print(\"✅ GOOD NEWS: Your features contain useful signal!\")\n",
    "    print(\"We can proceed with imbalance fixing strategies.\")\n",
    "else:\n",
    "    print(\"❌ BAD NEWS: No signal detected. Features need work first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25cc718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DETAILED SIGNAL ANALYSIS ===\n",
      "AUC-ROC: 0.808\n",
      "AUC-PR: 0.606\n",
      "Random baseline AUC-PR: 0.177\n",
      "Improvement over random: 3.4x\n",
      "\n",
      "With 0.5 threshold:\n",
      "Predicted positives: 1296\n",
      "Actual positives: 434.0\n",
      "F1 Score: 0.415\n",
      "\n",
      "Optimal F1 threshold analysis:\n",
      "Best threshold: 0.232\n",
      "Best F1 Score: 0.554\n",
      "Predicted positives at optimal: 418\n",
      "\n",
      "Top 10% analysis:\n",
      "Threshold for top 10%: 0.398\n",
      "Conversion rate in top 10%: 0.691\n",
      "That's 3.9x better than average!\n",
      "\n",
      "Classification Report (Optimal F1 Threshold = 0.232):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.91      2022\n",
      "         1.0       0.56      0.54      0.55       434\n",
      "\n",
      "    accuracy                           0.85      2456\n",
      "   macro avg       0.73      0.73      0.73      2456\n",
      "weighted avg       0.84      0.85      0.84      2456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Calculate AUC-PR (more reliable for imbalanced data)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Random baseline for comparison\n",
    "random_baseline = y_test.mean()  # 0.023\n",
    "\n",
    "print(\"\\n=== DETAILED SIGNAL ANALYSIS ===\")\n",
    "print(f\"AUC-ROC: {auc_score:.3f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "print(f\"Random baseline AUC-PR: {random_baseline:.3f}\")\n",
    "print(f\"Improvement over random: {auc_pr/random_baseline:.1f}x\")\n",
    "\n",
    "# Look at actual predictions with default 0.5 threshold\n",
    "y_pred = (y_pred_proba >= 0.1).astype(int)\n",
    "f1_default = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nWith 0.5 threshold:\")\n",
    "print(f\"Predicted positives: {y_pred.sum()}\")\n",
    "print(f\"Actual positives: {y_test.sum()}\")\n",
    "print(f\"F1 Score: {f1_default:.3f}\")\n",
    "\n",
    "# Find optimal threshold for F1 score\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1_scores = []\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_thresh))\n",
    "\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "optimal_f1 = max(f1_scores)\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(f\"\\nOptimal F1 threshold analysis:\")\n",
    "print(f\"Best threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"Best F1 Score: {optimal_f1:.3f}\")\n",
    "print(f\"Predicted positives at optimal: {y_pred_optimal.sum()}\")\n",
    "\n",
    "# Check top 10% of predictions\n",
    "top_10_percent_threshold = np.percentile(y_pred_proba, 90)\n",
    "print(f\"\\nTop 10% analysis:\")\n",
    "print(f\"Threshold for top 10%: {top_10_percent_threshold:.3f}\")\n",
    "top_10_mask = y_pred_proba >= top_10_percent_threshold\n",
    "print(f\"Conversion rate in top 10%: {y_test[top_10_mask].mean():.3f}\")\n",
    "print(f\"That's {y_test[top_10_mask].mean()/y_test.mean():.1f}x better than average!\")\n",
    "\n",
    "# Detailed classification report at optimal threshold\n",
    "print(f\"\\nClassification Report (Optimal F1 Threshold = {optimal_threshold:.3f}):\")\n",
    "print(classification_report(y_test, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f758cb4",
   "metadata": {},
   "source": [
    "#### First Strategy\n",
    "\n",
    "Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b7e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTING CLASS WEIGHTS ===\n",
      "Calculated positive class weight: 4.7\n",
      "\n",
      "Class Weights Results:\n",
      "AUC-ROC: 0.811\n",
      "AUC-PR: 0.594\n",
      "Improvement over baseline: 0.98x\n",
      "At 0.1 threshold: 2267 predicted positive, 0.189 precision\n",
      "At 0.2 threshold: 1890 predicted positive, 0.219 precision\n",
      "At 0.3 threshold: 1446 predicted positive, 0.262 precision\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test class weights with your strong signal\n",
    "print(\"\\n=== TESTING CLASS WEIGHTS ===\")\n",
    "\n",
    "# Calculate balanced class weight\n",
    "pos_weight = (1 - y_train.mean()) / y_train.mean()  # About 42 for your data\n",
    "print(f\"Calculated positive class weight: {pos_weight:.1f}\")\n",
    "\n",
    "# Train with class weights\n",
    "lr_weighted = LogisticRegression(\n",
    "    class_weight={0: 1, 1: pos_weight},\n",
    "    random_state=42, \n",
    "    max_iter=1000\n",
    ")\n",
    "lr_weighted.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_weighted = lr_weighted.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "precision_w, recall_w, _ = precision_recall_curve(y_test, y_pred_weighted)\n",
    "auc_pr_weighted = auc(recall_w, precision_w)\n",
    "auc_roc_weighted = roc_auc_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(f\"\\nClass Weights Results:\")\n",
    "print(f\"AUC-ROC: {auc_roc_weighted:.3f}\")\n",
    "print(f\"AUC-PR: {auc_pr_weighted:.3f}\")\n",
    "print(f\"Improvement over baseline: {auc_pr_weighted/auc_pr:.2f}x\")\n",
    "\n",
    "# Check different thresholds\n",
    "for thresh in [0.1, 0.2, 0.3]:\n",
    "    pred_at_thresh = (y_pred_weighted >= thresh).astype(int)\n",
    "    if pred_at_thresh.sum() > 0:\n",
    "        precision_at_thresh = (y_test[pred_at_thresh == 1]).mean()\n",
    "        print(f\"At {thresh} threshold: {pred_at_thresh.sum()} predicted positive, {precision_at_thresh:.3f} precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f549f2",
   "metadata": {},
   "source": [
    "Class weights actually made things slightly worse (AUC-PR dropped from 0.174 to 0.158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea0c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== THRESHOLD OPTIMIZATION ===\n",
      "Using original model (no class weights)\n",
      "Threshold 0.01: 2386 flagged (97.1%), Precision 0.180, Recall 0.991, F1 0.305\n",
      "Threshold 0.02: 2287 flagged (93.1%), Precision 0.188, Recall 0.991, F1 0.316\n",
      "Threshold 0.03: 2190 flagged (89.2%), Precision 0.194, Recall 0.977, F1 0.323\n",
      "Threshold 0.04: 2063 flagged (84.0%), Precision 0.203, Recall 0.963, F1 0.335\n",
      "Threshold 0.05: 1922 flagged (78.3%), Precision 0.214, Recall 0.949, F1 0.350\n",
      "Threshold 0.06: 1767 flagged (71.9%), Precision 0.226, Recall 0.922, F1 0.363\n",
      "Threshold 0.07: 1645 flagged (67.0%), Precision 0.241, Recall 0.912, F1 0.381\n",
      "Threshold 0.08: 1517 flagged (61.8%), Precision 0.253, Recall 0.885, F1 0.394\n",
      "Threshold 0.09: 1419 flagged (57.8%), Precision 0.264, Recall 0.862, F1 0.404\n",
      "Threshold 0.10: 1296 flagged (52.8%), Precision 0.277, Recall 0.827, F1 0.415\n"
     ]
    }
   ],
   "source": [
    "# checking the difference thresholds make\n",
    "\n",
    "# Use the original (better) model predictions\n",
    "print(\"=== THRESHOLD OPTIMIZATION ===\")\n",
    "print(\"Using original model (no class weights)\")\n",
    "\n",
    "# Try many different thresholds\n",
    "thresholds = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    pred_at_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    \n",
    "    if pred_at_thresh.sum() > 0:\n",
    "        precision = (y_test[pred_at_thresh == 1]).mean()\n",
    "        recall = (y_test * pred_at_thresh).sum() / y_test.sum()\n",
    "        \n",
    "        if precision > 0 and recall > 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "            \n",
    "        results.append({\n",
    "            'threshold': thresh,\n",
    "            'predicted_positive': pred_at_thresh.sum(),\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'percent_flagged': pred_at_thresh.sum() / len(y_test) * 100\n",
    "        })\n",
    "\n",
    "# Show results\n",
    "for r in results:\n",
    "    print(f\"Threshold {r['threshold']:.2f}: {r['predicted_positive']:4d} flagged ({r['percent_flagged']:4.1f}%), \"\n",
    "          f\"Precision {r['precision']:.3f}, Recall {r['recall']:.3f}, F1 {r['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594fb36a",
   "metadata": {},
   "source": [
    "#### Second Strategy\n",
    "\n",
    "Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf2cfccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Focal Loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Binary Crossentropy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training traditional models...\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\n",
      "==================================================\n",
      "RESULTS COMPARISON\n",
      "==================================================\n",
      "Focal Loss Accuracy:           0.4532\n",
      "Binary Crossentropy Accuracy:  0.5008\n",
      "Logistic Regression Accuracy:  0.4753\n",
      "Random Forest Accuracy:        0.6119\n",
      "\n",
      "------------------------------\n",
      "FOCAL LOSS DETAILED REPORT:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      2022\n",
      "         1.0       0.87      0.31      0.45       434\n",
      "\n",
      "    accuracy                           0.87      2456\n",
      "   macro avg       0.87      0.65      0.69      2456\n",
      "weighted avg       0.87      0.87      0.84      2456\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'f1_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, focal_pred))\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Show training progress\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFocal Loss - Final Training Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfocal_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBinary CE - Final Training Accuracy:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbce_history.history[\u001b[33m'\u001b[39m\u001b[33mf1_score\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFocal Loss - Final Training Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfocal_history.history[\u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'f1_score'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Your existing data split\n",
    "target_column = 'grosscontractsigned'\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale the features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Your Focal Loss class\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        ce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        alpha_t = y_true * self.alpha + (1 - y_true) * (1 - self.alpha)\n",
    "        focal_loss = alpha_t * tf.pow((1 - p_t), self.gamma) * ce_loss\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "\n",
    "# Simple neural network with Focal Loss\n",
    "def create_model(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 1. Model with Focal Loss\n",
    "print(\"Training model with Focal Loss...\")\n",
    "focal_model = create_model(X_train_scaled.shape[1])\n",
    "focal_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=FocalLoss(alpha=0.25, gamma=2.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "focal_history = focal_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 2. Model with Binary Crossentropy\n",
    "print(\"Training model with Binary Crossentropy...\")\n",
    "bce_model = create_model(X_train_scaled.shape[1])\n",
    "bce_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "bce_history = bce_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 3. Traditional methods for comparison\n",
    "print(\"Training traditional models...\")\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "focal_pred = (focal_model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "bce_pred = (bce_model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Focal Loss Accuracy:           {f1_score(y_test, focal_pred):.4f}\")\n",
    "print(f\"Binary Crossentropy Accuracy:  {f1_score(y_test, bce_pred):.4f}\")\n",
    "print(f\"Logistic Regression Accuracy:  {f1_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"Random Forest Accuracy:        {f1_score(y_test, rf_pred):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"FOCAL LOSS DETAILED REPORT:\")\n",
    "print(\"-\"*30)\n",
    "print(classification_report(y_test, focal_pred))\n",
    "\n",
    "# Show training progress\n",
    "print(f\"\\nFocal Loss - Final Training Accuracy: {focal_history.history['f1_score'][-1]:.4f}\")\n",
    "print(f\"Binary CE - Final Training Accuracy:  {bce_history.history['f1_score'][-1]:.4f}\")\n",
    "print(f\"\\nFocal Loss - Final Training Accuracy: {focal_history.history['precision'][-1]:.4f}\")\n",
    "print(f\"Binary CE - Final Training Accuracy:  {bce_history.history['precision'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38d4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Focal Loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Binary Crossentropy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training traditional models...\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2456, 3908]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Calculate metrics for all models\u001b[39;00m\n\u001b[32m    119\u001b[39m results = []\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m results.append(\u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocal_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocal_pred_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFocal Loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    121\u001b[39m results.append(calculate_metrics(y_test, bce_pred, bce_pred_proba, \u001b[33m'\u001b[39m\u001b[33mBinary Crossentropy\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    122\u001b[39m results.append(calculate_metrics(y_test, lr_pred, lr_pred_proba, \u001b[33m'\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mcalculate_metrics\u001b[39m\u001b[34m(y_true, y_pred, y_pred_proba, model_name)\u001b[39m\n\u001b[32m    103\u001b[39m recall = recall_score(y_true, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    104\u001b[39m f1 = f1_score(y_true, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m auc_pr = \u001b[43maverage_precision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m roc_auc = roc_auc_score(y_true, y_pred_proba)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    109\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m: model_name,\n\u001b[32m    110\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m: accuracy,\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mROC-AUC\u001b[39m\u001b[33m'\u001b[39m: roc_auc\n\u001b[32m    116\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:266\u001b[39m, in \u001b[36maverage_precision_score\u001b[39m\u001b[34m(y_true, y_score, average, pos_label, sample_weight)\u001b[39m\n\u001b[32m    261\u001b[39m     y_true = label_binarize(y_true, classes=present_labels)\n\u001b[32m    263\u001b[39m average_precision = partial(\n\u001b[32m    264\u001b[39m     _binary_uninterpolated_average_precision, pos_label=pos_label\n\u001b[32m    265\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43maverage_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py:69\u001b[39m, in \u001b[36m_average_binary_score\u001b[39m\u001b[34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m     72\u001b[39m y_true = check_array(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:227\u001b[39m, in \u001b[36maverage_precision_score.<locals>._binary_uninterpolated_average_precision\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_binary_uninterpolated_average_precision\u001b[39m(\n\u001b[32m    225\u001b[39m     y_true, y_score, pos_label=\u001b[32m1\u001b[39m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    226\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     precision, recall, _ = \u001b[43mprecision_recall_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Return the step function integral\u001b[39;00m\n\u001b[32m    231\u001b[39m     \u001b[38;5;66;03m# The following works because the last entry of precision is\u001b[39;00m\n\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# guaranteed to be 1, as returned by precision_recall_curve.\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;66;03m# Due to numerical error, we can get `-0.0` and we therefore clip it.\u001b[39;00m\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[32m0.0\u001b[39m, -np.sum(np.diff(recall) * np.array(precision)[:-\u001b[32m1\u001b[39m])))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1018\u001b[39m, in \u001b[36mprecision_recall_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m    912\u001b[39m     {\n\u001b[32m    913\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m     drop_intermediate=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    928\u001b[39m ):\n\u001b[32m    929\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute precision-recall pairs for different probability thresholds.\u001b[39;00m\n\u001b[32m    930\u001b[39m \n\u001b[32m    931\u001b[39m \u001b[33;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m \u001b[33;03m    array([0.1 , 0.35, 0.4 , 0.8 ])\u001b[39;00m\n\u001b[32m   1017\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m     fps, tps, thresholds = \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n\u001b[32m   1023\u001b[39m         \u001b[38;5;66;03m# Drop thresholds corresponding to points where true positives (tps)\u001b[39;00m\n\u001b[32m   1024\u001b[39m         \u001b[38;5;66;03m# do not change from the previous or subsequent point. This will keep\u001b[39;00m\n\u001b[32m   1025\u001b[39m         \u001b[38;5;66;03m# only the first and last point for each tps value. All points\u001b[39;00m\n\u001b[32m   1026\u001b[39m         \u001b[38;5;66;03m# with the same tps value have the same recall and thus x coordinate.\u001b[39;00m\n\u001b[32m   1027\u001b[39m         \u001b[38;5;66;03m# They appear as a vertical line on the plot.\u001b[39;00m\n\u001b[32m   1028\u001b[39m         optimal_idxs = np.where(\n\u001b[32m   1029\u001b[39m             np.concatenate(\n\u001b[32m   1030\u001b[39m                 [[\u001b[38;5;28;01mTrue\u001b[39;00m], np.logical_or(np.diff(tps[:-\u001b[32m1\u001b[39m]), np.diff(tps[\u001b[32m1\u001b[39m:])), [\u001b[38;5;28;01mTrue\u001b[39;00m]]\n\u001b[32m   1031\u001b[39m             )\n\u001b[32m   1032\u001b[39m         )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:865\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m y_true = column_or_1d(y_true)\n\u001b[32m    867\u001b[39m y_score = column_or_1d(y_score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [2456, 3908]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, precision_score, \n",
    "                           recall_score, f1_score, average_precision_score, roc_auc_score)\n",
    "import pandas as pd\n",
    "\n",
    "# Your existing data split\n",
    "target_column = 'grosscontractsigned'\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale the features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Your Focal Loss class\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        ce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        alpha_t = y_true * self.alpha + (1 - y_true) * (1 - self.alpha)\n",
    "        focal_loss = alpha_t * tf.pow((1 - p_t), self.gamma) * ce_loss\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "\n",
    "# Simple neural network with Focal Loss\n",
    "def create_model(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 1. Model with Focal Loss\n",
    "print(\"Training model with Focal Loss...\")\n",
    "focal_model = create_model(X_train_scaled.shape[1])\n",
    "focal_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=FocalLoss(alpha=0.25, gamma=2.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "focal_history = focal_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 2. Model with Binary Crossentropy\n",
    "print(\"Training model with Binary Crossentropy...\")\n",
    "bce_model = create_model(X_train_scaled.shape[1])\n",
    "bce_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "bce_history = bce_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 3. Traditional methods for comparison\n",
    "print(\"Training traditional models...\")\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "focal_pred = (focal_model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "bce_pred = (bce_model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate all metrics for each model\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    auc_pr = average_precision_score(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-PR': auc_pr,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "\n",
    "# Calculate metrics for all models\n",
    "results = []\n",
    "results.append(calculate_metrics(y_test, focal_pred, focal_pred_proba, 'Focal Loss'))\n",
    "results.append(calculate_metrics(y_test, bce_pred, bce_pred_proba, 'Binary Crossentropy'))\n",
    "results.append(calculate_metrics(y_test, lr_pred, lr_pred_proba, 'Logistic Regression'))\n",
    "results.append(calculate_metrics(y_test, rf_pred, rf_pred_proba, 'Random Forest'))\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING BY EACH METRIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-PR', 'ROC-AUC']\n",
    "for metric in metrics:\n",
    "    sorted_df = results_df.sort_values(metric, ascending=False)\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for i, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "        print(f\"  {i}. {row['Model']}: {row[metric]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "models = [\n",
    "    ('Focal Loss', focal_pred),\n",
    "    ('Binary Crossentropy', bce_pred),\n",
    "    ('Logistic Regression', lr_pred),\n",
    "    ('Random Forest', rf_pred)\n",
    "]\n",
    "\n",
    "for model_name, predictions in models:\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "# Show training progress\n",
    "print(f\"\\nFocal Loss - Final Training Accuracy: {focal_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Binary CE - Final Training Accuracy:  {bce_history.history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce4819",
   "metadata": {},
   "source": [
    "#### Third Strategy\n",
    "\n",
    "Smoteen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e261b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE-ENN: (9824, 40), {0.0: 8087, 1.0: 1737}\n",
      "After SMOTE-ENN: (14743, 40), {0.0: 8087, 1.0: 6656}\n",
      "\n",
      "Positive samples: 1737.0 → 6656.0 (added 4919.0)\n",
      "Negative samples: 8087.0 → 8087.0 (removed 0.0)\n",
      "\n",
      "==================================================\n",
      "TRAINING MODEL WITH SMOTE-ENN\n",
      "==================================================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - AUC: 0.7984 - accuracy: 0.7816 - loss: 0.4846 - precision: 0.7403 - recall: 0.4699 - val_AUC: 0.0000e+00 - val_accuracy: 0.5948 - val_loss: 0.6920 - val_precision: 1.0000 - val_recall: 0.5948 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.8663 - accuracy: 0.8256 - loss: 0.4034 - precision: 0.8022 - recall: 0.5908 - val_AUC: 0.0000e+00 - val_accuracy: 0.5744 - val_loss: 0.7365 - val_precision: 1.0000 - val_recall: 0.5744 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.8760 - accuracy: 0.8331 - loss: 0.3922 - precision: 0.8127 - recall: 0.6097 - val_AUC: 0.0000e+00 - val_accuracy: 0.6239 - val_loss: 0.6822 - val_precision: 1.0000 - val_recall: 0.6239 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.8841 - accuracy: 0.8339 - loss: 0.3804 - precision: 0.7969 - recall: 0.6329 - val_AUC: 0.0000e+00 - val_accuracy: 0.6151 - val_loss: 0.6598 - val_precision: 1.0000 - val_recall: 0.6151 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.8892 - accuracy: 0.8353 - loss: 0.3718 - precision: 0.8003 - recall: 0.6345 - val_AUC: 0.0000e+00 - val_accuracy: 0.6341 - val_loss: 0.6273 - val_precision: 1.0000 - val_recall: 0.6341 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8904 - accuracy: 0.8396 - loss: 0.3698 - precision: 0.8141 - recall: 0.6345 - val_AUC: 0.0000e+00 - val_accuracy: 0.6222 - val_loss: 0.6522 - val_precision: 1.0000 - val_recall: 0.6222 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.8951 - accuracy: 0.8390 - loss: 0.3623 - precision: 0.8104 - recall: 0.6366 - val_AUC: 0.0000e+00 - val_accuracy: 0.6412 - val_loss: 0.6485 - val_precision: 1.0000 - val_recall: 0.6412 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.8975 - accuracy: 0.8439 - loss: 0.3583 - precision: 0.8110 - recall: 0.6563 - val_AUC: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.6226 - val_precision: 1.0000 - val_recall: 0.6250 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9009 - accuracy: 0.8457 - loss: 0.3551 - precision: 0.8171 - recall: 0.6558 - val_AUC: 0.0000e+00 - val_accuracy: 0.6026 - val_loss: 0.6587 - val_precision: 1.0000 - val_recall: 0.6026 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.9018 - accuracy: 0.8492 - loss: 0.3494 - precision: 0.8235 - recall: 0.6620 - val_AUC: 0.0000e+00 - val_accuracy: 0.6494 - val_loss: 0.6775 - val_precision: 1.0000 - val_recall: 0.6494 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9037 - accuracy: 0.8444 - loss: 0.3469 - precision: 0.8087 - recall: 0.6615 - val_AUC: 0.0000e+00 - val_accuracy: 0.6521 - val_loss: 0.5760 - val_precision: 1.0000 - val_recall: 0.6521 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9082 - accuracy: 0.8514 - loss: 0.3397 - precision: 0.8239 - recall: 0.6704 - val_AUC: 0.0000e+00 - val_accuracy: 0.6931 - val_loss: 0.5810 - val_precision: 1.0000 - val_recall: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9117 - accuracy: 0.8531 - loss: 0.3344 - precision: 0.8312 - recall: 0.6682 - val_AUC: 0.0000e+00 - val_accuracy: 0.6494 - val_loss: 0.6063 - val_precision: 1.0000 - val_recall: 0.6494 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9136 - accuracy: 0.8543 - loss: 0.3309 - precision: 0.8272 - recall: 0.6782 - val_AUC: 0.0000e+00 - val_accuracy: 0.6504 - val_loss: 0.6174 - val_precision: 1.0000 - val_recall: 0.6504 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9151 - accuracy: 0.8565 - loss: 0.3293 - precision: 0.8359 - recall: 0.6760 - val_AUC: 0.0000e+00 - val_accuracy: 0.7107 - val_loss: 0.5217 - val_precision: 1.0000 - val_recall: 0.7107 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9184 - accuracy: 0.8582 - loss: 0.3241 - precision: 0.8237 - recall: 0.6984 - val_AUC: 0.0000e+00 - val_accuracy: 0.6738 - val_loss: 0.6174 - val_precision: 1.0000 - val_recall: 0.6738 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9190 - accuracy: 0.8603 - loss: 0.3227 - precision: 0.8303 - recall: 0.6981 - val_AUC: 0.0000e+00 - val_accuracy: 0.6467 - val_loss: 0.6188 - val_precision: 1.0000 - val_recall: 0.6467 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.9206 - accuracy: 0.8612 - loss: 0.3189 - precision: 0.8337 - recall: 0.6976 - val_AUC: 0.0000e+00 - val_accuracy: 0.6779 - val_loss: 0.5851 - val_precision: 1.0000 - val_recall: 0.6779 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9223 - accuracy: 0.8611 - loss: 0.3163 - precision: 0.8340 - recall: 0.6968 - val_AUC: 0.0000e+00 - val_accuracy: 0.7226 - val_loss: 0.5177 - val_precision: 1.0000 - val_recall: 0.7226 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9244 - accuracy: 0.8645 - loss: 0.3113 - precision: 0.8394 - recall: 0.7035 - val_AUC: 0.0000e+00 - val_accuracy: 0.6592 - val_loss: 0.5822 - val_precision: 1.0000 - val_recall: 0.6592 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9281 - accuracy: 0.8690 - loss: 0.3065 - precision: 0.8451 - recall: 0.7141 - val_AUC: 0.0000e+00 - val_accuracy: 0.7152 - val_loss: 0.5286 - val_precision: 1.0000 - val_recall: 0.7152 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9277 - accuracy: 0.8695 - loss: 0.3045 - precision: 0.8443 - recall: 0.7170 - val_AUC: 0.0000e+00 - val_accuracy: 0.7341 - val_loss: 0.4894 - val_precision: 1.0000 - val_recall: 0.7341 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9286 - accuracy: 0.8682 - loss: 0.3042 - precision: 0.8436 - recall: 0.7127 - val_AUC: 0.0000e+00 - val_accuracy: 0.7053 - val_loss: 0.5421 - val_precision: 1.0000 - val_recall: 0.7053 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9307 - accuracy: 0.8693 - loss: 0.3019 - precision: 0.8453 - recall: 0.7151 - val_AUC: 0.0000e+00 - val_accuracy: 0.7070 - val_loss: 0.5380 - val_precision: 1.0000 - val_recall: 0.7070 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9320 - accuracy: 0.8714 - loss: 0.2981 - precision: 0.8439 - recall: 0.7248 - val_AUC: 0.0000e+00 - val_accuracy: 0.7114 - val_loss: 0.5329 - val_precision: 1.0000 - val_recall: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9330 - accuracy: 0.8715 - loss: 0.2932 - precision: 0.8419 - recall: 0.7281 - val_AUC: 0.0000e+00 - val_accuracy: 0.7053 - val_loss: 0.5177 - val_precision: 1.0000 - val_recall: 0.7053 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9348 - accuracy: 0.8765 - loss: 0.2918 - precision: 0.8549 - recall: 0.7310 - val_AUC: 0.0000e+00 - val_accuracy: 0.7270 - val_loss: 0.5045 - val_precision: 1.0000 - val_recall: 0.7270 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9351 - accuracy: 0.8725 - loss: 0.2906 - precision: 0.8403 - recall: 0.7337 - val_AUC: 0.0000e+00 - val_accuracy: 0.7362 - val_loss: 0.4882 - val_precision: 1.0000 - val_recall: 0.7362 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9380 - accuracy: 0.8750 - loss: 0.2863 - precision: 0.8443 - recall: 0.7386 - val_AUC: 0.0000e+00 - val_accuracy: 0.7684 - val_loss: 0.4499 - val_precision: 1.0000 - val_recall: 0.7684 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9380 - accuracy: 0.8779 - loss: 0.2852 - precision: 0.8472 - recall: 0.7462 - val_AUC: 0.0000e+00 - val_accuracy: 0.7325 - val_loss: 0.4668 - val_precision: 1.0000 - val_recall: 0.7325 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.9397 - accuracy: 0.8788 - loss: 0.2819 - precision: 0.8460 - recall: 0.7513 - val_AUC: 0.0000e+00 - val_accuracy: 0.7077 - val_loss: 0.5270 - val_precision: 1.0000 - val_recall: 0.7077 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9411 - accuracy: 0.8814 - loss: 0.2805 - precision: 0.8525 - recall: 0.7529 - val_AUC: 0.0000e+00 - val_accuracy: 0.7341 - val_loss: 0.5073 - val_precision: 1.0000 - val_recall: 0.7341 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9408 - accuracy: 0.8814 - loss: 0.2796 - precision: 0.8499 - recall: 0.7561 - val_AUC: 0.0000e+00 - val_accuracy: 0.7484 - val_loss: 0.4612 - val_precision: 1.0000 - val_recall: 0.7484 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9424 - accuracy: 0.8820 - loss: 0.2743 - precision: 0.8515 - recall: 0.7564 - val_AUC: 0.0000e+00 - val_accuracy: 0.7426 - val_loss: 0.4656 - val_precision: 1.0000 - val_recall: 0.7426 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.9415 - accuracy: 0.8806 - loss: 0.2783 - precision: 0.8478 - recall: 0.7559 - val_AUC: 0.0000e+00 - val_accuracy: 0.7182 - val_loss: 0.5118 - val_precision: 1.0000 - val_recall: 0.7182 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9408 - accuracy: 0.8825 - loss: 0.2788 - precision: 0.8535 - recall: 0.7559 - val_AUC: 0.0000e+00 - val_accuracy: 0.7403 - val_loss: 0.4726 - val_precision: 1.0000 - val_recall: 0.7403 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9450 - accuracy: 0.8837 - loss: 0.2698 - precision: 0.8563 - recall: 0.7569 - val_AUC: 0.0000e+00 - val_accuracy: 0.7745 - val_loss: 0.4341 - val_precision: 1.0000 - val_recall: 0.7745 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9459 - accuracy: 0.8846 - loss: 0.2672 - precision: 0.8537 - recall: 0.7637 - val_AUC: 0.0000e+00 - val_accuracy: 0.7670 - val_loss: 0.4338 - val_precision: 1.0000 - val_recall: 0.7670 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9456 - accuracy: 0.8827 - loss: 0.2691 - precision: 0.8547 - recall: 0.7551 - val_AUC: 0.0000e+00 - val_accuracy: 0.7620 - val_loss: 0.4394 - val_precision: 1.0000 - val_recall: 0.7620 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9470 - accuracy: 0.8837 - loss: 0.2667 - precision: 0.8526 - recall: 0.7615 - val_AUC: 0.0000e+00 - val_accuracy: 0.7789 - val_loss: 0.4020 - val_precision: 1.0000 - val_recall: 0.7789 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.9465 - accuracy: 0.8847 - loss: 0.2661 - precision: 0.8546 - recall: 0.7629 - val_AUC: 0.0000e+00 - val_accuracy: 0.7616 - val_loss: 0.4374 - val_precision: 1.0000 - val_recall: 0.7616 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9494 - accuracy: 0.8864 - loss: 0.2586 - precision: 0.8607 - recall: 0.7618 - val_AUC: 0.0000e+00 - val_accuracy: 0.7558 - val_loss: 0.4473 - val_precision: 1.0000 - val_recall: 0.7558 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9470 - accuracy: 0.8887 - loss: 0.2668 - precision: 0.8614 - recall: 0.7696 - val_AUC: 0.0000e+00 - val_accuracy: 0.7786 - val_loss: 0.4276 - val_precision: 1.0000 - val_recall: 0.7786 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9479 - accuracy: 0.8868 - loss: 0.2616 - precision: 0.8542 - recall: 0.7715 - val_AUC: 0.0000e+00 - val_accuracy: 0.7843 - val_loss: 0.4094 - val_precision: 1.0000 - val_recall: 0.7843 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9488 - accuracy: 0.8902 - loss: 0.2613 - precision: 0.8681 - recall: 0.7672 - val_AUC: 0.0000e+00 - val_accuracy: 0.7908 - val_loss: 0.4149 - val_precision: 1.0000 - val_recall: 0.7908 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.9487 - accuracy: 0.8866 - loss: 0.2621 - precision: 0.8578 - recall: 0.7664 - val_AUC: 0.0000e+00 - val_accuracy: 0.7721 - val_loss: 0.4398 - val_precision: 1.0000 - val_recall: 0.7721 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.9503 - accuracy: 0.8887 - loss: 0.2586 - precision: 0.8535 - recall: 0.7796 - val_AUC: 0.0000e+00 - val_accuracy: 0.7511 - val_loss: 0.4800 - val_precision: 1.0000 - val_recall: 0.7511 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9522 - accuracy: 0.8914 - loss: 0.2525 - precision: 0.8623 - recall: 0.7788 - val_AUC: 0.0000e+00 - val_accuracy: 0.7962 - val_loss: 0.3981 - val_precision: 1.0000 - val_recall: 0.7962 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9518 - accuracy: 0.8888 - loss: 0.2528 - precision: 0.8570 - recall: 0.7758 - val_AUC: 0.0000e+00 - val_accuracy: 0.7698 - val_loss: 0.4462 - val_precision: 1.0000 - val_recall: 0.7698 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9513 - accuracy: 0.8898 - loss: 0.2545 - precision: 0.8589 - recall: 0.7769 - val_AUC: 0.0000e+00 - val_accuracy: 0.7982 - val_loss: 0.3929 - val_precision: 1.0000 - val_recall: 0.7982 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - AUC: 0.9538 - accuracy: 0.8933 - loss: 0.2493 - precision: 0.8571 - recall: 0.7926 - val_AUC: 0.0000e+00 - val_accuracy: 0.8081 - val_loss: 0.3990 - val_precision: 1.0000 - val_recall: 0.8081 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.9532 - accuracy: 0.8938 - loss: 0.2494 - precision: 0.8656 - recall: 0.7837 - val_AUC: 0.0000e+00 - val_accuracy: 0.7993 - val_loss: 0.3895 - val_precision: 1.0000 - val_recall: 0.7993 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9544 - accuracy: 0.8943 - loss: 0.2478 - precision: 0.8646 - recall: 0.7869 - val_AUC: 0.0000e+00 - val_accuracy: 0.7972 - val_loss: 0.3969 - val_precision: 1.0000 - val_recall: 0.7972 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9529 - accuracy: 0.8916 - loss: 0.2508 - precision: 0.8605 - recall: 0.7818 - val_AUC: 0.0000e+00 - val_accuracy: 0.8077 - val_loss: 0.3996 - val_precision: 1.0000 - val_recall: 0.8077 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9529 - accuracy: 0.8933 - loss: 0.2508 - precision: 0.8630 - recall: 0.7850 - val_AUC: 0.0000e+00 - val_accuracy: 0.7911 - val_loss: 0.3924 - val_precision: 1.0000 - val_recall: 0.7911 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9550 - accuracy: 0.8972 - loss: 0.2464 - precision: 0.8681 - recall: 0.7936 - val_AUC: 0.0000e+00 - val_accuracy: 0.8257 - val_loss: 0.3618 - val_precision: 1.0000 - val_recall: 0.8257 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9567 - accuracy: 0.8940 - loss: 0.2426 - precision: 0.8623 - recall: 0.7888 - val_AUC: 0.0000e+00 - val_accuracy: 0.8098 - val_loss: 0.3997 - val_precision: 1.0000 - val_recall: 0.8098 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9547 - accuracy: 0.8946 - loss: 0.2469 - precision: 0.8639 - recall: 0.7890 - val_AUC: 0.0000e+00 - val_accuracy: 0.8155 - val_loss: 0.3909 - val_precision: 1.0000 - val_recall: 0.8155 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9560 - accuracy: 0.8961 - loss: 0.2427 - precision: 0.8646 - recall: 0.7939 - val_AUC: 0.0000e+00 - val_accuracy: 0.8067 - val_loss: 0.3947 - val_precision: 1.0000 - val_recall: 0.8067 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9554 - accuracy: 0.8957 - loss: 0.2448 - precision: 0.8637 - recall: 0.7934 - val_AUC: 0.0000e+00 - val_accuracy: 0.7986 - val_loss: 0.4070 - val_precision: 1.0000 - val_recall: 0.7986 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9568 - accuracy: 0.8999 - loss: 0.2412 - precision: 0.8748 - recall: 0.7953 - val_AUC: 0.0000e+00 - val_accuracy: 0.8054 - val_loss: 0.3836 - val_precision: 1.0000 - val_recall: 0.8054 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9553 - accuracy: 0.8933 - loss: 0.2460 - precision: 0.8573 - recall: 0.7926 - val_AUC: 0.0000e+00 - val_accuracy: 0.8009 - val_loss: 0.3879 - val_precision: 1.0000 - val_recall: 0.8009 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9556 - accuracy: 0.8975 - loss: 0.2439 - precision: 0.8693 - recall: 0.7931 - val_AUC: 0.0000e+00 - val_accuracy: 0.7938 - val_loss: 0.3984 - val_precision: 1.0000 - val_recall: 0.7938 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9545 - accuracy: 0.8949 - loss: 0.2468 - precision: 0.8655 - recall: 0.7880 - val_AUC: 0.0000e+00 - val_accuracy: 0.7938 - val_loss: 0.4120 - val_precision: 1.0000 - val_recall: 0.7938 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9564 - accuracy: 0.8923 - loss: 0.2427 - precision: 0.8630 - recall: 0.7815 - val_AUC: 0.0000e+00 - val_accuracy: 0.7911 - val_loss: 0.4189 - val_precision: 1.0000 - val_recall: 0.7911 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9575 - accuracy: 0.8971 - loss: 0.2386 - precision: 0.8680 - recall: 0.7931 - val_AUC: 0.0000e+00 - val_accuracy: 0.8203 - val_loss: 0.3562 - val_precision: 1.0000 - val_recall: 0.8203 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9588 - accuracy: 0.8989 - loss: 0.2360 - precision: 0.8700 - recall: 0.7977 - val_AUC: 0.0000e+00 - val_accuracy: 0.8009 - val_loss: 0.3936 - val_precision: 1.0000 - val_recall: 0.8009 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9600 - accuracy: 0.9010 - loss: 0.2314 - precision: 0.8722 - recall: 0.8025 - val_AUC: 0.0000e+00 - val_accuracy: 0.8182 - val_loss: 0.3427 - val_precision: 1.0000 - val_recall: 0.8182 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9585 - accuracy: 0.8978 - loss: 0.2374 - precision: 0.8639 - recall: 0.8012 - val_AUC: 0.0000e+00 - val_accuracy: 0.8016 - val_loss: 0.3767 - val_precision: 1.0000 - val_recall: 0.8016 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9587 - accuracy: 0.9001 - loss: 0.2353 - precision: 0.8736 - recall: 0.7977 - val_AUC: 0.0000e+00 - val_accuracy: 0.8274 - val_loss: 0.3377 - val_precision: 1.0000 - val_recall: 0.8274 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9578 - accuracy: 0.8962 - loss: 0.2389 - precision: 0.8679 - recall: 0.7901 - val_AUC: 0.0000e+00 - val_accuracy: 0.8243 - val_loss: 0.3464 - val_precision: 1.0000 - val_recall: 0.8243 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9598 - accuracy: 0.8991 - loss: 0.2334 - precision: 0.8645 - recall: 0.8052 - val_AUC: 0.0000e+00 - val_accuracy: 0.8125 - val_loss: 0.3648 - val_precision: 1.0000 - val_recall: 0.8125 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9605 - accuracy: 0.8993 - loss: 0.2312 - precision: 0.8682 - recall: 0.8012 - val_AUC: 0.0000e+00 - val_accuracy: 0.8047 - val_loss: 0.3798 - val_precision: 1.0000 - val_recall: 0.8047 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9600 - accuracy: 0.9044 - loss: 0.2315 - precision: 0.8807 - recall: 0.8047 - val_AUC: 0.0000e+00 - val_accuracy: 0.8274 - val_loss: 0.3525 - val_precision: 1.0000 - val_recall: 0.8274 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9604 - accuracy: 0.9029 - loss: 0.2302 - precision: 0.8730 - recall: 0.8087 - val_AUC: 0.0000e+00 - val_accuracy: 0.8104 - val_loss: 0.3503 - val_precision: 1.0000 - val_recall: 0.8104 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9615 - accuracy: 0.9037 - loss: 0.2278 - precision: 0.8771 - recall: 0.8066 - val_AUC: 0.0000e+00 - val_accuracy: 0.8247 - val_loss: 0.3473 - val_precision: 1.0000 - val_recall: 0.8247 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9624 - accuracy: 0.9044 - loss: 0.2263 - precision: 0.8741 - recall: 0.8128 - val_AUC: 0.0000e+00 - val_accuracy: 0.8308 - val_loss: 0.3389 - val_precision: 1.0000 - val_recall: 0.8308 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9611 - accuracy: 0.9019 - loss: 0.2286 - precision: 0.8681 - recall: 0.8112 - val_AUC: 0.0000e+00 - val_accuracy: 0.8206 - val_loss: 0.3567 - val_precision: 1.0000 - val_recall: 0.8206 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9621 - accuracy: 0.9029 - loss: 0.2264 - precision: 0.8763 - recall: 0.8047 - val_AUC: 0.0000e+00 - val_accuracy: 0.8149 - val_loss: 0.3552 - val_precision: 1.0000 - val_recall: 0.8149 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m353/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.9658 - accuracy: 0.9044 - loss: 0.2173 - precision: 0.8718 - recall: 0.8184\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9635 - accuracy: 0.9019 - loss: 0.2229 - precision: 0.8732 - recall: 0.8047 - val_AUC: 0.0000e+00 - val_accuracy: 0.8169 - val_loss: 0.3447 - val_precision: 1.0000 - val_recall: 0.8169 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9640 - accuracy: 0.9062 - loss: 0.2207 - precision: 0.8790 - recall: 0.8136 - val_AUC: 0.0000e+00 - val_accuracy: 0.8159 - val_loss: 0.3618 - val_precision: 1.0000 - val_recall: 0.8159 - learning_rate: 5.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9664 - accuracy: 0.9066 - loss: 0.2147 - precision: 0.8816 - recall: 0.8117 - val_AUC: 0.0000e+00 - val_accuracy: 0.8132 - val_loss: 0.3634 - val_precision: 1.0000 - val_recall: 0.8132 - learning_rate: 5.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9643 - accuracy: 0.9065 - loss: 0.2199 - precision: 0.8805 - recall: 0.8128 - val_AUC: 0.0000e+00 - val_accuracy: 0.8406 - val_loss: 0.3237 - val_precision: 1.0000 - val_recall: 0.8406 - learning_rate: 5.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9676 - accuracy: 0.9116 - loss: 0.2113 - precision: 0.8814 - recall: 0.8303 - val_AUC: 0.0000e+00 - val_accuracy: 0.8372 - val_loss: 0.3236 - val_precision: 1.0000 - val_recall: 0.8372 - learning_rate: 5.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9673 - accuracy: 0.9132 - loss: 0.2100 - precision: 0.8890 - recall: 0.8271 - val_AUC: 0.0000e+00 - val_accuracy: 0.8369 - val_loss: 0.3262 - val_precision: 1.0000 - val_recall: 0.8369 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9673 - accuracy: 0.9119 - loss: 0.2102 - precision: 0.8912 - recall: 0.8198 - val_AUC: 0.0000e+00 - val_accuracy: 0.8366 - val_loss: 0.3185 - val_precision: 1.0000 - val_recall: 0.8366 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9693 - accuracy: 0.9126 - loss: 0.2033 - precision: 0.8883 - recall: 0.8257 - val_AUC: 0.0000e+00 - val_accuracy: 0.8257 - val_loss: 0.3382 - val_precision: 1.0000 - val_recall: 0.8257 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9699 - accuracy: 0.9111 - loss: 0.2036 - precision: 0.8830 - recall: 0.8268 - val_AUC: 0.0000e+00 - val_accuracy: 0.8454 - val_loss: 0.3092 - val_precision: 1.0000 - val_recall: 0.8454 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9680 - accuracy: 0.9111 - loss: 0.2084 - precision: 0.8813 - recall: 0.8290 - val_AUC: 0.0000e+00 - val_accuracy: 0.8396 - val_loss: 0.3187 - val_precision: 1.0000 - val_recall: 0.8396 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9672 - accuracy: 0.9119 - loss: 0.2095 - precision: 0.8864 - recall: 0.8255 - val_AUC: 0.0000e+00 - val_accuracy: 0.8410 - val_loss: 0.3192 - val_precision: 1.0000 - val_recall: 0.8410 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9695 - accuracy: 0.9126 - loss: 0.2044 - precision: 0.8845 - recall: 0.8303 - val_AUC: 0.0000e+00 - val_accuracy: 0.8389 - val_loss: 0.3223 - val_precision: 1.0000 - val_recall: 0.8389 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9699 - accuracy: 0.9152 - loss: 0.2015 - precision: 0.8893 - recall: 0.8341 - val_AUC: 0.0000e+00 - val_accuracy: 0.8308 - val_loss: 0.3396 - val_precision: 1.0000 - val_recall: 0.8308 - learning_rate: 5.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9691 - accuracy: 0.9078 - loss: 0.2052 - precision: 0.8808 - recall: 0.8174 - val_AUC: 0.0000e+00 - val_accuracy: 0.8393 - val_loss: 0.3255 - val_precision: 1.0000 - val_recall: 0.8393 - learning_rate: 5.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9703 - accuracy: 0.9153 - loss: 0.2013 - precision: 0.8871 - recall: 0.8371 - val_AUC: 0.0000e+00 - val_accuracy: 0.8250 - val_loss: 0.3594 - val_precision: 1.0000 - val_recall: 0.8250 - learning_rate: 5.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9681 - accuracy: 0.9106 - loss: 0.2092 - precision: 0.8842 - recall: 0.8236 - val_AUC: 0.0000e+00 - val_accuracy: 0.8355 - val_loss: 0.3538 - val_precision: 1.0000 - val_recall: 0.8355 - learning_rate: 5.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9692 - accuracy: 0.9116 - loss: 0.2046 - precision: 0.8782 - recall: 0.8344 - val_AUC: 0.0000e+00 - val_accuracy: 0.8498 - val_loss: 0.3257 - val_precision: 1.0000 - val_recall: 0.8498 - learning_rate: 5.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9703 - accuracy: 0.9139 - loss: 0.2008 - precision: 0.8837 - recall: 0.8363 - val_AUC: 0.0000e+00 - val_accuracy: 0.8372 - val_loss: 0.3332 - val_precision: 1.0000 - val_recall: 0.8372 - learning_rate: 5.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.9687 - accuracy: 0.9144 - loss: 0.2054 - precision: 0.8863 - recall: 0.8346 - val_AUC: 0.0000e+00 - val_accuracy: 0.8515 - val_loss: 0.2989 - val_precision: 1.0000 - val_recall: 0.8515 - learning_rate: 5.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.9697 - accuracy: 0.9139 - loss: 0.2035 - precision: 0.8830 - recall: 0.8368 - val_AUC: 0.0000e+00 - val_accuracy: 0.8376 - val_loss: 0.3389 - val_precision: 1.0000 - val_recall: 0.8376 - learning_rate: 5.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - AUC: 0.9693 - accuracy: 0.9124 - loss: 0.2049 - precision: 0.8855 - recall: 0.8284 - val_AUC: 0.0000e+00 - val_accuracy: 0.8406 - val_loss: 0.3252 - val_precision: 1.0000 - val_recall: 0.8406 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "\n",
      "==================================================\n",
      "EVALUATION ON ORIGINAL TEST SET\n",
      "==================================================\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "AUC-ROC: 0.787\n",
      "AUC-PR: 0.599\n",
      "Random baseline AUC-PR: 0.177\n",
      "Improvement over random: 3.4x\n",
      "\n",
      "=== THRESHOLD ANALYSIS (RECALL-FOCUSED) ===\n",
      "Threshold 0.01: 1541 flagged (62.7%), Precision 0.245, Recall 0.871, F1 0.383\n",
      "Threshold 0.02: 1373 flagged (55.9%), Precision 0.267, Recall 0.846, F1 0.406\n",
      "Threshold 0.03: 1261 flagged (51.3%), Precision 0.281, Recall 0.816, F1 0.418\n",
      "Threshold 0.04: 1178 flagged (48.0%), Precision 0.292, Recall 0.793, F1 0.427\n",
      "Threshold 0.05: 1125 flagged (45.8%), Precision 0.300, Recall 0.779, F1 0.434\n",
      "Threshold 0.06: 1067 flagged (43.4%), Precision 0.308, Recall 0.758, F1 0.438\n",
      "Threshold 0.07: 1021 flagged (41.6%), Precision 0.314, Recall 0.740, F1 0.441\n",
      "Threshold 0.08:  973 flagged (39.6%), Precision 0.324, Recall 0.726, F1 0.448\n",
      "Threshold 0.09:  922 flagged (37.5%), Precision 0.335, Recall 0.712, F1 0.456\n",
      "Threshold 0.10:  884 flagged (36.0%), Precision 0.337, Recall 0.687, F1 0.452\n",
      "Threshold 0.15:  724 flagged (29.5%), Precision 0.378, Recall 0.631, F1 0.473\n",
      "Threshold 0.20:  642 flagged (26.1%), Precision 0.407, Recall 0.601, F1 0.485\n",
      "Threshold 0.30:  528 flagged (21.5%), Precision 0.460, Recall 0.560, F1 0.505\n",
      "Threshold 0.50:  318 flagged (12.9%), Precision 0.623, Recall 0.456, F1 0.527\n",
      "\n",
      "Best threshold for recall: 0.01 (Recall: 0.871)\n",
      "\n",
      "=== COMPARISON WITH PREVIOUS APPROACHES ===\n",
      "SMOTE-ENN vs Previous Results:\n",
      "Best recall achieved: 0.871 (vs ~0.35 from class weights)\n",
      "AUC-PR: 0.599 (vs 0.174 from no modification)\n",
      "\n",
      "Top 5 thresholds by RECALL (your priority):\n",
      " threshold  flagged_pct  precision   recall       f1\n",
      "      0.01    62.744300   0.245295 0.870968 0.382785\n",
      "      0.02    55.903909   0.267298 0.845622 0.406198\n",
      "      0.03    51.343648   0.280730 0.815668 0.417699\n",
      "      0.04    47.964169   0.292020 0.792627 0.426799\n",
      "      0.05    45.806189   0.300444 0.778802 0.433611\n",
      "\n",
      "Top 5 balanced recall-precision options:\n",
      " threshold  flagged_pct  precision   recall       f1\n",
      "      0.50    12.947883   0.622642 0.456221 0.526596\n",
      "      0.30    21.498371   0.460227 0.559908 0.505198\n",
      "      0.20    26.140065   0.406542 0.601382 0.485130\n",
      "      0.15    29.478827   0.378453 0.631336 0.473230\n",
      "      0.09    37.540717   0.335141 0.711982 0.455752\n",
      "\n",
      "==================================================\n",
      "SMOTE-ENN ANALYSIS COMPLETE\n",
      "==================================================\n",
      "Key takeaways:\n",
      "1. SMOTE-ENN created 4919.0 synthetic positive samples\n",
      "2. Best recall achieved: 0.871\n",
      "3. For your use case (capture more buyers), consider threshold around 0.01\n",
      "4. Ready to compare with ensemble methods next\n"
     ]
    }
   ],
   "source": [
    "# Configure SMOTE-ENN\n",
    "smote_enn = SMOTEENN(\n",
    "    smote=SMOTE(random_state=42, k_neighbors=3),  # Reduced neighbors for small minority class\n",
    "    enn=EditedNearestNeighbours(n_neighbors=3),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply resampling\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Before SMOTE-ENN: {X_train_scaled.shape}, {y_train.value_counts().to_dict()}\")\n",
    "print(f\"After SMOTE-ENN: {X_train_resampled.shape}, {pd.Series(y_train_resampled).value_counts().to_dict()}\")\n",
    "\n",
    "# Calculate the change\n",
    "original_pos = y_train.sum()\n",
    "resampled_pos = pd.Series(y_train_resampled).sum()\n",
    "original_neg = len(y_train) - original_pos\n",
    "resampled_neg = len(y_train_resampled) - resampled_pos\n",
    "\n",
    "print(f\"\\nPositive samples: {original_pos} → {resampled_pos} (added {resampled_pos - original_pos})\")\n",
    "print(f\"Negative samples: {original_neg} → {resampled_neg} (removed {original_neg - resampled_neg})\")\n",
    "\n",
    "# 5. CREATE MODEL\n",
    "def create_model(input_dim, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall', 'AUC']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 6. TRAIN MODEL WITH SMOTE-ENN DATA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING MODEL WITH SMOTE-ENN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_smoteenn = create_model(X_train_resampled.shape[1])\n",
    "\n",
    "# Train on resampled data\n",
    "history_smoteenn = model_smoteenn.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # Split from resampled data\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. EVALUATE ON ORIGINAL TEST SET\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION ON ORIGINAL TEST SET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "y_test_pred_proba = model_smoteenn.predict(X_test_scaled)\n",
    "y_test_pred_proba = y_test_pred_proba.flatten()\n",
    "\n",
    "# Calculate PR-AUC and ROC-AUC\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_test_pred_proba)\n",
    "pr_auc = auc(recall_vals, precision_vals)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "random_baseline = y_test.sum() / len(y_test)\n",
    "\n",
    "print(f\"AUC-ROC: {roc_auc:.3f}\")\n",
    "print(f\"AUC-PR: {pr_auc:.3f}\")\n",
    "print(f\"Random baseline AUC-PR: {random_baseline:.3f}\")\n",
    "print(f\"Improvement over random: {pr_auc/random_baseline:.1f}x\")\n",
    "\n",
    "# 8. THRESHOLD ANALYSIS (focusing on recall for your use case)\n",
    "print(f\"\\n=== THRESHOLD ANALYSIS (RECALL-FOCUSED) ===\")\n",
    "thresholds = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.15, 0.20, 0.30, 0.50]\n",
    "\n",
    "best_recall = 0\n",
    "best_threshold = 0\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_test_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    if y_pred.sum() > 0:  # Avoid division by zero\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        flagged_count = y_pred.sum()\n",
    "        flagged_pct = flagged_count / len(y_test) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'flagged': flagged_count,\n",
    "            'flagged_pct': flagged_pct,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"Threshold {threshold:.2f}: {flagged_count:4d} flagged ({flagged_pct:4.1f}%), \"\n",
    "              f\"Precision {precision:.3f}, Recall {recall:.3f}, F1 {f1:.3f}\")\n",
    "        \n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest threshold for recall: {best_threshold} (Recall: {best_recall:.3f})\")\n",
    "\n",
    "# 9. COMPARE WITH YOUR PREVIOUS RESULTS\n",
    "print(f\"\\n=== COMPARISON WITH PREVIOUS APPROACHES ===\")\n",
    "print(\"SMOTE-ENN vs Previous Results:\")\n",
    "print(f\"Best recall achieved: {best_recall:.3f} (vs ~0.35 from class weights)\")\n",
    "print(f\"AUC-PR: {pr_auc:.3f} (vs 0.174 from no modification)\")\n",
    "\n",
    "# 10. TOP PERFORMERS ANALYSIS\n",
    "results_df = pd.DataFrame(results)\n",
    "# Sort by recall (since that's your priority)\n",
    "top_recall = results_df.nlargest(5, 'recall')\n",
    "print(f\"\\nTop 5 thresholds by RECALL (your priority):\")\n",
    "print(top_recall[['threshold', 'flagged_pct', 'precision', 'recall', 'f1']].to_string(index=False))\n",
    "\n",
    "# Also show balanced options\n",
    "results_df['recall_precision_product'] = results_df['recall'] * results_df['precision']\n",
    "balanced_options = results_df.nlargest(5, 'recall_precision_product')\n",
    "print(f\"\\nTop 5 balanced recall-precision options:\")\n",
    "print(balanced_options[['threshold', 'flagged_pct', 'precision', 'recall', 'f1']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"SMOTE-ENN ANALYSIS COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"Key takeaways:\")\n",
    "print(f\"1. SMOTE-ENN created {resampled_pos - original_pos} synthetic positive samples\")\n",
    "print(f\"2. Best recall achieved: {best_recall:.3f}\")\n",
    "print(f\"3. For your use case (capture more buyers), consider threshold around {best_threshold}\")\n",
    "print(\"4. Ready to compare with ensemble methods next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780af1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
