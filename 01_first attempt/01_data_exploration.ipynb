{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15616ed6",
   "metadata": {},
   "source": [
    "#### Gathering data from database\n",
    "\n",
    "requests; \n",
    "\n",
    " select createdat, deletedat, requestid, tsstart, type, is_passed, leadid from calendar_event\n",
    " where createdat > '2025-03-01'\n",
    " and createdat < '2025-08-15'\n",
    "and type <> 'VACATION'\n",
    "\n",
    "Qualitative info + target column\n",
    "\n",
    "select r.id as requestid, \n",
    "zipregion, r.evaluationtime, r.desiredinstallationend, electricitybill, heatingbill l.mktgparamscore, a.grosscontractsigned,  selfipaimportedat  -- for the two column that are present both in request and lead; request is more filled\n",
    "from  request r left join lead l on l.id = r.leadid left join airtable_contracts a on a.requestid = r.id\n",
    "-----NO TIME CONSTRAINT ON THIS -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db938703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5465b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests new\n",
    "file_path = r\"C:\\Users\\ElifYilmaz\\Downloads\\project 2.0.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06bcd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76097 entries, 0 to 76096\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   createdat  76097 non-null  object\n",
      " 1   deletedat  32987 non-null  object\n",
      " 2   requestid  76097 non-null  int64 \n",
      " 3   tsstart    76097 non-null  object\n",
      " 4   type       76097 non-null  object\n",
      " 5   is_passed  76097 non-null  int64 \n",
      " 6   leadid     76097 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# requests contracts\n",
    "path = r\"C:\\Users\\ElifYilmaz\\Downloads\\project 2.0_contracts.csv\"\n",
    "df2 = pd.read_csv(path)\n",
    "df2.columns = df.columns.str.lower()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4c3d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlapping leadid+tsstart combinations found - safe to concatenate!\n"
     ]
    }
   ],
   "source": [
    "# Check for overlapping IDs\n",
    "df_combinations = df[['leadid', 'tsstart']].drop_duplicates()\n",
    "df2_combinations = df2[['leadid', 'tsstart']].drop_duplicates()\n",
    "overlapping_combinations = pd.merge(df_combinations, df2_combinations, on=['leadid', 'tsstart'], how='inner')\n",
    "\n",
    "if len(overlapping_combinations) > 0:\n",
    "    print(f\"WARNING: Found {len(overlapping_combinations)} overlapping leadid+tsstart combinations:\")\n",
    "    print(overlapping_combinations)\n",
    "    \n",
    "    # Show which specific rows have duplicates\n",
    "    overlap_mask_df = df[['leadid', 'tsstart']].apply(tuple, axis=1).isin(overlapping_combinations[['leadid', 'tsstart']].apply(tuple, axis=1))\n",
    "    overlap_mask_df2 = df2[['leadid', 'tsstart']].apply(tuple, axis=1).isin(overlapping_combinations[['leadid', 'tsstart']].apply(tuple, axis=1))\n",
    "    \n",
    "    print(f\"\\nRows in df with overlapping combinations: {overlap_mask_df.sum()}\")\n",
    "    print(f\"Rows in df2 with overlapping combinations: {overlap_mask_df2.sum()}\")\n",
    "else:\n",
    "    print(\"No overlapping leadid+tsstart combinations found - safe to concatenate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4cd2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df, df2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "417a1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43bcfffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualitative \n",
    "\n",
    "file2 = r\"C:\\Users\\ElifYilmaz\\Downloads\\info client.csv\"\n",
    "\n",
    "df2 = pd.read_csv(file2)\n",
    "df2.columns = df2.columns.str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317f09b",
   "metadata": {},
   "source": [
    "### duplicates in df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a46e2ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of requestids with duplicates: 35\n",
      "Total duplicate rows: 35\n",
      "\n",
      "Dropped 8 absolute duplicate rows\n",
      "\n",
      "Remaining duplicate requestids: 27\n",
      "Number of requestids still with duplicates: 27\n",
      "\n",
      "ðŸ” DIFFERENCES ANALYSIS:\n",
      "==================================================\n",
      "\n",
      "RequestID: 21540\n",
      "------------------------------\n",
      "Columns that differ: ['netcontractsigned']\n",
      " requestid  netcontractsigned\n",
      "     21540                1.0\n",
      "     21540                0.0\n",
      "\n",
      "\n",
      "RequestID: 84726\n",
      "------------------------------\n",
      "Columns that differ: ['netcontractsigned']\n",
      " requestid  netcontractsigned\n",
      "     84726                1.0\n",
      "     84726                0.0\n",
      "\n",
      "\n",
      "RequestID: 86369\n",
      "------------------------------\n",
      "Columns that differ: ['netcontractsigned']\n",
      " requestid  netcontractsigned\n",
      "     86369                1.0\n",
      "     86369                0.0\n",
      "\n",
      "\n",
      "RequestID: 88220\n",
      "------------------------------\n",
      "Columns that differ: ['netcontractsigned']\n",
      " requestid  netcontractsigned\n",
      "     88220                1.0\n",
      "     88220                0.0\n",
      "\n",
      "\n",
      "RequestID: 105757\n",
      "------------------------------\n",
      "Columns that differ: ['netcontractsigned']\n",
      " requestid  netcontractsigned\n",
      "    105757                0.0\n",
      "    105757                1.0\n",
      "\n",
      "... and 22 more duplicate requestids\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count requestids that have duplicates\n",
    "duplicate_requestids = df2[df2['requestid'].duplicated(keep=False)]['requestid'].unique()\n",
    "print(f\"Number of requestids with duplicates: {len(duplicate_requestids)}\")\n",
    "print(f\"Total duplicate rows: {df2['requestid'].duplicated().sum()}\")\n",
    "\n",
    "# Step 2: Drop absolute duplicates (excluding leadid column)\n",
    "comparison_cols = [col for col in df2.columns if col != 'leadid']\n",
    "df2_before = len(df2)\n",
    "df2 = df2.drop_duplicates(subset=comparison_cols, keep='first')\n",
    "df2_after = len(df2)\n",
    "\n",
    "print(f\"\\nDropped {df2_before - df2_after} absolute duplicate rows\")\n",
    "\n",
    "# Step 3: Show differences for remaining duplicate requestids\n",
    "remaining_duplicates = df2[df2['requestid'].duplicated(keep=False)]\n",
    "\n",
    "if len(remaining_duplicates) > 0:\n",
    "    print(f\"\\nRemaining duplicate requestids: {df2['requestid'].duplicated().sum()}\")\n",
    "    print(f\"Number of requestids still with duplicates: {remaining_duplicates['requestid'].nunique()}\")\n",
    "    \n",
    "    # Analyze differences for each duplicate requestid\n",
    "    still_duplicate_ids = remaining_duplicates['requestid'].unique()\n",
    "    \n",
    "    print(f\"\\nðŸ” DIFFERENCES ANALYSIS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for requestid in still_duplicate_ids[:5]:  # Show first 5 to avoid overwhelming output\n",
    "        print(f\"\\nRequestID: {requestid}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Get all rows for this requestid\n",
    "        group = df2[df2['requestid'] == requestid]\n",
    "        \n",
    "        # Find columns that differ across rows\n",
    "        differing_columns = []\n",
    "        for col in df2.columns:\n",
    "            if col != 'requestid':  # Skip the grouping column\n",
    "                unique_values = group[col].nunique()\n",
    "                if unique_values > 1:\n",
    "                    differing_columns.append(col)\n",
    "        \n",
    "        if differing_columns:\n",
    "            print(f\"Columns that differ: {differing_columns}\")\n",
    "            # Show only the differing columns + requestid\n",
    "            cols_to_show = ['requestid'] + differing_columns\n",
    "            print(group[cols_to_show].to_string(index=False))\n",
    "        else:\n",
    "            print(\"No differences found (should not happen)\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if len(still_duplicate_ids) > 5:\n",
    "        print(f\"... and {len(still_duplicate_ids) - 5} more duplicate requestids\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâœ… No remaining duplicates! All duplicates were absolute duplicates and have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# they are in net contrcact signed.. double entries in airtable contracts. will handle in notebook 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3035b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for analysis\n",
    "\n",
    "final_df = df.merge(df2, on='requestid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "221179d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate requestid values: [106800 106797 106801 ... 122658 122670 122706]\n"
     ]
    }
   ],
   "source": [
    "# duplicates in final_df? --> we expect it because now df is a list of transactions.\n",
    "# Show which requestid values appear more than once\n",
    "duplicate_requestids = final_df[final_df['requestid'].duplicated(keep=False)]['requestid'].unique()\n",
    "print(f\"Duplicate requestid values: {duplicate_requestids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5e93e",
   "metadata": {},
   "source": [
    "Explatory checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e09067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "createdat                  object\n",
      "deletedat                  object\n",
      "requestid                   int64\n",
      "tsstart                    object\n",
      "type                       object\n",
      "is_passed                   int64\n",
      "leadid                      int64\n",
      "zipregion                  object\n",
      "evaluationtime             object\n",
      "desiredinstallationend     object\n",
      "electricitybill           float64\n",
      "heatingbill               float64\n",
      "mktgparamscore             object\n",
      "netcontractsigned         float64\n",
      "selfipaimportedat          object\n",
      "dtype: object\n",
      "\n",
      "Any missing values: 249807\n",
      "Shape of dataset: (62491, 15)\n"
     ]
    }
   ],
   "source": [
    "# basic check, correlation can only be checked after encoding since most values are categorical and the rest are entries of happenings\n",
    "\n",
    "# data types\n",
    "print(\"Data types:\")\n",
    "print(final_df.dtypes)\n",
    "print(f\"\\nAny missing values: {final_df.isnull().sum().sum()}\")\n",
    "\n",
    "# shape\n",
    "print(f\"Shape of dataset: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3f7784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "deletedat                 34889\n",
      "zipregion                  3781\n",
      "evaluationtime              643\n",
      "desiredinstallationend      636\n",
      "electricitybill           23251\n",
      "heatingbill               47678\n",
      "mktgparamscore            19820\n",
      "netcontractsigned         60328\n",
      "selfipaimportedat         58781\n",
      "dtype: int64\n",
      "\n",
      "Object columns needing encoding: ['createdat', 'deletedat', 'tsstart', 'type', 'zipregion', 'evaluationtime', 'desiredinstallationend', 'mktgparamscore', 'selfipaimportedat']\n"
     ]
    }
   ],
   "source": [
    "# Check missing values by column\n",
    "print(\"Missing values per column:\")\n",
    "missing_counts = final_df.isnull().sum()\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Check the object columns that need encoding\n",
    "object_cols = final_df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nObject columns needing encoding: {list(object_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cec312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipregion: 20 unique values\n",
      "\n",
      "evaluationtime: 10 unique values\n",
      "  Values: ['3-6 mesi', '<3 mesi', '>6 mesi', 'curious', 'evaluation', 'less_than_three_months', 'more_than_six_months', 'three_to_six_months', 'understand_need', 'understand_purchase']\n",
      "\n",
      "desiredinstallationend: 8 unique values\n",
      "  Values: ['1-2mesi', '3-4mesi', '5+mesi', 'Non lo so', 'dont_know', 'more_than_5_months', 'one_to_two_months', 'three_to_four_months']\n",
      "\n",
      "mktgparamscore: 13 unique values\n",
      "  Values: ['Affiliation', 'Google', 'Mediago', 'Meta', 'Organic', 'Other', 'Outbrain', 'Referral', 'Taboola', 'TikTok', 'Youtube', 'd2d', 'form_classico']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# categorical values\n",
    "# Check unique values in categorical columns\n",
    "for col in ['zipregion', 'evaluationtime', 'desiredinstallationend', 'mktgparamscore']:\n",
    "    unique_count = final_df[col].nunique()\n",
    "    print(f\"{col}: {unique_count} unique values\")\n",
    "    if unique_count < 20:  # Show values if not too many\n",
    "        print(f\"  Values: {sorted(final_df[col].dropna().unique())}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ef57fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rates by missingness:\n",
      "zipregion:\n",
      "  Missing: 0.752 (3781 cases)\n",
      "  Present: 0.763 (58710 cases)\n",
      "\n",
      "evaluationtime:\n",
      "  Missing: 0.153 (643 cases)\n",
      "  Present: 0.779 (61848 cases)\n",
      "\n",
      "desiredinstallationend:\n",
      "  Missing: 0.148 (636 cases)\n",
      "  Present: 0.780 (61855 cases)\n",
      "\n",
      "electricitybill:\n",
      "  Missing: 0.777 (23251 cases)\n",
      "  Present: 0.758 (39240 cases)\n",
      "\n",
      "mktgparamscore:\n",
      "  Missing: 0.786 (19820 cases)\n",
      "  Present: 0.752 (42671 cases)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if missingness patterns relate to conversion\n",
    "print(\"Conversion rates by missingness:\")\n",
    "for col in ['zipregion', 'evaluationtime', 'desiredinstallationend', 'electricitybill', 'mktgparamscore']:\n",
    "    missing_conversion = final_df[final_df[col].isnull()]['netcontractsigned'].mean()\n",
    "    present_conversion = final_df[final_df[col].notnull()]['netcontractsigned'].mean()\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Missing: {missing_conversion:.3f} ({final_df[col].isnull().sum()} cases)\")\n",
    "    print(f\"  Present: {present_conversion:.3f} ({final_df[col].notnull().sum()} cases)\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
