{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c8a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c360d6",
   "metadata": {},
   "source": [
    "#### Exploring final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bbc562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (18140, 44)\n",
      "Columns: ['gross_FU', 'gross_SC', 'net_FU', 'net_SC', 'time_first_sc_to_first_net_fu', 'electricitybill', 'heatingbill', 'netcontractsigned', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'mktgparamscore_missing', 'desiredinstallationend_encoded', 'mktg_High', 'mktg_Low', 'mktg_Medium', 'region_High_Performer', 'region_Large_Good', 'region_Medium', 'region_Other', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'lead_to_sc1_days', 'sc1_schedule_to_appointment_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'showed_up_sc1', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded']\n"
     ]
    }
   ],
   "source": [
    "# Load the saved dataset\n",
    "df = pd.read_csv('processed_data/merged_df.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6edf2001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18140 entries, 0 to 18139\n",
      "Data columns (total 44 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   gross_FU                          18140 non-null  int64  \n",
      " 1   gross_SC                          18140 non-null  int64  \n",
      " 2   net_FU                            18140 non-null  float64\n",
      " 3   net_SC                            18140 non-null  float64\n",
      " 4   time_first_sc_to_first_net_fu     18140 non-null  float64\n",
      " 5   electricitybill                   18140 non-null  float64\n",
      " 6   heatingbill                       18140 non-null  float64\n",
      " 7   netcontractsigned                 18140 non-null  float64\n",
      " 8   selfipa_done                      18140 non-null  int64  \n",
      " 9   zipregion_missing                 18140 non-null  int64  \n",
      " 10  evaluationtime_missing            18140 non-null  int64  \n",
      " 11  desiredinstallationend_missing    18140 non-null  int64  \n",
      " 12  electricitybill_missing           18140 non-null  int64  \n",
      " 13  heatingbill_missing               18140 non-null  int64  \n",
      " 14  mktgparamscore_missing            18140 non-null  int64  \n",
      " 15  desiredinstallationend_encoded    18140 non-null  int64  \n",
      " 16  mktg_High                         18140 non-null  bool   \n",
      " 17  mktg_Low                          18140 non-null  bool   \n",
      " 18  mktg_Medium                       18140 non-null  bool   \n",
      " 19  region_High_Performer             18140 non-null  bool   \n",
      " 20  region_Large_Good                 18140 non-null  bool   \n",
      " 21  region_Medium                     18140 non-null  bool   \n",
      " 22  region_Other                      18140 non-null  bool   \n",
      " 23  total_bc_attempts                 18140 non-null  float64\n",
      " 24  total_bc_outcomes                 18140 non-null  float64\n",
      " 25  lead_to_first_bc_days             18140 non-null  float64\n",
      " 26  bc_duration_days                  18140 non-null  float64\n",
      " 27  lead_to_sc1_days                  18140 non-null  float64\n",
      " 28  sc1_schedule_to_appointment_days  18140 non-null  float64\n",
      " 29  bc_frequency                      18140 non-null  float64\n",
      " 30  positive_outcomes_count           18140 non-null  float64\n",
      " 31  negative_outcomes_count           18140 non-null  float64\n",
      " 32  noshow_outcomes_count             18140 non-null  float64\n",
      " 33  positive_outcome_ratio            18140 non-null  float64\n",
      " 34  negative_outcome_ratio            18140 non-null  float64\n",
      " 35  noshow_outcome_ratio              18140 non-null  float64\n",
      " 36  reachability_score                18140 non-null  float64\n",
      " 37  outcome_trend                     18140 non-null  float64\n",
      " 38  persistence_after_negative        18140 non-null  float64\n",
      " 39  showed_up_sc1                     18140 non-null  float64\n",
      " 40  engagement_score                  18140 non-null  float64\n",
      " 41  efficiency_score                  18140 non-null  float64\n",
      " 42  last_bc_outcome_encoded           18140 non-null  float64\n",
      " 43  first_bc_outcome_encoded          18140 non-null  float64\n",
      "dtypes: bool(7), float64(27), int64(10)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a5c97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts (including NaN):\n",
      " showed_up_sc1\n",
      "0.0    14579\n",
      "1.0     3561\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts_with_nan = df['showed_up_sc1'].value_counts(dropna=False)\n",
    "print(\"Value counts (including NaN):\\n\", value_counts_with_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120118e5",
   "metadata": {},
   "source": [
    "### Data Understanding of this new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf727e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET VARIABLE ANALYSIS ===\n",
      "Total samples: 18140\n",
      "Conversion rate: 0.023\n",
      "Converted: 426\n",
      "Not converted: 17714\n"
     ]
    }
   ],
   "source": [
    "# Check the target variable\n",
    "print(\"=== TARGET VARIABLE ANALYSIS ===\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Conversion rate: {df['netcontractsigned'].mean():.3f}\")\n",
    "print(f\"Converted: {df['netcontractsigned'].sum():.0f}\")\n",
    "print(f\"Not converted: {(len(df) - df['netcontractsigned'].sum()):.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac2cdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPARATION ===\n",
      "Features shape: (18140, 43)\n",
      "Target shape: (18140,)\n",
      "Feature columns: ['gross_FU', 'gross_SC', 'net_FU', 'net_SC', 'time_first_sc_to_first_net_fu', 'electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing']...\n",
      "Any missing values in features: 0\n",
      "Any missing values in target: 0\n"
     ]
    }
   ],
   "source": [
    "# Separate features from target\n",
    "target_column = 'netcontractsigned'\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "print(\"=== DATA PREPARATION ===\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {X.columns.tolist()[:10]}...\")  # Show first 10 columns\n",
    "print(f\"Any missing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Any missing values in target: {y.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50e01b",
   "metadata": {},
   "source": [
    "#### To see any signal at all is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4cbd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN/TEST SPLIT ===\n",
      "Train size: 14512\n",
      "Test size: 3628\n",
      "Train conversion rate: 0.023\n",
      "Test conversion rate: 0.023\n",
      "\n",
      "=== SIGNAL TEST RESULTS ===\n",
      "AUC-ROC Score: 0.880\n",
      "✅ GOOD NEWS: Your features contain useful signal!\n",
      "We can proceed with imbalance fixing strategies.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=== TRAIN/TEST SPLIT ===\")\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")\n",
    "print(f\"Train conversion rate: {y_train.mean():.3f}\")\n",
    "print(f\"Test conversion rate: {y_test.mean():.3f}\")\n",
    "\n",
    "# Scale the features (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a simple logistic regression (NO imbalance handling yet)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Check if there's any signal\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\n=== SIGNAL TEST RESULTS ===\")\n",
    "print(f\"AUC-ROC Score: {auc_score:.3f}\")\n",
    "if auc_score > 0.5:\n",
    "    print(\"✅ GOOD NEWS: Your features contain useful signal!\")\n",
    "    print(\"We can proceed with imbalance fixing strategies.\")\n",
    "else:\n",
    "    print(\"❌ BAD NEWS: No signal detected. Features need work first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b9de2",
   "metadata": {},
   "source": [
    "=== TRAIN/TEST SPLIT ===\n",
    "Train size: 14512\n",
    "Test size: 3628\n",
    "Train conversion rate: 0.023\n",
    "Test conversion rate: 0.023\n",
    "\n",
    "=== SIGNAL TEST RESULTS ===\n",
    "AUC-ROC Score: 0.880\n",
    "✅ GOOD NEWS: Your features contain useful signal!\n",
    "We can proceed with imbalance fixing strategies.\n",
    "\n",
    "however lets take a step further to evaluate imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c14f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DETAILED SIGNAL ANALYSIS ===\n",
      "AUC-ROC: 0.880\n",
      "AUC-PR: 0.174\n",
      "Random baseline AUC-PR: 0.023\n",
      "Improvement over random: 7.4x\n",
      "\n",
      "With 0.5 threshold:\n",
      "Predicted positives: 2\n",
      "Actual positives: 85.0\n",
      "\n",
      "Top 10% analysis:\n",
      "Threshold for top 10%: 0.052\n",
      "Conversion rate in top 10%: 0.132\n",
      "That's 5.6x better than average!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate AUC-PR (more reliable for imbalanced data)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Random baseline for comparison\n",
    "random_baseline = y_test.mean()  # 0.023\n",
    "\n",
    "print(\"\\n=== DETAILED SIGNAL ANALYSIS ===\")\n",
    "print(f\"AUC-ROC: {auc_score:.3f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "print(f\"Random baseline AUC-PR: {random_baseline:.3f}\")\n",
    "print(f\"Improvement over random: {auc_pr/random_baseline:.1f}x\")\n",
    "\n",
    "# Look at actual predictions with default 0.5 threshold\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "print(f\"\\nWith 0.5 threshold:\")\n",
    "print(f\"Predicted positives: {y_pred.sum()}\")\n",
    "print(f\"Actual positives: {y_test.sum()}\")\n",
    "\n",
    "# Check top 10% of predictions\n",
    "top_10_percent_threshold = np.percentile(y_pred_proba, 90)\n",
    "print(f\"\\nTop 10% analysis:\")\n",
    "print(f\"Threshold for top 10%: {top_10_percent_threshold:.3f}\")\n",
    "top_10_mask = y_pred_proba >= top_10_percent_threshold\n",
    "print(f\"Conversion rate in top 10%: {y_test[top_10_mask].mean():.3f}\")\n",
    "print(f\"That's {y_test[top_10_mask].mean()/y_test.mean():.1f}x better than average!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b1528",
   "metadata": {},
   "source": [
    "=== DETAILED SIGNAL ANALYSIS ===\n",
    "AUC-ROC: 0.880\n",
    "AUC-PR: 0.174\n",
    "Random baseline AUC-PR: 0.023\n",
    "Improvement over random: 7.4x\n",
    "\n",
    "With 0.5 threshold:\n",
    "Predicted positives: 2\n",
    "Actual positives: 85.0\n",
    "\n",
    "Top 10% analysis:\n",
    "Threshold for top 10%: 0.052\n",
    "Conversion rate in top 10%: 0.132\n",
    "That's 5.6x better than average!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159f154",
   "metadata": {},
   "source": [
    "## Checking feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52217b3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m.info()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
