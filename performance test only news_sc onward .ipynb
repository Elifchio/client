{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb979381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "609d4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c68c61db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17955 entries, 0 to 17954\n",
      "Data columns (total 41 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   gross_FU                        17955 non-null  int64  \n",
      " 1   gross_SC                        17955 non-null  int64  \n",
      " 2   net_FU                          17955 non-null  float64\n",
      " 3   net_SC                          17955 non-null  float64\n",
      " 4   time_first_sc_to_first_net_fu   17955 non-null  float64\n",
      " 5   electricitybill                 17955 non-null  float64\n",
      " 6   heatingbill                     17955 non-null  float64\n",
      " 7   grosscontractsigned             17955 non-null  float64\n",
      " 8   selfipa_done                    17955 non-null  int64  \n",
      " 9   zipregion_missing               17955 non-null  int64  \n",
      " 10  evaluationtime_missing          17955 non-null  int64  \n",
      " 11  desiredinstallationend_missing  17955 non-null  int64  \n",
      " 12  electricitybill_missing         17955 non-null  int64  \n",
      " 13  heatingbill_missing             17955 non-null  int64  \n",
      " 14  aggregated_missing              17955 non-null  int64  \n",
      " 15  desiredinstallationend_encoded  17955 non-null  int64  \n",
      " 16  mktg_High                       17955 non-null  bool   \n",
      " 17  mktg_Low                        17955 non-null  bool   \n",
      " 18  mktg_Medium                     17955 non-null  bool   \n",
      " 19  region_High_Performer           17955 non-null  bool   \n",
      " 20  region_Large_Solid              17955 non-null  bool   \n",
      " 21  region_Lower                    17955 non-null  bool   \n",
      " 22  region_Medium                   17955 non-null  bool   \n",
      " 23  total_bc_attempts               17955 non-null  int64  \n",
      " 24  total_bc_outcomes               17955 non-null  int64  \n",
      " 25  lead_to_first_bc_days           17955 non-null  float64\n",
      " 26  bc_duration_days                17955 non-null  float64\n",
      " 27  bc_frequency                    17955 non-null  float64\n",
      " 28  positive_outcomes_count         17955 non-null  int64  \n",
      " 29  negative_outcomes_count         17955 non-null  int64  \n",
      " 30  noshow_outcomes_count           17955 non-null  int64  \n",
      " 31  positive_outcome_ratio          17955 non-null  float64\n",
      " 32  negative_outcome_ratio          17955 non-null  float64\n",
      " 33  noshow_outcome_ratio            17955 non-null  float64\n",
      " 34  reachability_score              17955 non-null  float64\n",
      " 35  outcome_trend                   17955 non-null  int64  \n",
      " 36  persistence_after_negative      17955 non-null  int64  \n",
      " 37  engagement_score                17955 non-null  float64\n",
      " 38  efficiency_score                17955 non-null  float64\n",
      " 39  last_bc_outcome_encoded         17955 non-null  int64  \n",
      " 40  first_bc_outcome_encoded        17955 non-null  int64  \n",
      "dtypes: bool(7), float64(15), int64(19)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data\\merged_df_only_after_march.csv')\n",
    "# processed_data\\merged_df_only_after_march.csv is all sc gross + net after march only\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a86b72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[ df[ 'net_SC'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fc63d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grosscontractsigned\n",
       "0.0    10109\n",
       "1.0      590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['grosscontractsigned'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da95b2",
   "metadata": {},
   "source": [
    "# first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af394c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class TwoStageContractPredictor:\n",
    "    \"\"\"\n",
    "    A two-stage model to predict contract signing while handling temporal leakage\n",
    "    and class imbalance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.stage1_model = None\n",
    "        self.stage2_model = None\n",
    "        self.stage1_scaler = StandardScaler()\n",
    "        self.stage2_scaler = StandardScaler()\n",
    "        self.stage1_features = None\n",
    "        self.stage2_features = None\n",
    "\n",
    "    def identify_feature_stages(self, df):\n",
    "        # lowercase dataframe columns\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        stage1_features = [\n",
    "            'electricitybill', 'heatingbill',\n",
    "            'selfipa_done', 'zipregion_missing',\n",
    "            'evaluationtime_missing', 'desiredinstallationend_missing',\n",
    "            'electricitybill_missing', 'heatingbill_missing',\n",
    "            'mktgparamscore_missing', 'desiredinstallationend_encoded',\n",
    "            'mktg_high', 'mktg_low', 'mktg_medium',\n",
    "            'region_high_performer', 'region_large_good',\n",
    "            'region_medium', 'region_other',\n",
    "            'total_bc_attempts', 'total_bc_outcomes',\n",
    "            'lead_to_first_bc_days', 'bc_duration_days',\n",
    "            'bc_frequency', 'positive_outcomes_count',\n",
    "            'negative_outcomes_count', 'noshow_outcomes_count',\n",
    "        \n",
    "            'positive_outcome_ratio', 'negative_outcome_ratio',\n",
    "            'noshow_outcome_ratio', 'reachability_score',\n",
    "            'outcome_trend', 'persistence_after_negative',\n",
    "            'engagement_score', 'efficiency_score',\n",
    "            'last_bc_outcome_encoded', 'first_bc_outcome_encoded'\n",
    "        ]\n",
    "\n",
    "        stage2_features = stage1_features + [\n",
    "            'gross_fu', 'gross_sc', 'net_fu', 'net_sc',\n",
    "            'time_first_sc_to_first_net_fu'\n",
    "        ]\n",
    "\n",
    "        self.stage1_features = [f for f in stage1_features if f in df.columns]\n",
    "        self.stage2_features = [f for f in stage2_features if f in df.columns]\n",
    "        return self.stage1_features, self.stage2_features\n",
    "\n",
    "    def create_stage_labels(self, df):\n",
    "        df.columns = df.columns.str.lower()\n",
    "        stage1_label = (df['net_sc'] > 0).astype(int) if 'net_sc' in df.columns else pd.Series(0, index=df.index)\n",
    "        stage2_label = df['grosscontractsigned']  # already lowercase in your dataset\n",
    "        return stage1_label, stage2_label\n",
    "\n",
    "    def build_neural_network(self, input_dim, name=\"model\"):\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ], name=name)\n",
    "        return model\n",
    "\n",
    "    def handle_imbalance(self, X, y, strategy='hybrid'):\n",
    "        if strategy == 'smote':\n",
    "            smote = SMOTE(random_state=self.random_state)\n",
    "            X_res, y_res = smote.fit_resample(X, y)\n",
    "        elif strategy == 'undersample':\n",
    "            rus = RandomUnderSampler(random_state=self.random_state)\n",
    "            X_res, y_res = rus.fit_resample(X, y)\n",
    "        elif strategy == 'hybrid':\n",
    "            unique, counts = np.unique(y, return_counts=True)\n",
    "            if len(counts) < 2:\n",
    "                X_res, y_res = X, y\n",
    "            else:\n",
    "                minority_count = min(counts)\n",
    "                majority_count = max(counts)\n",
    "                current_ratio = minority_count / majority_count\n",
    "                smote_ratio = min(0.3, current_ratio * 3)\n",
    "                final_ratio = min(0.6, current_ratio * 5)\n",
    "                try:\n",
    "                    pipeline = ImbPipeline([\n",
    "                        ('smote', SMOTE(sampling_strategy=smote_ratio, random_state=self.random_state)),\n",
    "                        ('undersample', RandomUnderSampler(sampling_strategy=final_ratio, random_state=self.random_state))\n",
    "                    ])\n",
    "                    X_res, y_res = pipeline.fit_resample(X, y)\n",
    "                except ValueError:\n",
    "                    smote = SMOTE(sampling_strategy=min(0.3, current_ratio * 2), random_state=self.random_state)\n",
    "                    X_res, y_res = smote.fit_resample(X, y)\n",
    "            return X_res, y_res\n",
    "        return X, y\n",
    "\n",
    "    def train_stage1(self, X_train, y_train, X_val, y_val, epochs=50):\n",
    "        print(\"Training Stage 1...\")\n",
    "        X_train_scaled = self.stage1_scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.stage1_scaler.transform(X_val)\n",
    "        self.stage1_model = self.build_neural_network(X_train_scaled.shape[1], name=\"stage1\")\n",
    "        class_weight = {0: 1., 1: 3.}\n",
    "        self.stage1_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "        self.stage1_model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=epochs, batch_size=32,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "    def train_stage2(self, X_train, y_train, X_val, y_val, epochs=50):\n",
    "        print(\"Training Stage 2...\")\n",
    "        X_train_scaled = self.stage2_scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.stage2_scaler.transform(X_val)\n",
    "        self.stage2_model = self.build_neural_network(X_train_scaled.shape[1], name=\"stage2\")\n",
    "        self.stage2_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "        self.stage2_model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=epochs, batch_size=32,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "    def fit(self, df, epochs_stage1=50, epochs_stage2=50):\n",
    "        self.identify_feature_stages(df)\n",
    "        stage1_label, stage2_label = self.create_stage_labels(df)\n",
    "\n",
    "        # --- Stage 1 ---\n",
    "        X_stage1 = df[self.stage1_features]\n",
    "        X1_train, X1_val, y1_train, y1_val = train_test_split(\n",
    "            X_stage1, stage1_label, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=stage1_label\n",
    "        )\n",
    "        self.train_stage1(X1_train, y1_train, X1_val, y1_val, epochs_stage1)\n",
    "\n",
    "        # --- Stage 2 ---\n",
    "        stage2_mask = stage1_label == 1\n",
    "        X_stage2_filtered = df.loc[stage2_mask, self.stage2_features]\n",
    "        y_stage2_filtered = stage2_label[stage2_mask]\n",
    "\n",
    "        if len(X_stage2_filtered) == 0 or y_stage2_filtered.nunique() < 2:\n",
    "            print(\"\\n⚠️ Skipping Stage 2 training (no SC leads or only one class).\")\n",
    "            self.stage2_model = None\n",
    "            return\n",
    "\n",
    "        X2_train, X2_val, y2_train, y2_val = train_test_split(\n",
    "            X_stage2_filtered, y_stage2_filtered, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=y_stage2_filtered\n",
    "        )\n",
    "        self.train_stage2(X2_train, y2_train, X2_val, y2_val, epochs_stage2)\n",
    "\n",
    "    def predict_proba(self, df):\n",
    "        X_stage1_scaled = self.stage1_scaler.transform(df[self.stage1_features])\n",
    "        p_sc = self.stage1_model.predict(X_stage1_scaled).ravel()\n",
    "\n",
    "        if self.stage2_model is None:\n",
    "            return {\n",
    "                'p_sc': p_sc,\n",
    "                'p_contract_given_sc': np.zeros_like(p_sc),\n",
    "                'p_contract': p_sc  # fallback\n",
    "            }\n",
    "\n",
    "        X_stage2_scaled = self.stage2_scaler.transform(df[self.stage2_features])\n",
    "        p_contract_given_sc = self.stage2_model.predict(X_stage2_scaled).ravel()\n",
    "        p_contract = p_sc * p_contract_given_sc\n",
    "\n",
    "        return {\n",
    "            'p_sc': p_sc,\n",
    "            'p_contract_given_sc': p_contract_given_sc,\n",
    "            'p_contract': p_contract\n",
    "        }\n",
    "\n",
    "    def evaluate(self, df):\n",
    "        predictions = self.predict_proba(df)\n",
    "        y_true = df['grosscontractsigned']\n",
    "        auc_score = roc_auc_score(y_true, predictions['p_contract'])\n",
    "        precision, recall, _ = precision_recall_curve(y_true, predictions['p_contract'])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        print(\"\\n=== Model Evaluation ===\")\n",
    "        print(f\"ROC-AUC: {auc_score:.4f}\")\n",
    "        print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "        return {'roc_auc': auc_score, 'pr_auc': pr_auc, 'predictions': predictions}\n",
    "\n",
    "\n",
    "def main(df):\n",
    "    model = TwoStageContractPredictor(random_state=42)\n",
    "    model.fit(df, epochs_stage1=50, epochs_stage2=50)\n",
    "    results = model.evaluate(df)\n",
    "    predictions = model.predict_proba(df)\n",
    "    df['pred_sc_probability'] = predictions['p_sc']\n",
    "    df['pred_contract_given_sc'] = predictions['p_contract_given_sc']\n",
    "    df['pred_contract_probability'] = predictions['p_contract']\n",
    "    return model, df, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdd1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stage 1...\n",
      "Training Stage 2...\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "=== Model Evaluation ===\n",
      "ROC-AUC: 0.8712\n",
      "PR-AUC: 0.7081\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "model, df_with_predictions, evaluation_results = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f743476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12280 entries, 0 to 12279\n",
      "Data columns (total 44 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   gross_fu                        12280 non-null  int64  \n",
      " 1   gross_sc                        12280 non-null  int64  \n",
      " 2   net_fu                          12280 non-null  float64\n",
      " 3   net_sc                          12280 non-null  float64\n",
      " 4   time_first_sc_to_first_net_fu   12280 non-null  float64\n",
      " 5   electricitybill                 12280 non-null  float64\n",
      " 6   heatingbill                     12280 non-null  float64\n",
      " 7   grosscontractsigned             12280 non-null  float64\n",
      " 8   selfipa_done                    12280 non-null  int64  \n",
      " 9   zipregion_missing               12280 non-null  int64  \n",
      " 10  evaluationtime_missing          12280 non-null  int64  \n",
      " 11  desiredinstallationend_missing  12280 non-null  int64  \n",
      " 12  electricitybill_missing         12280 non-null  int64  \n",
      " 13  heatingbill_missing             12280 non-null  int64  \n",
      " 14  aggregated_missing              12280 non-null  int64  \n",
      " 15  desiredinstallationend_encoded  12280 non-null  int64  \n",
      " 16  mktg_high                       12280 non-null  bool   \n",
      " 17  mktg_low                        12280 non-null  bool   \n",
      " 18  mktg_medium                     12280 non-null  bool   \n",
      " 19  region_high_performer           12280 non-null  bool   \n",
      " 20  region_large_solid              12280 non-null  bool   \n",
      " 21  region_lower                    12280 non-null  bool   \n",
      " 22  region_medium                   12280 non-null  bool   \n",
      " 23  total_bc_attempts               12280 non-null  int64  \n",
      " 24  total_bc_outcomes               12280 non-null  int64  \n",
      " 25  lead_to_first_bc_days           12280 non-null  float64\n",
      " 26  bc_duration_days                12280 non-null  float64\n",
      " 27  bc_frequency                    12280 non-null  float64\n",
      " 28  positive_outcomes_count         12280 non-null  int64  \n",
      " 29  negative_outcomes_count         12280 non-null  int64  \n",
      " 30  noshow_outcomes_count           12280 non-null  int64  \n",
      " 31  positive_outcome_ratio          12280 non-null  float64\n",
      " 32  negative_outcome_ratio          12280 non-null  float64\n",
      " 33  noshow_outcome_ratio            12280 non-null  float64\n",
      " 34  reachability_score              12280 non-null  float64\n",
      " 35  outcome_trend                   12280 non-null  int64  \n",
      " 36  persistence_after_negative      12280 non-null  int64  \n",
      " 37  engagement_score                12280 non-null  float64\n",
      " 38  efficiency_score                12280 non-null  float64\n",
      " 39  last_bc_outcome_encoded         12280 non-null  int64  \n",
      " 40  first_bc_outcome_encoded        12280 non-null  int64  \n",
      " 41  pred_sc_probability             12280 non-null  float32\n",
      " 42  pred_contract_given_sc          12280 non-null  float32\n",
      " 43  pred_contract_probability       12280 non-null  float32\n",
      "dtypes: bool(7), float32(3), float64(15), int64(19)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5922d8",
   "metadata": {},
   "source": [
    "comparing different models, after sc only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49efd86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12280, 43)\n",
      "Target distribution: grosscontractsigned\n",
      "0.0    10109\n",
      "1.0     2171\n",
      "Name: count, dtype: int64\n",
      "Imbalance ratio: 4.7:1\n",
      "Train set: 9824 samples\n",
      "Test set: 2456 samples\n",
      "Train target distribution: grosscontractsigned\n",
      "0.0    8087\n",
      "1.0    1737\n",
      "Name: count, dtype: int64\n",
      "Test target distribution: grosscontractsigned\n",
      "0.0    2022\n",
      "1.0     434\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "RANDOM FOREST\n",
      "==================================================\n",
      "TRAIN vs TEST COMPARISON:\n",
      "Train ROC-AUC: 0.9997\n",
      "Test ROC-AUC:  0.8646\n",
      "Difference:    0.1352\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.96      0.93      2022\n",
      "         1.0       0.74      0.49      0.59       434\n",
      "\n",
      "    accuracy                           0.88      2456\n",
      "   macro avg       0.82      0.73      0.76      2456\n",
      "weighted avg       0.87      0.88      0.87      2456\n",
      "\n",
      "ROC-AUC: 0.8646\n",
      "PR-AUC: 0.7014\n",
      "\n",
      "==================================================\n",
      "XGBOOST\n",
      "==================================================\n",
      "XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94      2022\n",
      "         1.0       0.81      0.56      0.66       434\n",
      "\n",
      "    accuracy                           0.90      2456\n",
      "   macro avg       0.86      0.76      0.80      2456\n",
      "weighted avg       0.89      0.90      0.89      2456\n",
      "\n",
      "ROC-AUC: 0.8706\n",
      "PR-AUC: 0.7400\n",
      "\n",
      "XGBoost TRAIN vs TEST Comparison:\n",
      "========================================\n",
      "Train ROC-AUC: 0.9923\n",
      "Test ROC-AUC:  0.8706\n",
      "Train PR-AUC:  0.9733\n",
      "Test PR-AUC:   0.7400\n",
      "ROC-AUC Difference (Train - Test): +0.1217\n",
      "⚠️  Possible overfitting detected\n",
      "\n",
      "==================================================\n",
      "NEURAL NETWORK\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Neural Network Results - TRAIN vs TEST Comparison:\n",
      "============================================================\n",
      "\n",
      "TRAINING SET PERFORMANCE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.95      8087\n",
      "         1.0       0.89      0.54      0.67      1737\n",
      "\n",
      "    accuracy                           0.91      9824\n",
      "   macro avg       0.90      0.76      0.81      9824\n",
      "weighted avg       0.91      0.91      0.90      9824\n",
      "\n",
      "Train ROC-AUC: 0.9194\n",
      "Train PR-AUC:  0.7955\n",
      "\n",
      "TEST SET PERFORMANCE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.93      2022\n",
      "         1.0       0.76      0.41      0.53       434\n",
      "\n",
      "    accuracy                           0.87      2456\n",
      "   macro avg       0.82      0.69      0.73      2456\n",
      "weighted avg       0.86      0.87      0.86      2456\n",
      "\n",
      "Test ROC-AUC:  0.8048\n",
      "Test PR-AUC:   0.6228\n",
      "\n",
      "TRAIN vs TEST DIFFERENCE:\n",
      "ROC-AUC Difference (Train - Test): +0.1147\n",
      "PR-AUC Difference (Train - Test):  +0.1727\n",
      "\n",
      "==================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn_pred_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 186\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m    182\u001b[39m models = [\u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNeural Network\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    183\u001b[39m roc_aucs = [\n\u001b[32m    184\u001b[39m     roc_auc_score(y_test, rf_pred_proba),\n\u001b[32m    185\u001b[39m     roc_auc_score(y_test, xgb_pred_proba),\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     roc_auc_score(y_test, \u001b[43mnn_pred_proba\u001b[49m)\n\u001b[32m    187\u001b[39m ]\n\u001b[32m    188\u001b[39m pr_aucs = [\n\u001b[32m    189\u001b[39m     average_precision_score(y_test, rf_pred_proba),\n\u001b[32m    190\u001b[39m     average_precision_score(y_test, xgb_pred_proba),\n\u001b[32m    191\u001b[39m     average_precision_score(y_test, nn_pred_proba)\n\u001b[32m    192\u001b[39m ]\n\u001b[32m    194\u001b[39m comparison_df = pd.DataFrame({\n\u001b[32m    195\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m: models,\n\u001b[32m    196\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mROC-AUC\u001b[39m\u001b[33m'\u001b[39m: roc_aucs,\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPR-AUC\u001b[39m\u001b[33m'\u001b[39m: pr_aucs\n\u001b[32m    198\u001b[39m })\n",
      "\u001b[31mNameError\u001b[39m: name 'nn_pred_proba' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is called 'df' and target is 'grosscontractsigend'\n",
    "# Separate features and target\n",
    "X = df.drop('grosscontractsigned', axis=1)\n",
    "y = df['grosscontractsigned']\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts()}\")\n",
    "print(f\"Imbalance ratio: {y.value_counts()[0]/y.value_counts()[1]:.1f}:1\")\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Train target distribution: {y_train.value_counts()}\")\n",
    "print(f\"Test target distribution: {y_test.value_counts()}\")\n",
    "\n",
    "# Scale features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. RANDOM FOREST\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Example for Random Forest\n",
    "rf_train_pred = rf.predict(X_train)\n",
    "rf_train_pred_proba = rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"TRAIN vs TEST COMPARISON:\")\n",
    "print(f\"Train ROC-AUC: {roc_auc_score(y_train, rf_train_pred_proba):.4f}\")\n",
    "print(f\"Test ROC-AUC:  {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n",
    "print(f\"Difference:    {roc_auc_score(y_train, rf_train_pred_proba) - roc_auc_score(y_test, rf_pred_proba):.4f}\")\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n",
    "print(f\"PR-AUC: {average_precision_score(y_test, rf_pred_proba):.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. XGBOOST\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"XGBOOST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost Results:\")\n",
    "print(classification_report(y_test, xgb_pred))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, xgb_pred_proba):.4f}\")\n",
    "print(f\"PR-AUC: {average_precision_score(y_test, xgb_pred_proba):.4f}\")\n",
    "\n",
    "# Get training set predictions for comparison\n",
    "xgb_train_pred = xgb_model.predict(X_train)\n",
    "xgb_train_pred_proba = xgb_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"\\nXGBoost TRAIN vs TEST Comparison:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Train ROC-AUC: {roc_auc_score(y_train, xgb_train_pred_proba):.4f}\")\n",
    "print(f\"Test ROC-AUC:  {roc_auc_score(y_test, xgb_pred_proba):.4f}\")\n",
    "print(f\"Train PR-AUC:  {average_precision_score(y_train, xgb_train_pred_proba):.4f}\")\n",
    "print(f\"Test PR-AUC:   {average_precision_score(y_test, xgb_pred_proba):.4f}\")\n",
    "\n",
    "roc_diff = roc_auc_score(y_train, xgb_train_pred_proba) - roc_auc_score(y_test, xgb_pred_proba)\n",
    "print(f\"ROC-AUC Difference (Train - Test): {roc_diff:+.4f}\")\n",
    "\n",
    "if roc_diff > 0.05:\n",
    "    print(\"⚠️  Possible overfitting detected\")\n",
    "else:\n",
    "    print(\"✅ Good generalization\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. NEURAL NETWORK\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEURAL NETWORK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Build feedforward network\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get predictions for both train and test sets\n",
    "nn_train_pred_proba = nn_model.predict(X_train_scaled).flatten()\n",
    "nn_train_pred = (nn_train_pred_proba > 0.5).astype(int)\n",
    "\n",
    "nn_test_pred_proba = nn_model.predict(X_test_scaled).flatten()\n",
    "nn_test_pred = (nn_test_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_roc_auc = roc_auc_score(y_train, nn_train_pred_proba)\n",
    "train_pr_auc = average_precision_score(y_train, nn_train_pred_proba)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_roc_auc = roc_auc_score(y_test, nn_test_pred_proba)\n",
    "test_pr_auc = average_precision_score(y_test, nn_test_pred_proba)\n",
    "\n",
    "print(\"Neural Network Results - TRAIN vs TEST Comparison:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTRAINING SET PERFORMANCE:\")\n",
    "print(classification_report(y_train, nn_train_pred))\n",
    "print(f\"Train ROC-AUC: {train_roc_auc:.4f}\")\n",
    "print(f\"Train PR-AUC:  {train_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(classification_report(y_test, nn_test_pred))\n",
    "print(f\"Test ROC-AUC:  {test_roc_auc:.4f}\")\n",
    "print(f\"Test PR-AUC:   {test_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\nTRAIN vs TEST DIFFERENCE:\")\n",
    "print(f\"ROC-AUC Difference (Train - Test): {train_roc_auc - test_roc_auc:+.4f}\")\n",
    "print(f\"PR-AUC Difference (Train - Test):  {train_pr_auc - test_pr_auc:+.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPARISON SUMMARY\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "models = ['Random Forest', 'XGBoost', 'Neural Network']\n",
    "roc_aucs = [\n",
    "    roc_auc_score(y_test, rf_pred_proba),\n",
    "    roc_auc_score(y_test, xgb_pred_proba),\n",
    "    roc_auc_score(y_test, nn_pred_proba)\n",
    "]\n",
    "pr_aucs = [\n",
    "    average_precision_score(y_test, rf_pred_proba),\n",
    "    average_precision_score(y_test, xgb_pred_proba),\n",
    "    average_precision_score(y_test, nn_pred_proba)\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'ROC-AUC': roc_aucs,\n",
    "    'PR-AUC': pr_aucs\n",
    "})\n",
    "\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# ROC Curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_pred_proba)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_pred_proba)\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, nn_pred_proba)\n",
    "\n",
    "ax1.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_aucs[0]:.3f})')\n",
    "ax1.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {roc_aucs[1]:.3f})')\n",
    "ax1.plot(fpr_nn, tpr_nn, label=f'Neural Network (AUC = {roc_aucs[2]:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curves')\n",
    "ax1.legend()\n",
    "\n",
    "# Precision-Recall Curves\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, rf_pred_proba)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_test, xgb_pred_proba)\n",
    "precision_nn, recall_nn, _ = precision_recall_curve(y_test, nn_pred_proba)\n",
    "\n",
    "ax2.plot(recall_rf, precision_rf, label=f'Random Forest (PR-AUC = {pr_aucs[0]:.3f})')\n",
    "ax2.plot(recall_xgb, precision_xgb, label=f'XGBoost (PR-AUC = {pr_aucs[1]:.3f})')\n",
    "ax2.plot(recall_nn, precision_nn, label=f'Neural Network (PR-AUC = {pr_aucs[2]:.3f})')\n",
    "ax2.axhline(y=y_test.mean(), color='k', linestyle='--', label=f'Random ({y_test.mean():.3f})')\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curves')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for tree-based models\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FEATURE IMPORTANCE (Random Forest)\")\n",
    "print(\"=\"*30)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FEATURE IMPORTANCE (XGBoost)\")\n",
    "print(\"=\"*30)\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance_xgb.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35059efe",
   "metadata": {},
   "source": [
    "Deeper on two layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a8c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now our dataaset is merged_df that has aòso peolpe who havent made it to net sc\n",
    "df2= pd.read_csv(\"processed_data/merged_df_only_after_march.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25cfed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "class TwoStageContractPredictor:\n",
    "    \"\"\"\n",
    "    Two-stage funnel model:\n",
    "    Stage 1: Predict probability of reaching SC\n",
    "    Stage 2: Predict probability of signing given SC\n",
    "    Final probability = p_sc * p_contract_given_sc\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.stage1_model = None\n",
    "        self.stage2_model = None\n",
    "        self.stage1_scaler = StandardScaler()\n",
    "        self.stage2_scaler = StandardScaler()\n",
    "        self.stage1_features = None\n",
    "        self.stage2_features = None\n",
    "\n",
    "    def identify_feature_stages(self, df):\n",
    "        \"\"\"Define features by stage (case-insensitive).\"\"\"\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        stage1_features = [\n",
    "            # Lead-level features (pre-SC)\n",
    "            'electricitybill', 'heatingbill',\n",
    "            'selfipa_done', 'zipregion_missing',\n",
    "            'evaluationtime_missing', 'desiredinstallationend_missing',\n",
    "            'electricitybill_missing', 'heatingbill_missing',\n",
    "            'mktgparamscore_missing', 'desiredinstallationend_encoded',\n",
    "            'mktg_high', 'mktg_low', 'mktg_medium',\n",
    "            'region_high_performer', 'region_large_good',\n",
    "            'region_medium', 'region_other',\n",
    "            'total_bc_attempts', 'total_bc_outcomes',\n",
    "            'lead_to_first_bc_days', 'bc_duration_days',\n",
    "            'bc_frequency', 'positive_outcomes_count',\n",
    "            'negative_outcomes_count', 'noshow_outcomes_count',\n",
    "            'positive_outcome_ratio', 'negative_outcome_ratio',\n",
    "            'noshow_outcome_ratio', 'reachability_score',\n",
    "            'outcome_trend', 'persistence_after_negative',\n",
    "            'engagement_score', 'efficiency_score',\n",
    "            'last_bc_outcome_encoded', 'first_bc_outcome_encoded'\n",
    "        ]\n",
    "\n",
    "        stage2_features = stage1_features + [\n",
    "            # SC-related features (available only post-SC)\n",
    "            'gross_fu', 'gross_sc', 'net_fu', 'net_sc',\n",
    "            'time_first_sc_to_first_net_fu'\n",
    "        ]\n",
    "\n",
    "        self.stage1_features = [f for f in stage1_features if f in df.columns]\n",
    "        self.stage2_features = [f for f in stage2_features if f in df.columns]\n",
    "\n",
    "        print(\"Stage 1 features used:\", self.stage1_features)\n",
    "        print(\"Stage 2 features used:\", self.stage2_features)\n",
    "\n",
    "        return self.stage1_features, self.stage2_features\n",
    "\n",
    "    def create_stage_labels(self, df):\n",
    "        \"\"\"Create labels for each stage.\"\"\"\n",
    "        df.columns = df.columns.str.lower()\n",
    "        stage1_label = (df['net_sc'] > 0).astype(int) if 'net_sc' in df.columns else pd.Series(0, index=df.index)\n",
    "        stage2_label = df['grosscontractsigned']\n",
    "        return stage1_label, stage2_label\n",
    "\n",
    "    def build_neural_network(self, input_dim, name=\"model\"):\n",
    "        \"\"\"Simple dense NN.\"\"\"\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ], name=name)\n",
    "        return model\n",
    "\n",
    "    def train_stage1(self, X_train, y_train, X_val, y_val, epochs=50):\n",
    "        print(\"\\nTraining Stage 1 (Predicting SC)...\")\n",
    "        X_train_scaled = self.stage1_scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.stage1_scaler.transform(X_val)\n",
    "        self.stage1_model = self.build_neural_network(X_train_scaled.shape[1], name=\"stage1\")\n",
    "        class_weight = {0: 1., 1: 3.}  # weight SC positives more\n",
    "        self.stage1_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "        self.stage1_model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=epochs, batch_size=32,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "    def train_stage2(self, X_train, y_train, X_val, y_val, epochs=50):\n",
    "        print(\"\\nTraining Stage 2 (Predicting Contract given SC)...\")\n",
    "        X_train_scaled = self.stage2_scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.stage2_scaler.transform(X_val)\n",
    "        self.stage2_model = self.build_neural_network(X_train_scaled.shape[1], name=\"stage2\")\n",
    "        self.stage2_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "        self.stage2_model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=epochs, batch_size=32,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "    def fit(self, df, epochs_stage1=50, epochs_stage2=50):\n",
    "        \"\"\"Train the two-stage funnel model.\"\"\"\n",
    "        self.identify_feature_stages(df)\n",
    "        stage1_label, stage2_label = self.create_stage_labels(df)\n",
    "\n",
    "        # --- Stage 1 ---\n",
    "        X_stage1 = df[self.stage1_features]\n",
    "        X1_train, X1_val, y1_train, y1_val = train_test_split(\n",
    "            X_stage1, stage1_label, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=stage1_label\n",
    "        )\n",
    "        self.train_stage1(X1_train, y1_train, X1_val, y1_val, epochs_stage1)\n",
    "\n",
    "        # --- Stage 2 ---\n",
    "        stage2_mask = stage1_label == 1\n",
    "        X_stage2_filtered = df.loc[stage2_mask, self.stage2_features]\n",
    "        y_stage2_filtered = stage2_label[stage2_mask]\n",
    "\n",
    "        if len(X_stage2_filtered) == 0 or y_stage2_filtered.nunique() < 2:\n",
    "            print(\"\\n⚠️ Skipping Stage 2 (no SC leads or only one class).\")\n",
    "            self.stage2_model = None\n",
    "            return\n",
    "\n",
    "        X2_train, X2_val, y2_train, y2_val = train_test_split(\n",
    "            X_stage2_filtered, y_stage2_filtered, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=y_stage2_filtered\n",
    "        )\n",
    "        self.train_stage2(X2_train, y2_train, X2_val, y2_val, epochs_stage2)\n",
    "\n",
    "    def predict_proba(self, df):\n",
    "        \"\"\"Generate probabilities for SC, contract given SC, and overall.\"\"\"\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # Stage 1\n",
    "        X_stage1_scaled = self.stage1_scaler.transform(df[self.stage1_features])\n",
    "        p_sc = self.stage1_model.predict(X_stage1_scaled).ravel()\n",
    "\n",
    "        # Stage 2\n",
    "        if self.stage2_model is None:\n",
    "            return {'p_sc': p_sc,\n",
    "                    'p_contract_given_sc': np.zeros_like(p_sc),\n",
    "                    'p_contract': p_sc}  # fallback\n",
    "\n",
    "        X_stage2_scaled = self.stage2_scaler.transform(df[self.stage2_features])\n",
    "        p_contract_given_sc = self.stage2_model.predict(X_stage2_scaled).ravel()\n",
    "        p_contract = p_sc * p_contract_given_sc\n",
    "\n",
    "        return {'p_sc': p_sc,\n",
    "                'p_contract_given_sc': p_contract_given_sc,\n",
    "                'p_contract': p_contract}\n",
    "\n",
    "    def evaluate(self, df):\n",
    "        \"\"\"Evaluate full model performance.\"\"\"\n",
    "        predictions = self.predict_proba(df)\n",
    "        y_true = df['grosscontractsigned']\n",
    "        auc_score = roc_auc_score(y_true, predictions['p_contract'])\n",
    "        precision, recall, _ = precision_recall_curve(y_true, predictions['p_contract'])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        print(\"\\n=== Model Evaluation ===\")\n",
    "        print(f\"ROC-AUC: {auc_score:.4f}\")\n",
    "        print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "        return {'roc_auc': auc_score, 'pr_auc': pr_auc, 'predictions': predictions}\n",
    "\n",
    "\n",
    "def main(df):\n",
    "    model = TwoStageContractPredictor(random_state=42)\n",
    "    model.fit(df, epochs_stage1=50, epochs_stage2=50)\n",
    "    results = model.evaluate(df)\n",
    "    predictions = model.predict_proba(df)\n",
    "    df['pred_sc_probability'] = predictions['p_sc']\n",
    "    df['pred_contract_given_sc'] = predictions['p_contract_given_sc']\n",
    "    df['pred_contract_probability'] = predictions['p_contract']\n",
    "    return model, df, results\n",
    "\n",
    "def evaluate_stage2_only(df_with_predictions):\n",
    "    \"\"\"Evaluate Stage 2 (conversion given SC) separately.\"\"\"\n",
    "    mask = df_with_predictions['net_sc'] > 0\n",
    "    y_true_sc = df_with_predictions.loc[mask, 'grosscontractsigned']\n",
    "    y_pred_sc = df_with_predictions.loc[mask, 'pred_contract_given_sc']\n",
    "\n",
    "    if len(y_true_sc) == 0 or y_true_sc.nunique() < 2:\n",
    "        print(\"⚠️ No valid SC leads for Stage 2 evaluation.\")\n",
    "        return None\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc_sc = roc_auc_score(y_true_sc, y_pred_sc)\n",
    "\n",
    "    # PR-AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_true_sc, y_pred_sc)\n",
    "    pr_auc_sc = auc(recall, precision)\n",
    "\n",
    "    print(\"\\n=== Stage 2 Evaluation (only SC leads) ===\")\n",
    "    print(f\"ROC-AUC (Stage 2): {roc_auc_sc:.4f}\")\n",
    "    print(f\"PR-AUC  (Stage 2): {pr_auc_sc:.4f}\")\n",
    "\n",
    "    return {\"roc_auc_stage2\": roc_auc_sc, \"pr_auc_stage2\": pr_auc_sc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146138eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded']\n",
      "Stage 2 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded', 'gross_fu', 'gross_sc', 'net_fu', 'net_sc', 'time_first_sc_to_first_net_fu']\n",
      "\n",
      "Training Stage 1 (Predicting SC)...\n",
      "\n",
      "Training Stage 2 (Predicting Contract given SC)...\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step\n",
      "\n",
      "=== Model Evaluation ===\n",
      "ROC-AUC: 0.6078\n",
      "PR-AUC: 0.1032\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step\n"
     ]
    }
   ],
   "source": [
    "model, df_with_predictions, evaluation_results = main(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea42c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded']\n",
      "Stage 2 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded', 'gross_fu', 'gross_sc', 'net_fu', 'net_sc', 'time_first_sc_to_first_net_fu']\n",
      "\n",
      "Training Stage 1 (Predicting SC)...\n",
      "\n",
      "Training Stage 2 (Predicting Contract given SC)...\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "=== Model Evaluation ===\n",
      "ROC-AUC: 0.6551\n",
      "PR-AUC: 0.2035\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "=== Stage 2 Evaluation (only SC leads) ===\n",
      "ROC-AUC (Stage 2): 0.8196\n",
      "PR-AUC  (Stage 2): 0.3188\n"
     ]
    }
   ],
   "source": [
    "model, df_with_predictions, evaluation_results = main(df2)\n",
    "stage2_eval = evaluate_stage2_only(df_with_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec6c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.19760677\n",
      "Precision: 0.33226837060702874\n",
      "Recall: 0.3525423728813559\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true_sc, y_pred_sc)\n",
    "f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "best_idx = np.argmax(f1)\n",
    "print(\"Best threshold:\", thresholds[best_idx])\n",
    "print(\"Precision:\", precision[best_idx])\n",
    "print(\"Recall:\", recall[best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205e328",
   "metadata": {},
   "source": [
    "🔥 Full Two-Stage Funnel Model (with switchable Stage 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21158016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class TwoStageContractPredictorFlexible:\n",
    "    \"\"\"\n",
    "    Two-stage funnel model with flexible Stage 2 backend (NN or XGBoost).\n",
    "    Stage 1: Predict SC probability\n",
    "    Stage 2: Predict contract probability given SC\n",
    "    Final probability = p_sc * p_contract_given_sc\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stage2_type=\"nn\", random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.stage2_type = stage2_type  # \"nn\" or \"xgb\"\n",
    "        self.stage1_model = None\n",
    "        self.stage2_model = None\n",
    "        self.stage1_scaler = StandardScaler()\n",
    "        self.stage2_scaler = StandardScaler() if stage2_type == \"nn\" else None\n",
    "        self.stage1_features = None\n",
    "        self.stage2_features = None\n",
    "\n",
    "    def identify_feature_stages(self, df):\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        stage1_features = [\n",
    "            'electricitybill', 'heatingbill',\n",
    "            'selfipa_done', 'zipregion_missing',\n",
    "            'evaluationtime_missing', 'desiredinstallationend_missing',\n",
    "            'electricitybill_missing', 'heatingbill_missing',\n",
    "            'mktgparamscore_missing', 'desiredinstallationend_encoded',\n",
    "            'mktg_high', 'mktg_low', 'mktg_medium',\n",
    "            'region_high_performer', 'region_large_good',\n",
    "            'region_medium', 'region_other',\n",
    "            'total_bc_attempts', 'total_bc_outcomes',\n",
    "            'lead_to_first_bc_days', 'bc_duration_days',\n",
    "            'bc_frequency', 'positive_outcomes_count',\n",
    "            'negative_outcomes_count', 'noshow_outcomes_count',\n",
    "            'positive_outcome_ratio', 'negative_outcome_ratio',\n",
    "            'noshow_outcome_ratio', 'reachability_score',\n",
    "            'outcome_trend', 'persistence_after_negative',\n",
    "            'engagement_score', 'efficiency_score',\n",
    "            'last_bc_outcome_encoded', 'first_bc_outcome_encoded'\n",
    "        ]\n",
    "\n",
    "        stage2_features = stage1_features + [\n",
    "            'gross_fu', 'gross_sc', 'net_fu', 'net_sc',\n",
    "            'time_first_sc_to_first_net_fu'\n",
    "        ]\n",
    "\n",
    "        self.stage1_features = [f for f in stage1_features if f in df.columns]\n",
    "        self.stage2_features = [f for f in stage2_features if f in df.columns]\n",
    "\n",
    "        print(\"Stage 1 features used:\", self.stage1_features)\n",
    "        print(\"Stage 2 features used:\", self.stage2_features)\n",
    "\n",
    "    def create_stage_labels(self, df):\n",
    "        df.columns = df.columns.str.lower()\n",
    "        stage1_label = (df['net_sc'] > 0).astype(int) if 'net_sc' in df.columns else pd.Series(0, index=df.index)\n",
    "        stage2_label = df['grosscontractsigned']\n",
    "        return stage1_label, stage2_label\n",
    "\n",
    "    def build_neural_network(self, input_dim, name=\"model\"):\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ], name=name)\n",
    "        return model\n",
    "\n",
    "    def train_stage1(self, X_train, y_train, X_val, y_val, epochs=50):\n",
    "        print(\"\\nTraining Stage 1 (Predicting SC)...\")\n",
    "        X_train_scaled = self.stage1_scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.stage1_scaler.transform(X_val)\n",
    "        self.stage1_model = self.build_neural_network(X_train_scaled.shape[1], name=\"stage1\")\n",
    "        class_weight = {0: 1., 1: 3.}\n",
    "        self.stage1_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "        self.stage1_model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=epochs, batch_size=32,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "    def train_stage2(self, X_train, y_train, X_val, y_val, epochs=50):\n",
    "        print(f\"\\nTraining Stage 2 (Predicting Contract given SC) using {self.stage2_type.upper()}...\")\n",
    "        if self.stage2_type == \"nn\":\n",
    "            X_train_scaled = self.stage2_scaler.fit_transform(X_train)\n",
    "            X_val_scaled = self.stage2_scaler.transform(X_val)\n",
    "            self.stage2_model = self.build_neural_network(X_train_scaled.shape[1], name=\"stage2\")\n",
    "            self.stage2_model.compile(\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "            early_stop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "            self.stage2_model.fit(\n",
    "                X_train_scaled, y_train,\n",
    "                validation_data=(X_val_scaled, y_val),\n",
    "                epochs=epochs, batch_size=32,\n",
    "                callbacks=[early_stop], verbose=0\n",
    "            )\n",
    "        elif self.stage2_type == \"xgb\":\n",
    "            self.stage2_model = xgb.XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                eval_metric=\"auc\",\n",
    "                random_state=self.random_state,\n",
    "                use_label_encoder=False\n",
    "            )\n",
    "            self.stage2_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    def fit(self, df, epochs_stage1=50, epochs_stage2=50):\n",
    "        self.identify_feature_stages(df)\n",
    "        stage1_label, stage2_label = self.create_stage_labels(df)\n",
    "\n",
    "        # Stage 1\n",
    "        X_stage1 = df[self.stage1_features]\n",
    "        X1_train, X1_val, y1_train, y1_val = train_test_split(\n",
    "            X_stage1, stage1_label, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=stage1_label\n",
    "        )\n",
    "        self.train_stage1(X1_train, y1_train, X1_val, y1_val, epochs_stage1)\n",
    "\n",
    "        # Stage 2\n",
    "        stage2_mask = stage1_label == 1\n",
    "        X_stage2_filtered = df.loc[stage2_mask, self.stage2_features]\n",
    "        y_stage2_filtered = stage2_label[stage2_mask]\n",
    "        if len(X_stage2_filtered) == 0 or y_stage2_filtered.nunique() < 2:\n",
    "            print(\"\\n⚠️ Skipping Stage 2 (no SC leads or only one class).\")\n",
    "            self.stage2_model = None\n",
    "            return\n",
    "        X2_train, X2_val, y2_train, y2_val = train_test_split(\n",
    "            X_stage2_filtered, y_stage2_filtered, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=y_stage2_filtered\n",
    "        )\n",
    "        self.train_stage2(X2_train, y2_train, X2_val, y2_val, epochs_stage2)\n",
    "\n",
    "    def predict_proba(self, df):\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # Stage 1\n",
    "        X_stage1_scaled = self.stage1_scaler.transform(df[self.stage1_features])\n",
    "        p_sc = self.stage1_model.predict(X_stage1_scaled).ravel()\n",
    "\n",
    "        # Stage 2\n",
    "        if self.stage2_model is None:\n",
    "            return {\"p_sc\": p_sc, \"p_contract_given_sc\": np.zeros_like(p_sc), \"p_contract\": p_sc}\n",
    "\n",
    "        if self.stage2_type == \"nn\":\n",
    "            X_stage2_scaled = self.stage2_scaler.transform(df[self.stage2_features])\n",
    "            p_contract_given_sc = self.stage2_model.predict(X_stage2_scaled).ravel()\n",
    "        else:  # xgb\n",
    "            p_contract_given_sc = self.stage2_model.predict_proba(df[self.stage2_features])[:, 1]\n",
    "\n",
    "        p_contract = p_sc * p_contract_given_sc\n",
    "        return {\"p_sc\": p_sc, \"p_contract_given_sc\": p_contract_given_sc, \"p_contract\": p_contract}\n",
    "\n",
    "    def evaluate_stage2_only(self, df):\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower()\n",
    "        mask = df['net_sc'] > 0\n",
    "        y_true_sc = df.loc[mask, 'grosscontractsigned']\n",
    "        preds = self.predict_proba(df)\n",
    "        y_pred_sc = preds['p_contract_given_sc'][mask]\n",
    "        if len(y_true_sc) == 0 or y_true_sc.nunique() < 2:\n",
    "            print(\"⚠️ No valid SC leads for Stage 2 evaluation.\")\n",
    "            return None\n",
    "        roc_auc_sc = roc_auc_score(y_true_sc, y_pred_sc)\n",
    "        precision, recall, _ = precision_recall_curve(y_true_sc, y_pred_sc)\n",
    "        pr_auc_sc = auc(recall, precision)\n",
    "        print(\"\\n=== Stage 2 Evaluation (only SC leads) ===\")\n",
    "        print(f\"ROC-AUC (Stage 2): {roc_auc_sc:.4f}\")\n",
    "        print(f\"PR-AUC  (Stage 2): {pr_auc_sc:.4f}\")\n",
    "        return {\"roc_auc_stage2\": roc_auc_sc, \"pr_auc_stage2\": pr_auc_sc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7c2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded']\n",
      "Stage 2 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded', 'gross_fu', 'gross_sc', 'net_fu', 'net_sc', 'time_first_sc_to_first_net_fu']\n",
      "\n",
      "Training Stage 1 (Predicting SC)...\n",
      "\n",
      "Training Stage 2 (Predicting Contract given SC) using NN...\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "=== Stage 2 Evaluation (only SC leads) ===\n",
      "ROC-AUC (Stage 2): 0.8273\n",
      "PR-AUC  (Stage 2): 0.3292\n"
     ]
    }
   ],
   "source": [
    "model_nn = TwoStageContractPredictorFlexible(stage2_type=\"nn\")\n",
    "model_nn.fit(df2)\n",
    "eval_stage2_nn = model_nn.evaluate_stage2_only(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa830a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded']\n",
      "Stage 2 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded', 'gross_fu', 'gross_sc', 'net_fu', 'net_sc', 'time_first_sc_to_first_net_fu']\n",
      "\n",
      "Training Stage 1 (Predicting SC)...\n",
      "\n",
      "Training Stage 2 (Predicting Contract given SC) using XGB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:57:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "=== Stage 2 Evaluation (only SC leads) ===\n",
      "ROC-AUC (Stage 2): 0.8883\n",
      "PR-AUC  (Stage 2): 0.5367\n"
     ]
    }
   ],
   "source": [
    "model_xgb = TwoStageContractPredictorFlexible(stage2_type=\"xgb\")\n",
    "model_xgb.fit(df2)\n",
    "eval_stage2_xgb = model_xgb.evaluate_stage2_only(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21cf13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3bea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Funnel Stats ===\n",
      "Stage 1 (Reach SC): 17955 leads, 10699 progressed (59.6%)\n",
      "Stage 2 (Sign Contract, given SC): 10699 SC leads, 590.0 signed (5.5%)\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 size and positives\n",
    "total_leads = len(df)\n",
    "stage1_total = total_leads\n",
    "stage1_positives = (df['net_sc'] > 0).sum()\n",
    "stage1_positive_rate = stage1_positives / stage1_total\n",
    "\n",
    "# Stage 2 size and positives\n",
    "stage2_total = (df['net_sc'] > 0).sum()\n",
    "stage2_positives = df.loc[df['net_sc'] > 0, 'grosscontractsigned'].sum()\n",
    "stage2_positive_rate = stage2_positives / stage2_total\n",
    "\n",
    "print(\"\\n=== Funnel Stats ===\")\n",
    "print(f\"Stage 1 (Reach SC): {stage1_total} leads, {stage1_positives} progressed ({stage1_positive_rate:.1%})\")\n",
    "print(f\"Stage 2 (Sign Contract, given SC): {stage2_total} SC leads, {stage2_positives} signed ({stage2_positive_rate:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "019fb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step\n",
      "\n",
      "Stage 1 Confusion Matrix:\n",
      " [[   16  7240]\n",
      " [    4 10695]]\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step\n",
      "\n",
      "Stage 2 Confusion Matrix:\n",
      " [[9744  365]\n",
      " [ 392  198]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Stage 1 recall: how many SC leads did model rank correctly?\n",
    "stage1_preds = (model.predict_proba(df)['p_sc'] > 0.5).astype(int)\n",
    "cm_stage1 = confusion_matrix(df['net_sc'] > 0, stage1_preds)\n",
    "print(\"\\nStage 1 Confusion Matrix:\\n\", cm_stage1)\n",
    "\n",
    "# Stage 2 recall: how many contracts did model catch among SC leads?\n",
    "mask = df['net_sc'] > 0\n",
    "stage2_preds = (model.predict_proba(df)['p_contract_given_sc'][mask] > 0.2).astype(int)  # tuned threshold\n",
    "cm_stage2 = confusion_matrix(df.loc[mask, 'grosscontractsigned'], stage2_preds)\n",
    "print(\"\\nStage 2 Confusion Matrix:\\n\", cm_stage2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa8eedd",
   "metadata": {},
   "source": [
    "🔥 Full Two-Stage XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "555feba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class TwoStageXGBContractPredictor:\n",
    "    \"\"\"\n",
    "    Two-stage funnel model using XGBoost for both stages.\n",
    "    Stage 1: Predict SC probability\n",
    "    Stage 2: Predict contract probability given SC\n",
    "    Final probability = p_sc * p_contract_given_sc\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.stage1_model = None\n",
    "        self.stage2_model = None\n",
    "        self.stage1_features = None\n",
    "        self.stage2_features = None\n",
    "\n",
    "    def identify_feature_stages(self, df):\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        stage1_features = [\n",
    "            'electricitybill', 'heatingbill',\n",
    "            'selfipa_done', 'zipregion_missing',\n",
    "            'evaluationtime_missing', 'desiredinstallationend_missing',\n",
    "            'electricitybill_missing', 'heatingbill_missing',\n",
    "            'mktgparamscore_missing', 'desiredinstallationend_encoded',\n",
    "            'mktg_high', 'mktg_low', 'mktg_medium',\n",
    "            'region_high_performer', 'region_large_good',\n",
    "            'region_medium', 'region_other',\n",
    "            'total_bc_attempts', 'total_bc_outcomes',\n",
    "            'lead_to_first_bc_days', 'bc_duration_days',\n",
    "            'bc_frequency', 'positive_outcomes_count',\n",
    "            'negative_outcomes_count', 'noshow_outcomes_count',\n",
    "            'positive_outcome_ratio', 'negative_outcome_ratio',\n",
    "            'noshow_outcome_ratio', 'reachability_score',\n",
    "            'outcome_trend', 'persistence_after_negative',\n",
    "            'engagement_score', 'efficiency_score',\n",
    "            'last_bc_outcome_encoded', 'first_bc_outcome_encoded'\n",
    "        ]\n",
    "\n",
    "        stage2_features = stage1_features + [\n",
    "            'gross_fu', 'gross_sc', 'net_fu', 'net_sc',\n",
    "            'time_first_sc_to_first_net_fu'\n",
    "        ]\n",
    "\n",
    "        self.stage1_features = [f for f in stage1_features if f in df.columns]\n",
    "        self.stage2_features = [f for f in stage2_features if f in df.columns]\n",
    "\n",
    "        print(\"Stage 1 features used:\", self.stage1_features)\n",
    "        print(\"Stage 2 features used:\", self.stage2_features)\n",
    "\n",
    "    def create_stage_labels(self, df):\n",
    "        df.columns = df.columns.str.lower()\n",
    "        stage1_label = (df['net_sc'] > 0).astype(int) if 'net_sc' in df.columns else pd.Series(0, index=df.index)\n",
    "        stage2_label = df['grosscontractsigned']\n",
    "        return stage1_label, stage2_label\n",
    "\n",
    "    def train_stage1(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"\\nTraining Stage 1 (Predicting SC with XGBoost)...\")\n",
    "        self.stage1_model = xgb.XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric=\"auc\",\n",
    "            random_state=self.random_state,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "        self.stage1_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    def train_stage2(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"\\nTraining Stage 2 (Predicting Contract given SC with XGBoost)...\")\n",
    "        self.stage2_model = xgb.XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric=\"auc\",\n",
    "            random_state=self.random_state,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "        self.stage2_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.identify_feature_stages(df)\n",
    "        stage1_label, stage2_label = self.create_stage_labels(df)\n",
    "\n",
    "        # Stage 1\n",
    "        X_stage1 = df[self.stage1_features]\n",
    "        X1_train, X1_val, y1_train, y1_val = train_test_split(\n",
    "            X_stage1, stage1_label, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=stage1_label\n",
    "        )\n",
    "        self.train_stage1(X1_train, y1_train, X1_val, y1_val)\n",
    "\n",
    "        # Stage 2\n",
    "        stage2_mask = stage1_label == 1\n",
    "        X_stage2_filtered = df.loc[stage2_mask, self.stage2_features]\n",
    "        y_stage2_filtered = stage2_label[stage2_mask]\n",
    "        if len(X_stage2_filtered) == 0 or y_stage2_filtered.nunique() < 2:\n",
    "            print(\"\\n⚠️ Skipping Stage 2 (no SC leads or only one class).\")\n",
    "            self.stage2_model = None\n",
    "            return\n",
    "        X2_train, X2_val, y2_train, y2_val = train_test_split(\n",
    "            X_stage2_filtered, y_stage2_filtered, test_size=0.2,\n",
    "            random_state=self.random_state, stratify=y_stage2_filtered\n",
    "        )\n",
    "        self.train_stage2(X2_train, y2_train, X2_val, y2_val)\n",
    "\n",
    "    def predict_proba(self, df):\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # Stage 1\n",
    "        p_sc = self.stage1_model.predict_proba(df[self.stage1_features])[:, 1]\n",
    "\n",
    "        # Stage 2\n",
    "        if self.stage2_model is None:\n",
    "            return {\"p_sc\": p_sc, \"p_contract_given_sc\": np.zeros_like(p_sc), \"p_contract\": p_sc}\n",
    "\n",
    "        p_contract_given_sc = self.stage2_model.predict_proba(df[self.stage2_features])[:, 1]\n",
    "        p_contract = p_sc * p_contract_given_sc\n",
    "\n",
    "        return {\"p_sc\": p_sc, \"p_contract_given_sc\": p_contract_given_sc, \"p_contract\": p_contract}\n",
    "\n",
    "    def evaluate_stage(self, df, stage=\"stage1\", threshold=0.5):\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower()\n",
    "        if stage == \"stage1\":\n",
    "            y_true = (df['net_sc'] > 0).astype(int)\n",
    "            y_pred_proba = self.stage1_model.predict_proba(df[self.stage1_features])[:, 1]\n",
    "        elif stage == \"stage2\":\n",
    "            mask = df['net_sc'] > 0\n",
    "            y_true = df.loc[mask, 'grosscontractsigned']\n",
    "            y_pred_proba = self.stage2_model.predict_proba(df.loc[mask, self.stage2_features])[:, 1]\n",
    "        else:\n",
    "            raise ValueError(\"stage must be 'stage1' or 'stage2'\")\n",
    "\n",
    "        # Metrics\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        y_pred = (y_pred_proba > threshold).astype(int)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\n=== Evaluation {stage.upper()} ===\")\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "        return {\"roc_auc\": roc_auc, \"pr_auc\": pr_auc, \"confusion_matrix\": cm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf64fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded']\n",
      "Stage 2 features used: ['electricitybill', 'heatingbill', 'selfipa_done', 'zipregion_missing', 'evaluationtime_missing', 'desiredinstallationend_missing', 'electricitybill_missing', 'heatingbill_missing', 'desiredinstallationend_encoded', 'mktg_high', 'mktg_low', 'mktg_medium', 'region_high_performer', 'region_medium', 'total_bc_attempts', 'total_bc_outcomes', 'lead_to_first_bc_days', 'bc_duration_days', 'bc_frequency', 'positive_outcomes_count', 'negative_outcomes_count', 'noshow_outcomes_count', 'positive_outcome_ratio', 'negative_outcome_ratio', 'noshow_outcome_ratio', 'reachability_score', 'outcome_trend', 'persistence_after_negative', 'engagement_score', 'efficiency_score', 'last_bc_outcome_encoded', 'first_bc_outcome_encoded', 'gross_fu', 'gross_sc', 'net_fu', 'net_sc', 'time_first_sc_to_first_net_fu']\n",
      "\n",
      "Training Stage 1 (Predicting SC with XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:41:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Stage 2 (Predicting Contract given SC with XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:41:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation STAGE1 ===\n",
      "ROC-AUC: 0.7413\n",
      "PR-AUC: 0.8193\n",
      "Confusion Matrix:\n",
      " [[2544 4712]\n",
      " [1109 9590]]\n",
      "\n",
      "=== Evaluation STAGE2 ===\n",
      "ROC-AUC: 0.9170\n",
      "PR-AUC: 0.6756\n",
      "Confusion Matrix:\n",
      " [[9901  208]\n",
      " [ 223  367]]\n"
     ]
    }
   ],
   "source": [
    "model_xgb2 = TwoStageXGBContractPredictor()\n",
    "model_xgb2.fit(df)\n",
    "\n",
    "# Stage 1 evaluation\n",
    "stage1_eval = model_xgb2.evaluate_stage(df, stage=\"stage1\", threshold=0.5)\n",
    "\n",
    "# Stage 2 evaluation\n",
    "stage2_eval = model_xgb2.evaluate_stage(df, stage=\"stage2\", threshold=0.2)  # use tuned threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40f476ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 972 candidates, totalling 2916 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:15:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'scale_pos_weight': 10, 'subsample': 0.9}\n",
      "✅ Best CV PR-AUC: 0.2428414821411807\n",
      "Validation PR-AUC: 0.27674451521806476\n"
     ]
    }
   ],
   "source": [
    "# grid search for model\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# 🔹 Step 1: filter only SC leads\n",
    "stage2_mask = df['net_sc'] > 0\n",
    "X_stage2 = df.loc[stage2_mask, model_xgb2.stage2_features]\n",
    "y_stage2 = df.loc[stage2_mask, 'grosscontractsigned']\n",
    "\n",
    "# 🔹 Step 2: train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_stage2, y_stage2, test_size=0.2, stratify=y_stage2, random_state=42\n",
    ")\n",
    "\n",
    "# 🔹 Step 3: parameter grid\n",
    "param_grid = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "    \"scale_pos_weight\": [10, 15, 18, 20]  # imbalance handling\n",
    "}\n",
    "\n",
    "# 🔹 Step 4: set up XGBoost + GridSearchCV\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"average_precision\",  # PR-AUC\n",
    "    cv=3,  # 3-fold CV\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 🔹 Step 5: run grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Best Parameters:\", grid.best_params_)\n",
    "print(\"✅ Best CV PR-AUC:\", grid.best_score_)\n",
    "\n",
    "# 🔹 Step 6: evaluate on hold-out validation\n",
    "y_val_pred = grid.best_estimator_.predict_proba(X_val)[:, 1]\n",
    "val_pr_auc = average_precision_score(y_val, y_val_pred)\n",
    "print(\"Validation PR-AUC:\", val_pr_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2545cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auc&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.7,\n",
    "    scale_pos_weight=10,\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42\n",
    ")\n",
    "-- suggested model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9061382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c59a4dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Assume X_train, X_val, y_train, y_val already prepared for Stage 2 (SC leads only)\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 🔹 1. Train XGBoost with early stopping\u001b[39;00m\n\u001b[32m      8\u001b[39m stage2_model = xgb.XGBClassifier(\n\u001b[32m      9\u001b[39m     n_estimators=\u001b[32m1000\u001b[39m,\n\u001b[32m     10\u001b[39m     learning_rate=\u001b[32m0.05\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     use_label_encoder=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mstage2_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 🔹 2. Get predicted probabilities\u001b[39;00m\n\u001b[32m     28\u001b[39m y_scores = stage2_model.predict_proba(X_val)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assume X_train, X_val, y_train, y_val already prepared for Stage 2 (SC leads only)\n",
    "\n",
    "# 🔹 1. Train XGBoost with early stopping\n",
    "stage2_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.7,\n",
    "    scale_pos_weight=10,  # imbalance handling\n",
    "    eval_metric=\"aucpr\",\n",
    "    random_state=42,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "stage2_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 🔹 2. Get predicted probabilities\n",
    "y_scores = stage2_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 🔹 3. Precision–Recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_scores)\n",
    "\n",
    "# Balanced F1 threshold\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "\n",
    "# High recall (≥80%)\n",
    "recall_target = 0.8\n",
    "recall_idx = np.argmin(np.abs(recall - recall_target))\n",
    "\n",
    "# High precision (≥60%)\n",
    "precision_target = 0.6\n",
    "precision_idx = np.argmin(np.abs(precision - precision_target))\n",
    "\n",
    "print(\"\\n=== Suggested Thresholds ===\")\n",
    "print(f\"Balanced F1 -> threshold={thresholds[best_f1_idx]:.3f}, \"\n",
    "      f\"Precision={precision[best_f1_idx]:.2f}, Recall={recall[best_f1_idx]:.2f}\")\n",
    "\n",
    "print(f\"High Recall (~80%) -> threshold={thresholds[recall_idx]:.3f}, \"\n",
    "      f\"Precision={precision[recall_idx]:.2f}, Recall={recall[recall_idx]:.2f}\")\n",
    "\n",
    "print(f\"High Precision (~60%) -> threshold={thresholds[precision_idx]:.3f}, \"\n",
    "      f\"Precision={precision[precision_idx]:.2f}, Recall={recall[precision_idx]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20689120",
   "metadata": {},
   "source": [
    "# second attempt (defo not chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d585da9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f2a0934",
   "metadata": {},
   "source": [
    "## gradient boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a02f6",
   "metadata": {},
   "source": [
    "since this is a 2 layer model that i am getting 2 probablilities; i changed my dataset and take everything after march, also sc gross = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0c7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"processed_data\\merged_df_only_after_march.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4368e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17955 entries, 0 to 17954\n",
      "Data columns (total 41 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   gross_FU                        17955 non-null  int64  \n",
      " 1   gross_SC                        17955 non-null  int64  \n",
      " 2   net_FU                          17955 non-null  float64\n",
      " 3   net_SC                          17955 non-null  float64\n",
      " 4   time_first_sc_to_first_net_fu   17955 non-null  float64\n",
      " 5   electricitybill                 17955 non-null  float64\n",
      " 6   heatingbill                     17955 non-null  float64\n",
      " 7   grosscontractsigned             17955 non-null  float64\n",
      " 8   selfipa_done                    17955 non-null  int64  \n",
      " 9   zipregion_missing               17955 non-null  int64  \n",
      " 10  evaluationtime_missing          17955 non-null  int64  \n",
      " 11  desiredinstallationend_missing  17955 non-null  int64  \n",
      " 12  electricitybill_missing         17955 non-null  int64  \n",
      " 13  heatingbill_missing             17955 non-null  int64  \n",
      " 14  aggregated_missing              17955 non-null  int64  \n",
      " 15  desiredinstallationend_encoded  17955 non-null  int64  \n",
      " 16  mktg_High                       17955 non-null  bool   \n",
      " 17  mktg_Low                        17955 non-null  bool   \n",
      " 18  mktg_Medium                     17955 non-null  bool   \n",
      " 19  region_High_Performer           17955 non-null  bool   \n",
      " 20  region_Large_Solid              17955 non-null  bool   \n",
      " 21  region_Lower                    17955 non-null  bool   \n",
      " 22  region_Medium                   17955 non-null  bool   \n",
      " 23  total_bc_attempts               17955 non-null  int64  \n",
      " 24  total_bc_outcomes               17955 non-null  int64  \n",
      " 25  lead_to_first_bc_days           17955 non-null  float64\n",
      " 26  bc_duration_days                17955 non-null  float64\n",
      " 27  bc_frequency                    17955 non-null  float64\n",
      " 28  positive_outcomes_count         17955 non-null  int64  \n",
      " 29  negative_outcomes_count         17955 non-null  int64  \n",
      " 30  noshow_outcomes_count           17955 non-null  int64  \n",
      " 31  positive_outcome_ratio          17955 non-null  float64\n",
      " 32  negative_outcome_ratio          17955 non-null  float64\n",
      " 33  noshow_outcome_ratio            17955 non-null  float64\n",
      " 34  reachability_score              17955 non-null  float64\n",
      " 35  outcome_trend                   17955 non-null  int64  \n",
      " 36  persistence_after_negative      17955 non-null  int64  \n",
      " 37  engagement_score                17955 non-null  float64\n",
      " 38  efficiency_score                17955 non-null  float64\n",
      " 39  last_bc_outcome_encoded         17955 non-null  int64  \n",
      " 40  first_bc_outcome_encoded        17955 non-null  int64  \n",
      "dtypes: bool(7), float64(15), int64(19)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e8e9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grosscontractsigned\n",
       "0.0    17365\n",
       "1.0      590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grosscontractsigned\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697780d6",
   "metadata": {},
   "source": [
    "Pre-SC features (safe for Stage 1):\n",
    "\n",
    "Everything else (marketing, region, BC attempts/outcomes, engagement-style metrics, etc.)\n",
    "\n",
    "👉 These are fair game for predicting whether a lead will engage in SC at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c44d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 – Engagement Prediction (Before SC) --> not gross because all of them arrived to gross. now we separate to net sc\n",
    "y_stage1 = (df['net_sc'] > 0).astype(int)\n",
    "\n",
    "X_stage1 = df.drop(columns=[\n",
    "    'gross_fu','gross_sc','net_fu','net_sc','time_first_sc_to_first_net_fu',\n",
    "    'grosscontractsigned'   # target column\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49bd392f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net_sc\n",
       "1    10699\n",
       "0     7256\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stage1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4a825",
   "metadata": {},
   "source": [
    "Stage 2 – Contract Prediction (After SC)\n",
    "\n",
    "Target: contract signed, given SC happened.\n",
    "Filter only rows where SC occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03468fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_mask = df['net_sc'] > 0\n",
    "\n",
    "y_stage2 = df.loc[sc_mask, 'grosscontractsigned']\n",
    "\n",
    "X_stage2 = df.loc[sc_mask].drop(columns=[\n",
    "    'grosscontractsigned'   # target\n",
    "    # keep SC-related cols in this stage\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a580fc0",
   "metadata": {},
   "source": [
    "Stage 1 – Train Engagement Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1eba239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 (Engagement) results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.74      0.58      2177\n",
      "           1       0.72      0.46      0.56      3210\n",
      "\n",
      "    accuracy                           0.57      5387\n",
      "   macro avg       0.60      0.60      0.57      5387\n",
      "weighted avg       0.63      0.57      0.57      5387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# --- Train/test split (Stage 1) ---\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X_stage1, y_stage1, test_size=0.3, stratify=y_stage1, random_state=42\n",
    ")\n",
    "\n",
    "# Handle imbalance\n",
    "weights1 = compute_sample_weight(class_weight='balanced', y=y_train1)\n",
    "\n",
    "# Train model\n",
    "stage1_model = GradientBoostingClassifier(random_state=42)\n",
    "stage1_model.fit(X_train1, y_train1, sample_weight=weights1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Stage 1 (Engagement) results:\")\n",
    "print(classification_report(y_test1, stage1_model.predict(X_test1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01818e77",
   "metadata": {},
   "source": [
    "🔹 Stage 2 – Train Contract Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f138547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 (Contract | SC) results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.81      0.88      3033\n",
      "         1.0       0.14      0.56      0.23       177\n",
      "\n",
      "    accuracy                           0.79      3210\n",
      "   macro avg       0.56      0.69      0.56      3210\n",
      "weighted avg       0.92      0.79      0.84      3210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Train/test split (Stage 2) ---\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_stage2, y_stage2, test_size=0.3, stratify=y_stage2, random_state=42\n",
    ")\n",
    "\n",
    "weights2 = compute_sample_weight(class_weight='balanced', y=y_train2)\n",
    "\n",
    "stage2_model = GradientBoostingClassifier(random_state=42)\n",
    "stage2_model.fit(X_train2, y_train2, sample_weight=weights2)\n",
    "\n",
    "print(\"Stage 2 (Contract | SC) results:\")\n",
    "print(classification_report(y_test2, stage2_model.predict(X_test2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a27b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Stage 1 probabilities (on full dataset)\n",
    "p_sc = stage1_model.predict_proba(X_stage1)[:,1]   # P(SC)\n",
    "\n",
    "# Stage 2 probabilities (only valid for SC leads)\n",
    "p_contract_given_sc = np.zeros(len(df))\n",
    "p_contract_given_sc[sc_mask] = stage2_model.predict_proba(X_stage2)[:,1]\n",
    "\n",
    "# Final probability\n",
    "p_final = p_sc * p_contract_given_sc\n",
    "\n",
    "df['p_sc'] = p_sc\n",
    "df['p_contract_given_sc'] = p_contract_given_sc\n",
    "df['p_final'] = p_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10dddf2",
   "metadata": {},
   "source": [
    "p_contract_given_sc_test = Stage 2’s standalone prediction.\n",
    "\n",
    "p_final_test = full pipeline’s final prediction = probability of contract signing before knowing whether SC happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3639fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model ROC AUC: 0.897166714655917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Final model ROC AUC:\", roc_auc_score(df['grosscontractsigned'], df['p_final']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5854e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 (Engagement) results:\n",
      "ROC AUC: 0.650502420519249\n",
      "PR AUC: 0.7564041317568899\n",
      "F1: 0.5642001141335362\n",
      "Precision: 0.7244748412310699\n",
      "Recall: 0.461993769470405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.74      0.58      2177\n",
      "           1       0.72      0.46      0.56      3210\n",
      "\n",
      "    accuracy                           0.57      5387\n",
      "   macro avg       0.60      0.60      0.57      5387\n",
      "weighted avg       0.63      0.57      0.57      5387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score,\n",
    "    precision_score, recall_score, classification_report\n",
    ")\n",
    "\n",
    "# Stage 1 predictions (test set)\n",
    "y_pred1 = stage1_model.predict(X_test1)\n",
    "y_proba1 = stage1_model.predict_proba(X_test1)[:,1]\n",
    "\n",
    "print(\"Stage 1 (Engagement) results:\")\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test1, y_proba1))\n",
    "print(\"PR AUC:\", average_precision_score(y_test1, y_proba1))\n",
    "print(\"F1:\", f1_score(y_test1, y_pred1))\n",
    "print(\"Precision:\", precision_score(y_test1, y_pred1))\n",
    "print(\"Recall:\", recall_score(y_test1, y_pred1))\n",
    "print(classification_report(y_test1, y_pred1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5e922",
   "metadata": {},
   "source": [
    "🔹 Stage 1 (Engagement)\n",
    "\n",
    "ROC AUC: 0.65 → Modest ranking ability, but above random.\n",
    "\n",
    "PR AUC: 0.76 → Very encouraging, means the model is reasonably good at identifying likely engagers (positive class).\n",
    "\n",
    "Precision = 0.72, Recall = 0.46, F1 = 0.56 →\n",
    "\n",
    "You’re precise (when it says “yes, SC engagement”, it’s right 72% of the time).\n",
    "\n",
    "But recall is limited (it misses over half of actual engagers).\n",
    "\n",
    "This is common if the model is conservative about predicting “1”.\n",
    "\n",
    "👉 Takeaway: Stage 1 is okay, but if recall matters (you don’t want to miss potential SCs), you should adjust the decision threshold down from 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6365ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 2 (Contract | SC) results:\n",
      "ROC AUC: 0.752195715304904\n",
      "PR AUC: 0.24249488437831754\n",
      "F1: 0.2304147465437788\n",
      "Precision: 0.1447178002894356\n",
      "Recall: 0.5649717514124294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.81      0.88      3033\n",
      "         1.0       0.14      0.56      0.23       177\n",
      "\n",
      "    accuracy                           0.79      3210\n",
      "   macro avg       0.56      0.69      0.56      3210\n",
      "weighted avg       0.92      0.79      0.84      3210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = stage2_model.predict(X_test2)\n",
    "y_proba2 = stage2_model.predict_proba(X_test2)[:,1]\n",
    "\n",
    "print(\"\\nStage 2 (Contract | SC) results:\")\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test2, y_proba2))\n",
    "print(\"PR AUC:\", average_precision_score(y_test2, y_proba2))\n",
    "print(\"F1:\", f1_score(y_test2, y_pred2))\n",
    "print(\"Precision:\", precision_score(y_test2, y_pred2))\n",
    "print(\"Recall:\", recall_score(y_test2, y_pred2))\n",
    "print(classification_report(y_test2, y_pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91700ba8",
   "metadata": {},
   "source": [
    "🔹 Stage 2 (Contract | SC)\n",
    "\n",
    "ROC AUC: 0.75 → Good ranking ability (stronger than Stage 1).\n",
    "\n",
    "PR AUC: 0.24 → Expectedly low, because the positive class (contracts signed) is rare.\n",
    "\n",
    "Precision = 0.14, Recall = 0.56, F1 = 0.23 →\n",
    "\n",
    "Very recall-heavy: catches over half of the signed contracts.\n",
    "\n",
    "But at the cost of precision: many false positives.\n",
    "\n",
    "Still, this is typical in imbalanced problems (lots of “no contract” cases).\n",
    "\n",
    "👉 Takeaway: Stage 2 is doing a decent job ranking but needs better calibration / threshold tuning to be useful in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7513f84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final combined model results:\n",
      "ROC AUC: 0.897166714655917\n",
      "PR AUC: 0.2775010755822842\n",
      "F1: 0.3315985130111524\n",
      "Precision: 0.295364238410596\n",
      "Recall: 0.37796610169491524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     17365\n",
      "         1.0       0.30      0.38      0.33       590\n",
      "\n",
      "    accuracy                           0.95     17955\n",
      "   macro avg       0.64      0.67      0.65     17955\n",
      "weighted avg       0.96      0.95      0.95     17955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Stage 1 probability for all\n",
    "p_sc = stage1_model.predict_proba(X_stage1)[:,1]\n",
    "\n",
    "# Stage 2 probability (only valid if SC happened)\n",
    "p_contract_given_sc = np.zeros(len(df))\n",
    "p_contract_given_sc[sc_mask] = stage2_model.predict_proba(X_stage2)[:,1]\n",
    "\n",
    "# Final probability\n",
    "p_final = p_sc * p_contract_given_sc\n",
    "\n",
    "# Evaluate final vs ground truth\n",
    "y_true_final = df['grosscontractsigned']\n",
    "\n",
    "print(\"\\nFinal combined model results:\")\n",
    "print(\"ROC AUC:\", roc_auc_score(y_true_final, p_final))\n",
    "print(\"PR AUC:\", average_precision_score(y_true_final, p_final))\n",
    "\n",
    "# For F1 etc. need threshold (default 0.5 here, but can tune)\n",
    "y_pred_final = (p_final >= 0.5).astype(int)\n",
    "print(\"F1:\", f1_score(y_true_final, y_pred_final))\n",
    "print(\"Precision:\", precision_score(y_true_final, y_pred_final))\n",
    "print(\"Recall:\", recall_score(y_true_final, y_pred_final))\n",
    "print(classification_report(y_true_final, y_pred_final))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8af7f",
   "metadata": {},
   "source": [
    "### Threshold tuning of the base models\n",
    "Both stages are evaluated at the default 0.5 threshold previously.\n",
    "You can tune thresholds to maximize F1, or to match your business objective (e.g., catch as many signed contracts as possible, even if precision is low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c14f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for Stage 1: 0.29175202162069486\n",
      "Best F1: 0.7484504736288152\n"
     ]
    }
   ],
   "source": [
    "# looks ok for stage 1 but didnt work great for 2\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test1, y_proba1)\n",
    "\n",
    "# Find threshold that maximizes F1\n",
    "f1_scores = 2 * (prec * rec) / (prec + rec)\n",
    "best_idx = f1_scores.argmax()\n",
    "best_thr = thr[best_idx]\n",
    "\n",
    "print(\"Best threshold for Stage 1:\", best_thr)\n",
    "print(\"Best F1:\", f1_scores[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34d55e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;friedman_mse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">init&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for stage 2 we try class-weighted training\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "weights2 = compute_sample_weight(class_weight='balanced', y=y_train2)\n",
    "stage2_model.fit(X_train2, y_train2, sample_weight=weights2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5060f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions with these new parameters\n",
    "y_pred2 = stage2_model.predict(X_test2)\n",
    "y_proba2 = stage2_model.predict_proba(X_test2)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b130388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 (Contract | SC, class-balanced) results:\n",
      "ROC AUC: 0.752195715304904\n",
      "PR AUC: 0.24249488437831754\n",
      "F1 (default 0.5): 0.2304147465437788\n",
      "Precision (0.5): 0.1447178002894356\n",
      "Recall (0.5): 0.5649717514124294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.81      0.88      3033\n",
      "         1.0       0.14      0.56      0.23       177\n",
      "\n",
      "    accuracy                           0.79      3210\n",
      "   macro avg       0.56      0.69      0.56      3210\n",
      "weighted avg       0.92      0.79      0.84      3210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#results \n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    f1_score, precision_score, recall_score, classification_report\n",
    ")\n",
    "\n",
    "print(\"Stage 2 (Contract | SC, class-balanced) results:\")\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test2, y_proba2))\n",
    "print(\"PR AUC:\", average_precision_score(y_test2, y_proba2))\n",
    "print(\"F1 (default 0.5):\", f1_score(y_test2, y_pred2))\n",
    "print(\"Precision (0.5):\", precision_score(y_test2, y_pred2))\n",
    "print(\"Recall (0.5):\", recall_score(y_test2, y_pred2))\n",
    "print(classification_report(y_test2, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4caa351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.20 | Precision=0.068 | Recall=0.938 | F1=0.127\n",
      "Threshold=0.30 | Precision=0.083 | Recall=0.819 | F1=0.151\n",
      "Threshold=0.50 | Precision=0.145 | Recall=0.565 | F1=0.230\n",
      "Threshold=0.70 | Precision=0.258 | Recall=0.316 | F1=0.284\n",
      "Threshold=0.90 | Precision=0.737 | Recall=0.079 | F1=0.143\n"
     ]
    }
   ],
   "source": [
    "# different thresholds\n",
    "for thr in [0.2, 0.3, 0.5, 0.7, 0.9]:\n",
    "    preds = (y_proba2 >= thr).astype(int)\n",
    "    p = precision_score(y_test2, preds, zero_division=0)\n",
    "    r = recall_score(y_test2, preds, zero_division=0)\n",
    "    f1 = f1_score(y_test2, preds, zero_division=0)\n",
    "    print(f\"Threshold={thr:.2f} | Precision={p:.3f} | Recall={r:.3f} | F1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6960fcf1",
   "metadata": {},
   "source": [
    "Threshold ~0.7 gives the best F1 (≈ 0.28) → a good trade-off between catching signed contracts and avoiding false alarms.\n",
    "\n",
    "If your business values recall more (don’t miss potential contracts, even with lots of false positives), you’d lean to 0.2–0.3.\n",
    "\n",
    "If goal = maximize signed contracts caught → use 0.3–0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "685b4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PIPELINE RESULTS\n",
      "ROC AUC: 0.897166714655917\n",
      "PR AUC: 0.2775010755822842\n",
      "F1: 0.2898550724637681\n",
      "Precision: 0.1917808219178082\n",
      "Recall: 0.5932203389830508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95     17365\n",
      "         1.0       0.19      0.59      0.29       590\n",
      "\n",
      "    accuracy                           0.90     17955\n",
      "   macro avg       0.59      0.75      0.62     17955\n",
      "weighted avg       0.96      0.90      0.93     17955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# full pipeline evaluation after tuning for stage 2 \n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# --- Stage 1 ---\n",
    "p_sc = stage1_model.predict_proba(X_stage1)[:,1]\n",
    "y_pred1_tuned = (p_sc >= 0.29).astype(int)   # tuned threshold\n",
    "\n",
    "# --- Stage 2 ---\n",
    "p_contract_given_sc = np.zeros(len(df))\n",
    "p_contract_given_sc[sc_mask] = stage2_model.predict_proba(X_stage2)[:,1]\n",
    "\n",
    "# Apply threshold (let’s start with 0.5)\n",
    "y_pred2_tuned = np.zeros(len(df))\n",
    "y_pred2_tuned[sc_mask] = (p_contract_given_sc[sc_mask] >= 0.5).astype(int)\n",
    "\n",
    "# --- Final Probability ---\n",
    "p_final = p_sc * p_contract_given_sc\n",
    "\n",
    "# Final tuned decision (threshold on combined prob, try 0.3)\n",
    "y_pred_final = (p_final >= 0.3).astype(int)\n",
    "y_true_final = df['grosscontractsigned']\n",
    "\n",
    "# --- Evaluate ---\n",
    "print(\"FINAL PIPELINE RESULTS\")\n",
    "print(\"ROC AUC:\", roc_auc_score(y_true_final, p_final))\n",
    "print(\"PR AUC:\", average_precision_score(y_true_final, p_final))\n",
    "print(\"F1:\", f1_score(y_true_final, y_pred_final))\n",
    "print(\"Precision:\", precision_score(y_true_final, y_pred_final))\n",
    "print(\"Recall:\", recall_score(y_true_final, y_pred_final))\n",
    "print(classification_report(y_true_final, y_pred_final))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bf840",
   "metadata": {},
   "source": [
    "🔹 Final Pipeline Results\n",
    "\n",
    "ROC AUC: 0.90 → Excellent ranking ability; the model distinguishes signed vs. not-signed really well across thresholds.\n",
    "\n",
    "PR AUC: 0.28 → This is in line with your class imbalance (only ~3% contracts overall). Anything above ~0.03 (random baseline) is meaningful.\n",
    "\n",
    "F1: 0.29, Precision: 0.19, Recall: 0.59 →\n",
    "\n",
    "Recall = 59%: you’re catching more than half of the signed contracts 🎯\n",
    "\n",
    "Precision = 19%: still noisy, but this is expected when contracts are <5% of the dataset.\n",
    "\n",
    "F1 is modest, but that’s normal in extreme imbalance scenarios.\n",
    "\n",
    "🔹 Business Interpretation\n",
    "\n",
    "High recall ✅: You won’t miss too many real contract signers.\n",
    "\n",
    "Moderate precision ❌: For every 5 flagged leads, only ~1 actually signs.\n",
    "\n",
    "But compared to baseline (≈3% conversion rate), you’re concentrating signed contracts in your “high-score” group 6× more effectively.\n",
    "\n",
    "That’s already very actionable:\n",
    "\n",
    "Sales team can prioritize these high-probability leads.\n",
    "\n",
    "You can tune the threshold higher if you want to reduce wasted effort, or lower if you want to maximize contract capture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c1892b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to separate train and test\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def evaluate_pipeline(stage1_model, stage2_model, X_stage1, y_stage1, X_stage2, y_stage2, df_subset, sc_mask, threshold_final=0.3):\n",
    "    \"\"\"\n",
    "    Evaluate the 2-stage funnel pipeline.\n",
    "    Returns ROC AUC, PR AUC, F1, Precision, Recall, plus classification report.\n",
    "    \"\"\"\n",
    "    # Stage 1\n",
    "    p_sc = stage1_model.predict_proba(X_stage1)[:, 1]\n",
    "\n",
    "    # Stage 2\n",
    "    p_contract_given_sc = np.zeros(len(df_subset))\n",
    "    p_contract_given_sc[sc_mask] = stage2_model.predict_proba(X_stage2)[:, 1]\n",
    "\n",
    "    # Final probability\n",
    "    p_final = p_sc * p_contract_given_sc\n",
    "\n",
    "    # Final prediction at threshold\n",
    "    y_pred_final = (p_final >= threshold_final).astype(int)\n",
    "    y_true_final = df_subset['grosscontractsigned'].values\n",
    "\n",
    "    return {\n",
    "        \"ROC AUC\": roc_auc_score(y_true_final, p_final),\n",
    "        \"PR AUC\": average_precision_score(y_true_final, p_final),\n",
    "        \"F1\": f1_score(y_true_final, y_pred_final),\n",
    "        \"Precision\": precision_score(y_true_final, y_pred_final),\n",
    "        \"Recall\": recall_score(y_true_final, y_pred_final),\n",
    "        \"Report\": classification_report(y_true_final, y_pred_final, digits=3)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c332b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set evaluation\n",
    "train_results = evaluate_pipeline(\n",
    "    stage1_model, stage2_model,\n",
    "    X_train1, y_train1, X_train2, y_train2,\n",
    "    df.loc[X_train1.index], sc_mask.loc[X_train1.index]\n",
    ")\n",
    "\n",
    "# Test set evaluation\n",
    "test_results = evaluate_pipeline(\n",
    "    stage1_model, stage2_model,\n",
    "    X_test1, y_test1, X_test2, y_test2,\n",
    "    df.loc[X_test1.index], sc_mask.loc[X_test1.index]\n",
    ")\n",
    "\n",
    "# Full dataset evaluation\n",
    "full_results = evaluate_pipeline(\n",
    "    stage1_model, stage2_model,\n",
    "    X_stage1, y_stage1, X_stage2, y_stage2,\n",
    "    df, sc_mask\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6e90e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ROC AUC    PR AUC        F1  Precision    Recall\n",
      "Train  0.756163  0.084530  0.142373   0.094666  0.287016\n",
      "Test   0.759002  0.074400  0.118519   0.076336  0.264901\n",
      "Full   0.897167  0.277501  0.289855   0.191781  0.593220\n",
      "\n",
      "--- Train Report ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.972     0.901     0.935     12129\n",
      "         1.0      0.095     0.287     0.142       439\n",
      "\n",
      "    accuracy                          0.879     12568\n",
      "   macro avg      0.533     0.594     0.539     12568\n",
      "weighted avg      0.941     0.879     0.907     12568\n",
      "\n",
      "\n",
      "--- Test Report ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.977     0.908     0.941      5236\n",
      "         1.0      0.076     0.265     0.119       151\n",
      "\n",
      "    accuracy                          0.890      5387\n",
      "   macro avg      0.527     0.586     0.530      5387\n",
      "weighted avg      0.952     0.890     0.918      5387\n",
      "\n",
      "\n",
      "--- Full Report ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.985     0.915     0.949     17365\n",
      "         1.0      0.192     0.593     0.290       590\n",
      "\n",
      "    accuracy                          0.904     17955\n",
      "   macro avg      0.588     0.754     0.619     17955\n",
      "weighted avg      0.959     0.904     0.927     17955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame([train_results, test_results, full_results],\n",
    "                          index=[\"Train\", \"Test\", \"Full\"]).drop(columns=\"Report\")\n",
    "print(comparison)\n",
    "\n",
    "# If you also want classification reports:\n",
    "print(\"\\n--- Train Report ---\\n\", train_results[\"Report\"])\n",
    "print(\"\\n--- Test Report ---\\n\", test_results[\"Report\"])\n",
    "print(\"\\n--- Full Report ---\\n\", full_results[\"Report\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b6d15e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 AUC: 0.752195715304904\n",
      "Stage 2 PR AUC: 0.24249488437831754\n"
     ]
    }
   ],
   "source": [
    "# only stage 2\n",
    "p_contract_given_sc_test = stage2_model.predict_proba(X_test2)[:,1]\n",
    "print(\"Stage 2 AUC:\", roc_auc_score(y_test2, p_contract_given_sc_test))\n",
    "print(\"Stage 2 PR AUC:\", average_precision_score(y_test2, p_contract_given_sc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fc9486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 AUC: 0.650502420519249\n",
      "Stage 1 PR AUC: 0.7564041317568899\n"
     ]
    }
   ],
   "source": [
    "#stage 1 \n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "p_sc_test = stage1_model.predict_proba(X_test1)[:,1]\n",
    "print(\"Stage 1 AUC:\", roc_auc_score(y_test1, p_sc_test))\n",
    "print(\"Stage 1 PR AUC:\", average_precision_score(y_test1, p_sc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ff9411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhUpJREFUeJzt3Qd8jPcfB/BP9kASQcQIsfdWatWoVWpTf1VFjaKqpdVWlz1Ka1SV2tVSapbae9Tee8cWCUL2vv/r+zsXWUjI5bnxeb9eJ/c899zd9+5J4pPf/YaNTqfTgYiIiIjIDNlqXQARERER0ctimCUiIiIis8UwS0RERERmi2GWiIiIiMwWwywRERERmS2GWSIiIiIyWwyzRERERGS2GGaJiIiIyGwxzBIRERGR2WKYJSKLdO3aNdjY2GD+/PlJ9m/YsAEVK1aEs7Ozuv3Ro0cwRzt27FD1y1dTVa9ePZQtW1brMojIwjHMEpHZkYAqQe7w4cPput+DBw/wzjvvwMXFBdOmTcMff/yBLFmyYMyYMVi1alW662jXrh2aNWv2wuMCAgLw1VdfoVy5csiaNasK0kWLFkX37t2xZ88emJvg4GAMHz4cFSpUUK9H3k8JrV9++SXu3LmjSU3yvMOGDcPx48c1eX4i0o69hs9NRGQ0BQsWREREBBwcHBL2HTp0CCEhIRg5ciQaNmyYsF/CbPv27dG6des0P35MTAw2b96MsWPHPve4gwcPonnz5up5//e//6FPnz5wcnKCn5+fCtASzHfu3Ik33ngjXa9PjpfX5+joiMx09epV9d7duHEDHTp0QO/evVUNJ0+exJw5c7By5UpcvHgRWoRZCdi+vr6q5Z2IrAfDLBFZJGm5lRbQ5C2kwsPD45Uff/fu3SqgSlB9lqCgIBWQ7e3tVYthyZIlk9w+atQoLF68WLVsppetrW2K12dssbGxaNu2Le7du6e6N9SuXTvJ7aNHj8YPP/yQ6TXFx8dn6nMSkWlhNwMisoo+s9J/s2vXrur6a6+9pm7r1q2b+hoWFobff/9dXTfsf5G1a9eidOnSqiXwWWbMmIG7d+9i8uTJKYKskOfq1KmTqsfg+vXr6NevH0qUKKFCbo4cOVQLqLyeF/WZNfRRPXv2LOrXrw9XV1fky5cP48ePT/HcU6dORZkyZdQx2bNnR9WqVbFo0aLnvubly5fjxIkT+Oabb1IEWeHm5qYCbXIvqic6Ohrff/89qlSpAnd3d9X1o06dOti+fXuq5/THH39U72mRIkVUK/evv/6a8B5K1w3DeUzeX5qILBNbZonIKkgAk4A4c+ZMjBgxAoUKFVJhSD4y79mzJ6pVq6Y+Mhey/0XWrVuHt99++7nHrFmzRgVSac1MK+kKsXfvXtUlIX/+/CrATZ8+XQVVCYUSCJ9HWoObNm2qnlP6By9btkz1ZZX+um+99ZY6ZtasWRgwYIDqWvHJJ58gMjJSdRM4cOAA3n333Wc+9urVq9XXLl26pPn1pKUe6YM7e/ZsFex79eqlWryly0KTJk1UN43k3QbmzZunapbzJWG2TZs26j4SiGWfBGFRs2bNNNdJRGZMR0RkZubNm6eTX1+HDh165jF+fn7qGDn2RffLkiWLrmvXrml+/qtXr6rH2b59+3OPy549u65ixYop9gcHB+sCAwMTLqGhoQm3hYeHpzh+37596vkWLFiQsE+eO3kNdevWTXFcVFSUztvbW9euXbuEfa1atdKVKVNGl16VKlXSubu7p/n4tNYTGxur9icWFBSky507t+6DDz5IcU7d3Nx0AQEBSY6Xc5r8fBORdWA3AyKidJIuBvJxeGoftScmLY4y2j85adnMlStXwkVaKg0S95+VQWYyA4PMfCD9fI8ePfrC2uT53nvvvYRtGZwlrc4ycMtAHuvWrVuqFTg95PVky5YtXfdJSz12dnYJA9mk/+vDhw9VX1jp+pDaa5ZZJOR9IyISDLNERC8RZhs3bqwGdj2PBL/Q0NAU+6Wbg8yEIJfkZIYC+bjcx8dHfYSeM2dOFdxkPtzHjx+/sDbpmiD9RROTPrHycb+BhGcJmRIqixUrho8++gj//fffCx9b+sTKx/npkZZ6hPRZLl++vBrUJv2E5TXL+5zaa5YuIkREBgyzRETpEB4ergZdpWV+WRn0deHCBdXCmpiENumrm3h6MIOPP/5YDaKS/qV///03Nm3apEKvBLy0jNqXVs7U6HTyKbxeqVKlVF0yk4K0LsvALvk6dOjQF74eCZc3b958YR3pqefPP/9Ug+6kr7L0lZWFLeQ1N2jQINXX/DKzPxCR5WKYJSKrl7zl8Hm2bduGqKiohMFLzyMDxKSlVeZeTSsZICWzLvz0009qgFajRo1U0MzolcpkxoCOHTuqwVQyZ6xMMSYhWgZWPUuLFi0SwmdGktdcuHBhrFixQnXBkIFfEvSfV8urnEMisiwMs0Rk9STYpTUsyiwG0pczd+7cLzy2b9++6riBAwemupBA4tbJxC2ZyffLNFpxcXHIKNIPNzHpryrTjMnzJm9FTkzCtcxCIKF33759KW6XLggya0R6GVpvE79umVkhted43jkU5ro8MRG9PE7NRURma+7cueoj6eRkuqn0kPlNt2zZgokTJyJv3ryqT2b16tWfGWZlLtO08PT0VK2y0qIpS7/KdFsyH6qsSiYf1S9dulQdV6BAgSStubLMrgwwk4ApgU5qk24GGUX6+3p7e6NWrVoqbJ87dw6//PKLap193gAvqVtaT6XVVFYgk64Q8hiy/8yZM2qeWukPm9pcs88jr1keV6bYkhpkdTSZo1def2p9jlMjXRRkYJvcT16DhFs5h+xfS2T5GGaJyGzJ/KupScuiB4lJiJX5Sb/99lvVLUA+5k8tzEpgk0UN0tJf1qBGjRo4ffq0eg4Z0LRkyRLVD1QWD5DuAzLvrWFeVDFlyhTVUrlw4UL1MbuERQmz8tF7Rvnwww/V40tNEhZlkJbMOyuv/0VkZgVZzWzSpEkqqMuSvPJ6ZL/M1yuPk15yvvz9/fHbb79h48aNKsRKVwYJ+4kXhXgeCdQyiGzIkCFqyWCZDUG6UDDMElk+G5mfS+siiIjMgaxcJQFQVvViH00iItPAPrNERGkkS9dKiySDLBGR6WDLLBERERGZLbbMEhEREZHZYpglIiIiIrPFMEtEREREZothloiIiIjMltXNMyvzId65c0dNqs0RyURERESmR+YnkFUFZSEbW9vnt71aXZiVIOvj46N1GURERET0ArJaoizs8jxWF2YNSzXKm+Pm5qZ1ORZN1njftGmTWjpTVuchy8dzbp143q0Pz7n1icnkcx4cHKwaH5+3xLbVhllD1wIJsgyzxv/Gd3V1Ve8zf9lZB55z68Tzbn14zq1PjEbnPC1dQjkAjIiIiIjMFsMsEREREZkthlkiIiIiMltW12c2rdNBxMbGIi4uTutSzL5/jb29PSIjIzP8vbSzs1OPzenViIiIrBvDbDLR0dG4e/cuwsPDtS7FIv4o8Pb2VjNHGCN0Skf0PHnywNHRMcMfm4iIiMwDw2yyBRX8/PxUq59M0ishiS1/r/Z+hoaGImvWrC+c8Di9IVn+6AgMDFTnq1ixYhn6+ERERGQ+GGYTkYAkAUzmNZNWP3o18l7Ke+rs7JzhYdPFxUVNDXL9+vWE5yAiIiLrw+asVLCVzzzwPBERERHTABERERGZLYZZIiIiIjJbDLNGEhevw74rD/DP8dvqq2ybsx07dqjBcI8ePUrzfQoXLozp06cbtS4iIiKybgyzRrDh9F3U/mEbOs3aj08WH1dfZVv2G0u3bt1U2OzTp0+K2z766CN1mxxDREREZEkYZjOYBNa+fx7F3ceRSfb7P45U+40ZaGUWhsWLFyMiIiJhnyxYsGjRIhQoUMBoz0tERESkFYbZNMxpGh4dm6ZLSGQMhq4+g9Q6FBj2DVt9Vh2XlseT506PypUrq0C7YsWKhH1yXYJspUqVEvZFRUVhwIAB8PLyUlNa1a5dG4cOHUryWOvWrUPx4sXVFFj169fHtWvXUjzfnj17UKdOHXWMPK88ZlhYWLpqJiLzJl2oDvg9xJH7NuqruXepstauZOnBc85zHmdir13TeWZ37dqFCRMm4MiRI2rVrZUrV6J169Yv7Ls5aNAgnDlzRgWob7/91qgfn0fExKH09xsz5LHk1PsHR6LcsE1pOv7siCZwdUzfKfrggw8wb948dO7cWW3PnTsX3bt3V++bwRdffIHly5fj999/R8GCBTF+/Hg0adIEly9fhqenp1qxq23btqp7Qu/evXH48GF89tlnSZ7nypUraNq0KUaNGqWeQxYw6N+/v7rI8xNZE/nFftDvIQJCIuGVzRnVCnnCztbyF1yRT5qGrzn75JMoOyy4dBh53J0xtEVpNC2bB9bxuvWs4XULnnOe8wUmeM41bZmVVrwKFSpg2rRpaTpeVntq3ry5aik8fvw4Pv30U/Ts2RMbN2ZM2LQE7733nmoxlcUE5PLff/+pfYnfcxmUJX9EvPXWWyhdujRmzZqlWlfnzJmjjpHbixQpgp9++gklSpRQwTj5Hwxjx45V++UcyApcNWvWxM8//4wFCxaorg1E1kKLPvLW3qVKS9b6uq35tVvr6zan165py6yEKbmk1YwZM1CoUCEVskSpUqVUcJs0aZJqWTQGFwc71UKaFtIy021e0o/rUzO/+2uq5SYtz51euXLlUoF//vz5qpuCXM+ZM2eSFtWYmBjUqlUrYZ+spFWtWjWcO3dObcvX6tWrJ3ncGjVqJNk+ceIETp48iYULFybsk+czLAks54bI0hl+0Sf/wM3wi376e5VNpuUireTnODZeh5i4eETHxiP6ydeYuKf75BOrr1eefm6XqiErTiE+XgdbC2qhltfz9Srre93W/Nqt9XWn9trtEIc46HOJ7JNXKy22jUp7a/5JlFktZ7tv3z40bNgwyT4JsdI6+CzSP1QuBsHBweqrBDq5JCbbhkAmFwNn+7Q1YNcqkgPebs64FxyZ6je+nGpvd2d1XFpOvNSS1n6zhmOlbmlFlf6rYurUqWpf4ttF8teY+PbkxxqOT3y/0NBQ1QXh448/TlGL9NFN/tiJtzOKoVY5b3Z26Q/+lPEMP1PJf7YstWvBsOf0kdf/oj+DesVS/rzLfxIqGKqL7klYfBoaZf/Tbfn69PiYNN0n0e3J9j8Nqanc58l2OrvrpyooPAb9Fh2DtbHW123Nr93yX7cOHe12oIfdOrSPHoZgZHmyF6rFdt/lAFRPQwNdeqXn/xGzCrP+/v7InTt3kn2yLQFVRvDLR+XJycfhw4cPT7F/06ZNcHV1TbLP3t4e3t7eKqhFR0e/VI2D3/TF5yvPq//IEv9/YPiv7PMGvggLDYExTnpsbKx6L+QjfwnwMh2XtKjKPrlNjpGWW0dHR2zZsgUdOnRIuK8MAJNpveRYmR92/fr1CcHf0L9ZhISEqGVky5Yti1OnTqlBZMlJNwO5GAKs3McY5BzJeZfa5PWR6di8eTMs3aXHNvAPfvYfUfpf9FGoMnITJMvGxgNxOv3X+ITfCObB3kYHO1v5qr/I6wiNffFryOWsQ1YHWIzQGCAw0vpetzW/dmt93YbXHh4ZiTEOc9DKbq/a957dFvwa1wqJbdp9AA/OZfyAsPDwcMsMsy9jyJAhasCYgQQ0GTjWuHFjuLm5JTlWApgMfsqaNasa5f8y2rzmpkL1iH/PqcFeBtIi+13zUmha1hvGIF0FJIwbXtPZs2fVV8O23CbH5MmTR4XWYcOGIV++fKoVVfrPSijs16+fOl5adaUfswzu6tGjhxqgJ1N+iWzZsqljvvnmGxWa5asckyVLFvWcEpKlNVhI6DXcR4J1RpPzJe/1G2+88dLnizKW/GEkQbZRo0bq+81S3QwKx/ZtVySuvvDYsDSEPntbGzja28LBzgaOdvLVNmH76XXbJ7cZjtXvd0zlPmr7OfcxHOOYeDvJ8U/3SW3Jf35lNPN7cw+/8HVNevc1o7TYaMVaX7c1v3Zrfd3i9NE9cF/7GQrb+iNWZ4sfY9/Bb3FvI7nGdaob5bUnblCzqDArrab37t1Lsk+2JVyl1iornJyc1CU5+Y82+X+2cXFx6pe2hDBDEHsZzcrnRZOyeTJ1dLPUbahdeHh4PPP2H374QX0837VrV9VqWrVqVTWILkeOHOpYX19fNdvBwIED8csvv6j+tGPGjFEzJRjem4oVK2Lnzp0qzNatW1c9ngwa69ixY4r3LnFdGUkeUx47tXNJ2rK0cyLdAo7feoQtZ+9h67kAXLiX9k8bRrUui8oFsj8JnqmHR3Pra1ejqJcazSx9g5/XpUqO07ovXUay1tdtza/dKl+3TgccnoOKm76GjW0Ubuty4OPoj3FUVzxTX3t6/g8xqzArH5nL/KeJSStQ8sFJpkBObI0i+nCYGWTA1/OsWrUq4bq0YsrMA3J5lrfffltdEpMpvhJ77bXXVHeNZ7l69Wq6/rIiMiUy1/OeS/ex5dw9bDsfgPuh0Ul+vqsW9MDZuyEIiUy9i4vhF32nagUs5z+5J+T1yLQ8MsjtWV2q5Ha+bsthra/dKl/3w6vA+q9gEx+DgDz18bbf//AI2ZIcYmqvXdMwK31TZW5TAxkFL1NuyVyn8vG3dBG4ffu2mu5JyMfj0lIo86RKK+G2bdvw999/Y+3atRq+CiKyFNL6svW8vvV1z+X7amCUQTYne9QtkQsNS+VGvRK54OHqmDCbAazlP7lEZJYGma0h+dyb3iY2/2RGs9bXbc2v3eped44iQJMxQHwMvF7vh7Fn/E3+tdvo0rvMVAaSifxlztjk5ONvaWmUUfmy8lTiCf/lunz8Lf0z8+fPj++++y5diyZIS6G7uzseP36cap9ZCdQy/Rf7YL46GQAm77e8z8boZsDzZZp9ZuXTk2bNmplFNwP59XfmTrAKr9ICe+r24yS358/uosJro9K58Zqvp+oakJw1T6aesCrS5QA1CET6zlnUx63PYa0LZQiecws75zodcHAmUKAGkKe8yZzz5+U1k2qZrVev3nOnnkrto3O5z7FjljwFBhEZU1RsnFqKUgLs1nP3cCdRCJVxThV9PFSAlUvx3FlfOHhRAqvMs2iR/8mlgbxOGfwho5mrW9nrzsyuZKaE59yCRAQB//QHzv8LeBYB+uwGHPVTb5nTOTerPrNERC/jQWgUtl8IVAO4dl8KRFh0XJLFSWoXy4lGpXKjfkkv5MqWcsCoVf4nR0SW7dZhYGl34PENwM4RqN4HcEg6Zam5YJglIosjn/hcCQzF5rP61tcjN4KSLASQ280Jb6rWVy/ULJITzi+x2h4RkVnS6YB9vwBbhgHxsUD2QkCHeUDeSjBXDLNEZBFi4+Jx6FqQ6vsqAfbag6QTbpfO44aGpfUBtmxed7ObDouI6JVFhQLLewAXN+i3y7QBWvwMOD+/T6qpY5glIrMVHBmDndJ94Nw97LgQiMcRT5c/lPlbXy+SA41KeaFBqdzI55H6XNRERFbDwRWIjQLsnIC3xgFVuusHC5g5hlkiMis3HoTrW1/P38OBqw8RG/+0/0B2Vwc0KKlvfa1TPBeyOvFXHBFZuXhZQzsGsHeS1YaAtjOB0HuAdzlYCv6mJyKzWX1LQuzFe6FJbi+SK4vqPiADuCoVyG5yo2yJiDQTGgis/BBwzw+0fLJQUlYv/cWCMMzSK5Opi1auXInWrVtrXQpZ0Opbuy/dV31fU1t96zXf7GrqLBnEVShnymlkiIis3rU9wLIeQKg/YO8C1BkEZPeFJWKYtRCycMTvv/+urtvb26sFJTp06IARI0ZwQQEyq9W3pAX2vysPUl19SxYvqFtcv/oWERGlIj4O2P0TsGMsoIsHcpYAOsy32CArGGYtSNOmTTFv3jy1CtORI0fUSmrSavrDDz9oXRpZAVkh5oDfQxy5b4Mcfg9fuELMi1bf8vF0wZsln7/6FhERJRJyD1jRC/Dbqd+u2BloNiHVhRAsCcNsWkWHPfs2GzvAwTmNx9oCDi4vPvYlvvGcnJzg7e2trvv4+KBhw4bYvHmzCrMPHjxA//79sWvXLgQFBaFIkSL4+uuv0alTpySrq5UvX1615M6ePRuOjo7o06cPhg0blnDMpUuX0KNHDxw8eBCFCxfGlClTUtRx6tQpfPLJJ9i3bx9cXFzQrl07TJo0CVmzZk1oRX706BGqVaum7h8VFYVBgwapeoYMGYI5c+bA1dUVI0eORPfu3dP9PlDmS7qkqx0WXDqc6pKuhtW39NNnBSRZAvZlVt8iIqJEA70WtAICz+lnLWg+Eaj49P94S8Ywm1Zj8j77tmKNgc5Ln25PKArEJJ3jMkHB2kD3tU+3J5cDwh+kPG5Y0laq9Dp9+jT27t2LggULqu3IyEhUqVIFX375pVrjeO3atejSpYsKtRIqDaSrggTLAwcOqDAqwbNWrVpo1KgR4uPj0bZtW+TOnVvdLuslf/rpp0meNywsDE2aNEGNGjXUMdeuXVPHSJBOvDzxtm3bVFcICdf//fefCshS7xtvvKHut2TJEnz44YfqeeU4Mu0g2/fPo9Cl0m1A9o9vr1/rW8LrrkuBCE+2+ladYjlVeH3Z1beIiAj6mQoaDQe2jgDazwNyFYe1YJi1IP/++69q/YyNjVWtnba2tvjll1/Ubfny5cPnn3+ecOzHH3+MjRs34u+//04SZqVldujQoep6sWLF1P23bt2qQuWWLVtw/vx5db+8efXhfsyYMXjrrbcS7r9o0SIVnBcsWKBaZQsUKICff/4ZrVq1Ui3EEoSFp6en2i81lihRAuPHj0d4eLhqnRXSQjtu3Djs2bMH//vf/zLpHaSX6VogLbLJg6ww7Bu87GSS/Vx9i4gogwTfBR5eBXxr6beLNwGKvAnYWVe8s65X+yq+vvP8bgaJDb78nGOT9fv79BQySv369TF9+nTVOiof68tAMPmIX8TFxangKeH19u3biI6OVoFXPs5PTMJsYnny5EFAQIC6fu7cOdV9wRBkhbTAJibHVKhQAVmyZFEtuUJaduX6hQsXEsJsmTJlVJA1kP1ly5ZN2Lazs0OOHDkSnptM00G/h0m6CjyLbw5XtKyYT02fVTafG7sPEBG9qstbgBUf6ueQ7bMH8Cig329lQVZY3yt+Wenpw2qsY19AAmTRokXV9blz56pQKf1P5SP8CRMmqP6pkydPRrly5dSx8vG/hNrEHBwckmxL6DCE0oyU2vNk1nNTxgkIeXGQFQMbFUerivmMXg8RkcWLiwW2jwL2TNJve5cD4mNhzTg82EJJq6d8ZP/tt98iIiJC9UuVj/rfe+89FXJl8NbFixfT9ZilSpXCzZs3cffu3YR9+/fvT3HMiRMnVOuwgTy3oTsBWY6I6DgcuvYwTcd6ZeP0cEREr+zxLWB+86dB9rWeQI8tgGdhWDOGWQsm88zKx/XTpk1T/V9lZgMZZCVdAWRw1b1799L1eDI7QvHixdWUXxJYd+/ejW+++SbJMZ07d1azIcgxMghNjpGZDWSwmaGLAZm3yJg4zN3jhzcmbMef+28891jpTCCzGlQr5Jlp9RERWaSLG4EZtYGb+wEnN/3csc1/SjqbkpViNwMLJn1mZRYBGVx17NgxXL16Vc00IP1ke/furVbskhkJ0kpaV2WlL+m2IIPGfH191SAumd/WQB5bBohJgK1evXqSqbnI/EPskkM3MW37ZQSERKl9+bO7oH6JXAmhNvFAMEOvWJmei0vMEhFlQJiNCALyVtLPVuBZSOuKTIaNTmYutyLBwcFwd3dXIU6mqEpMRuH7+fmhUKFCXDUrA0h/V3m/5X1OPNgro/B8ZQ6ZG/bvw7cwbdtl+Afr+8jm83BB/wZF0a5yfrWYQdJ5ZvVSm2eWLJMs1LJu3To0a9YsRd93skw85xqIiQQOzABe7wvYO1n8OQ9+Tl5Lji2zRJQqWU526ZGbKsTeeRJSJaB+VL8oOlTNDyf7p7N4SGBtVNob+y4HYNPuA2hcp/oLVwAjIqLnOPcvcHKJvjuB7ZPFmWonndud9BhmiSiJmLh4LD9yC1O3XcbtRxEJc8NKiO34mk+SEJuYBNfqhTzx4JxOfWWQJSJ6CbFRwObv9a2w4ugCoCpXw3wehlkiUmLj4rHi2G1M3XYJNx/qQ6ysyNWvXhF0qlaAixsQERmbLICwtDtw97h+u+bHQKX3tK7K5DHMElk5CbGrjt9RIfb6A/0yzDmzOqFvvSLoXJ0hlogoU5xZCaweAEQFAy7ZgTa/6Vf0ohdimE2FlY2JM1s8T6++FO3qE7fx89bL8Luvnxc4RxZH9KlbBO+9XhAujgyxRESZYvdPwNYR+us+rwPt5wDu+bWuymwwzCZiGJ0XHh6uppQi0ybnSXAkbfpD7L8n7+DnrZdwJVAfYrO7OuDDukXwfo2CcHXkrwUiokxVvCmw60egeh+g/jdWuSTtq+C7lYgsMODh4YGAgICEOVO5hvyrTc0ly+XKFFoZOTWXtMhKkJXzJOdLzhu9WHy8DmtP3cWUrZdwOSBU7fNwdUCvOoXRtaYvsjrx1wERUaa5fxnIqV+CHrnLAAOOAdm8ta7KLPF/r2S8vfXfSIZAS68WOmUpXWnlNsYfBRJkDeeLnh9iN5zxx5Qtl3DhXoja5+Zsr0Jst1q+yObMlm0iokwTEwGs/xI4vhDovgHweU2/n0H2pTHMJiOhK0+ePPDy8lITBNPLk/dv165deOONNzK8K4A8HltkX/zHxMYz9zB5y0Wc99eH2GzO9uhZuzC61/aFG0MsEVHmCrwALO0GBJzVr5N4+8jTMEsvjWH2GSQoMSy9Gnn/YmNj1epc7NeauSF2y7kATNp8EWfvBqt92Zzs0b12IfSoXQjuLjwXRESZ7vgiYO1nQEw4kMULaDcLKFxP66osAsMskQWF2G3nAzB5yyWcuv1Y7cviaIfutQqhZ51C8HB11LpEIiLrEx0GrP0cOLFIv12oLtB2FpAtt9aVWQyGWSILCLE7LgZi8uaLOHFLH2JdHe3Qraav6hebPQtDLBGRZk4v1wdZG1ug3tdAnUH65WkpwzDMEplxiN196T4mbr6I4zcfqX0uDnZ4v2ZB9K5TGDmyOmldIhERVeqi7xtbrgPgW1vraiwSwyyRGYbY/y4/wKQtF3HkepDa5+xgiy6vF1RzxcrqXUREpJGoEGDneKDuF4BTNhlZDrSYonVVFo1hlsiM7L1yH5M3X8LBaw/VtpO9LTpXL4g+9QrDK5uz1uUREVk3/1P62QoeXAbCAoE2M7SuyCowzBKZgQNX9S2x+6/qQ6yjvS3erVYA/eoVgZcbQywRkaZkefXDc4ENQ4C4KMAtH1Clm9ZVWQ2GWSITdujaQzXF1t4rD9S2o50t/lfNB/3qFYW3O0MsEZHmIh8Daz4Bzqx8ujRt6+mAq6fWlVkNhlkiEyR9YWWxAxngJRzsbPBOVR98VL8o8nq4aF0eERGJgHPAX52AID/A1h5oOByo8ZG+nyxlGoZZIhMisxJIS+zOi4Fq297WBh2q5lchNn92V63LIyKixFxz6OeRdS8AdJgH5K+qdUVWiWGWyAScvKUPsdsv6EOsna0N2lfOj/4NisLHkyGWiMhkxEQADk8+IcvqBXReCmQvCLhk17oyq8UwS6Sh07cfq+4EsvyssLUB2lbOj48bFEXBHFm0Lo+IiBK7dRhY2h1oOBQo116/L29FrauyegyzRBo4eydYhdhNZ+8lhNjWFfPh4zeLoVBOhlgiIpObrWDfL8CWYUB8LPDfZKBMW8DWVuvKiGGWKOPFxetw0O8hAkIi1dyv1Qp5qm4D4rx/sJondsMZf7UtYwRaVcirQmyRXFk1rpyIiFIIfwis6gtc3KDfLt0KaDmVQdaEMMwSZaANp+9i+JqzuPs4MmFfHndn9KpTWM1QsPbU3YQQ+3b5vPjkzaIo6pVNw4qJiOiZbhwAln0ABN8C7JyApmOAqj04W4GJYZglysAg2/fPo9Al2y/BdsS/ZxO2m5fLg08aFkPx3AyxREQmK+gaML+ZvluBZxGgw3wgT3mtq6JUMMwSZVDXAmmRTR5kE3O2t8WyvjVRNp97JlZGREQvJbsvUL0PEHoPeHsS4MQGCFPFMEuUAaSPbOKuBamJjI1HSGRsptVERETpdG0P4FEQ8PDRbzcaAdjYsluBiWPvZaIMIIO9MvI4IiLKRPFxwM7xwO8t9H1k42L0+23tGGTNAFtmiV5RdGw8dl7QzxP7IjK7ARERmZDQAGB5T8Bvp347R1F9mLVz0LoySiOGWaJXXPTg86UncN4/5LnHyd/13u76abqIiMhEXN2pD7JhAYCDK9D8J6Diu1pXRenEMEv0kq2x07ZfVpfYeB08sziiXeV8mL3bT92eeCCY4QOqoS1KJ8w3S0REWncr+EHftUB+Y3uVBtrPA7xKal0ZvQSGWaKXWL3rs6UncO5usNp+q6w3RrYui5xZnVClYPYU88xKi6wE2aZl82hYNRERJZBuBOfX6oNs5feBpj8Ajq5aV0UviWGWKI1i4uLx6/YrmLrtkmqNze7qgBGtyuLt8nlg82SAgATWRqW9n7kCGBERmQAHZ/28sXeOA+U7aF0NvSKGWaI0kFZY6Rt75o6+NbZJmdwY1boccmVzSnGsBNcaRXJoUCUREaUqLhbYPgpwyALUHazfl7OY/kJmj2GW6AWtsTN2XMHP2y4hJk4HD1cHDG9ZBi0r5E1ojSUiIhP2+BawrAdwc79+ztiybYEcRbSuijIQwyzRM1zwD8FnS4/j9G19a2zj0rkxqk1ZTq9FRGQuLm4EVn4IRAQBTm5AiykMshaIYZYomVhpjd15BVO26ltj3V2kbyxbY4mIzGqA19bhwN6p+u08FYEO8wDPwlpXRkbAMEuUyMV7Iapv7Mlbj9V2w1K5MUZaY93YGktEZBZ0OuCPNsC13frt6n30y9LapxzjQJaBYZboSWvsb7uuYsqWS4iOi4ebsz2GtyqD1hXzsTWWiMicyO9s6RfrfxJoNQ0o1ULrisjIGGbJ6l160hp74klr7JslvTCmbTnkZmssEZF5iI0Cgm8/7UZQpTtQ8m0gq5fWlVEmYJglq26NnbXbD5O2XFQremVztsewFmXQtjJbY4mIzMZDP2BpNyD8IdBnF+CSXd86yyBrNRhmySpdDghVrbHHbz5S2/VL5MLYtuXVal1ERGQmzqwCVn8MRAXrQ+yDK0D+qlpXRZmMYZasSly8DrN3X8VPm5+0xjrZ4/sWpdG+Sn62xhIRmYuYSGDTN8Ch2fptn9eB9nMA9/xaV0YaYJglq3ElMBSDl57A0Rv61ti6xXNhXLtyyOPuonVpRESUVtL6urQr4H9Kv117IFD/G8DOQevKSCMMs2QVrbFz9/jhx00XEPWkNfa7t0ujQ1W2xhIRmZ3to/VB1jUH0GYmUKyh1hWRxhhmyaJdldbYZSdx5HqQ2q5TLCd+aFceeT3YGktEZJaa/SjzbwGNRwJuebWuhkwAwyxZbGvsvP/8MGGjvjU2q5M9vm1eCh1f82FrLBGROQm8AJxeDtQbop+lwNVT3z+W6AmGWbI41+6HYfCyEzh0Td8aW7toTvzQvjzysTWWiMi8HP8LWDsIiAkHshcCKnbSuiIyQQyzZDHi43WYv/caxm88j8iYeGRxtMM3zUujUzW2xhIRmZXoMGDdYOD4Qv12oTeAIg20ropMFMMsWYTrD6Q19iQO+j1U27WK5lB9Y/Nnd9W6NCIiSo97Z/WLINy/ANjY6rsX1PkMsLXTujIyUQyzZPatsQv2XcMPGy4gIiYOro52+LpZKXSuXoCtsURE5ubUMuCf/kBsBJDVG2g3GyhUR+uqyMQxzJLZuvEgXPWNPfCkNbZG4RwY3748fDzZGktEZJay5ARiI/VdCmTaray5tK6ILDXM3rhxA9evX0d4eDhy5cqFMmXKwMnJKeOrI3pGa+yfB65j3PrzCI/Wt8YOeaskOlcvCFtbtsYSEZld/1jHLPrrhesB3dfpV/SytdW6MrK0MHvt2jVMnz4dixcvxq1bt6DT6RJuc3R0RJ06ddC7d2+0a9cOtvwGJCO5+TAcXyw7iX1XH6jt6oU8MaF9BRTIwdZYIiKzIjni8Fxg+xigxyYgRxH9/oI1ta6MzEyaUueAAQNQoUIF+Pn5YdSoUTh79iweP36M6Oho+Pv7Y926dahduza+//57lC9fHocOHTJ+5WR1rbF/7L+OJpN3qSDr4mCH4S3L4K9erzPIEhGZm8hgYFl3/bRb4feBI/O0rogsvWU2S5YsuHr1KnLkyJHiNi8vLzRo0EBdhg4dig0bNuDmzZt47bXXjFEvWaFbQeH4cvlJ/HdZ3xpbzdcTEzqUR8EcTz6WIiIi83HnGLC0OxDkB9jaAw2HAa9/pHVVZOlhduzYsWl+wKZNm75KPUQJpCvLooM3MGbtOYRFx8HZwRZfNi2JrjV82TeWiMgcuxUcnAls+haIiwbcCwDt5wI+bPyiV8PZDMgk3X4Uga+Wn8TuS/fV9mu+2VXfWN+cbI0lIjJLsgDC+i/010u+DbT6BXDJrnVVZC1htlKlSmmes/Po0aOvWhNZeWvs4kM3MXrtOYRGxarW2MFNSqJbTV/YsTWWiMh8lXsHOPYnULo1UP1DgHOBU2aG2datW2fU8xE9051HEapvrKE1tmrB7JjQoQIKsTWWiMg8uxWcWgqUaQPYOQD2jkC3dZxyi7QJszKwi8iYrbF/H76JUf+eQ0hULJzspTW2BLrXKsTWWCIicxT+EFjVD7i4Hgg4qx/kJRhkyQjYZ5Y0dfex9I09hZ0XA9V25QIeqjW2SK6sWpdGREQv48YBYNkHQPAtwM4RcM+vdUVk4dIUZrNnz57mPrMPH+qXFiV6UWvs0iO3MPLfswiJjIWjvS0+b1wcPWoXZmssEZE5io8H9k4Bto4EdHGAZxGgw3wgT3mtKyMLl6YwO3nyZONXQlbD/3Ekhqw4ie0X9K2xFX088GOHCijqxdZYIiKzFHYfWNkHuLxZv122PdBiMuCUTevKyAqkKcx27drVaAVMmzYNEyZMUCuJySpjU6dORbVq1Z4brGVZ3Rs3biBnzpxo3769mgfX2dnZaDVS+sXF63DA7yGO3LdBDr+HqFHUC9LguvzobQxfcyahNXZQo+LoVYetsUREZi0iCLi+F7B3Bt4aD1R+n7MVkHn0mY2MjFRL2ibm5uaW5vsvWbIEgwYNwowZM1C9enUVVJs0aYILFy6olcWSW7RoEb766ivMnTsXNWvWxMWLF9GtWzfVBWLixImv8lIoA204fRfD15zF3ceRAOyw4NJheGVzgpebE07fDlbHVJDW2PblUSw3/2onIjJ7OYsB7WYB2X2B3GW0roasTLqHFYaFhaF///4qbMoyt9KfNvElPSSA9urVC927d0fp0qVVqHV1dVVhNTV79+5FrVq18O6778LX1xeNGzdGp06dcPDgwfS+DDJikO3759EnQfapgJAoFWTtbW3wRdMSWN6nBoMsEZG5Cg3A65d/hM2NvU/3lWzOIEvm0TL7xRdfYPv27eqj/i5duqhuArdv38Zvv/2GcePGpflxpEX3yJEjGDJkSMI+W1tbNGzYEPv27Uv1PtIa++eff6rwKl0Rrl69inXr1qk6niUqKkpdDIKD9S2DMTEx6kIZ27Vg2Ooz0D3nGA9XB3xQowB08XGIiY/LxOooMxh+pvizZV143q2LzbVdsF/VB7nDAhD/76eI6bMPsLXTuiyysJ/z9DxPusPsmjVrsGDBAtSrV0+1qNapUwdFixZFwYIFsXDhQnTu3DlNj3P//n3ExcUhd+7cSfbL9vnz51O9j7TIyv1q166tRsPHxsaiT58++Prrr5/5PNKfdvjw4Sn2b9q0SbUCU8a59NgG/sHP/4V2PzQavyzZgGLuz4u8ZO42b34yCISsCs+7hdPFo4T/KpTw/wc20CHYOR8O5+6FkA0bta6MLPDnPDw83HhhVqbeKly4cEL/WMNUXBIw+/btC2PasWMHxowZg19//VX1sb18+TI++eQTjBw5Et99912q95GWX+mXm7hl1sfHR3VRSE//XnqxNSfvAmdPvfC4wmUqoln5PJlSE2Uu+UtaftE1atQIDg4OWpdDmYTn3QqE3IXdP31g6/+f2owt9y522dZHgyZv85xbiZhM/jk3fJJulDArQdbPzw8FChRAyZIl8ffff6uP/KXF1sPDI82PIzMR2NnZ4d69e0n2y7a3t3eq95HAKl0KevbsqbbLlSun+vD27t0b33zzjeqmkJyTk5O6JCcngj+AGSuPR5Y0H8f33rLx58s68bxbqMe3gNn1gfD7gEMWNeWWrlQbxK1bx3NuhRwy6Zyn5znSPQBMuhacOHFCXZeZBaTPrEyLNXDgQAwePDjNj+Po6IgqVapg69atCfvi4+PVdo0aNZ7Z5Jw8sEogFtLtgLRVrZAnvN2ePUWaTNKSx91ZHUdERGbCLR9QqA6Quxzw4S6g/DtaV0T0ai2zEloNZLCW9G+VgVzSb7Z8+fSt8iEf/8sctlWrVlWtuzI1l7S0SmAW77//PvLly6f6vYoWLVqoGRAqVaqU0M1AWmtlvyHUknZkrtjqhT3xz/E7KW4zzDY4tEVpzilLRGTqHt8GHLMALh76+WJbTgVs7QEHF60rI8rYeWaFDPySy8vo2LEjAgMD8f3336tFEypWrIgNGzYkDAqThRESt8R+++23ak5Z+SozKOTKlUsF2dGjR7/qy6AM4Hc/DOtP+6vrHi4OeBTxdCSit7uzCrJNy7KvLBGRSbu4Ub+al29t4J0F+jDLlbzIksLsgAEDVCusfE3sl19+US2l6V36VuaslcuzBnwlKdbeHkOHDlUXMi3SzePrFacQHRuPOsVyYl6317D/SiA27T6AxnWqqxXA2CJLRGTC4mKArcOBvVP124+uA5GP9a2zRCYs3X1mly9frhYuSG0O2GXLlmVUXWRmlh25hX1XH8DZwRajW5eDvZ0tqhfyRJWcOvWVQZaIyIQ9ugHMe+tpkK32IdBjM4MsmYV0t8w+ePAA7u7uKfbLNFcyByxZn/uhURi97py6PrBhcRTIwfl7iYjMxrl/gX/66VthndyBVr8ApVtqXRWR8VpmpYuB9GtNbv369Qnzz5J1GfXvWTwKj0HpPG7oUbuQ1uUQEVFaxUQA67/UB9l8VYA+uxhkyfJbZmUGAunjKgO3GjRooPbJdFo//fRTuvvLkvnbeTEQq47fgfQiGNtW372AiIjMhMxO0H4OcG4N8OZQwN5R64qIjB9mP/jgA0RFRakZBGTlLeHr64vp06erqbTIeoRHx+KblfoVv7rVLIQKPuxbRURk8s6sAuKin84XW+B1/YXImqbmkmVr5SKtsy4uLsiaNWvGV0Ymb8qWS7gVFIF8Hi74rHFxrcshIqLniYkENn0DHJoN2LsAeSsDOYtqXRXRK3upz4RjY2OxZcsWrFixImHlrTt37iA0NPTVKyKzcPr2Y8ze46euj2pdFlmcXnnKYiIiMpYHV4A5jfRBVlT/EMj+cnPEE5madCeQ69evo2nTpmpBA+lu0KhRI2TLlg0//PCD2p4xY4ZxKiWTERsXjyErTiEuXoe3y+dB/ZJeWpdERETPcmoZsOYTIDoUcM0BtPkNKNZI66qItGuZ/eSTT9Tys0FBQaqLgUGbNm3UQDCyfPP3XsOp24/h5myP71uU1rocIiJKjXxy+u9AYHkPfZAtUBPos4dBlixOultmd+/ejb1798LRMemIRxkEJkvMkmW7+TAcP226qK5/3awUvLI5a10SERGlRpahlZZY2ABvfA7U/QqwY5cwsjzp/q6Oj49HXFxciv23bt1S3Q3Ickn/6O/+OY2ImDhUK+SJd6r6aF0SERElFxUKOD0ZmC0BtlhjwKea1lURmU43g8aNGyeZT9bGxkYN/Bo6dCiaNWuW0fWRCfn35F3suBAIRztbjGlTDrZcopaIyHREhwGrPgLmNwdio/T7pCWWQZYsXLpbZmVxhCZNmqB06dKIjIzEu+++i0uXLiFnzpz466+/jFMlae5xeAyGrzmjrn9UvyiKenE6NiIikxFwDljaDQg8D9jYAtd2A0Ubal0VkWmG2fz58+PEiRNYsmSJ+iqtsj169EDnzp2TDAgjyzJ2/TncD41WIbZPPS5bTERkMoO8jv0JrBsMxEYAWb2BdrOBQnW0rowo07xUT3B7e3sVXuVicPfuXQwePBi//PJLRtZHJmD/1QdYfOimuj6ubTk42dtpXRIREUWFAP8OAk79rd8u0gBoMxPImkvryohMN8yeOXMG27dvVzMZvPPOO/Dw8MD9+/fV0rYyv2zhwmyxszSRMXH4eoV+ydrO1Qugqq+n1iUREZFY8ylwehlgYwc0+AaoNRCwfam1kIisI8yuXr0a7du3V6t/ifHjx2PWrFkq1FapUgUrV65UiymQZfl1+2VcvR8Gr2xO+KJpSa3LISIigwbfAvfOAG9PAgrW0LoaIs2k+U+4UaNG4aOPPkJwcDAmTpyIq1evYsCAAVi3bh02bNjAIGuBLt4LwfSdV9T14S3LwN3FQeuSiIisV2QwcHrF023PQkDfvQyyZPXSHGYvXLigwmzWrFnx8ccfw9bWFpMmTcJrr71m3ApJE/HxOrVkbUycDg1L5UbTst5al0REZL3uHAd+ewNY1h24vOXpfnYrIEp7N4OQkBC4ubmp63Z2dmrmAvaRtVyLDt7AketByOJohxGtyqj5hImISIPZCg7OAjZ9A8RFA+4+gJO71lURme8AsI0bN8Ld3T1hJbCtW7fi9OnTSY5p2bJlxlZIme5ecCR+WH9eXR/cpATyenDKNSKiTBfxCFjdHzi3Rr9dohnQahrgyoG4RC8dZrt27Zpk+8MPP0yyLa13qS11S+Zl2OozCImKRQUfD3Sp4at1OURE1uf2EWBpd+DRdcDWAWg8EqjeR/6j1boyIvMNs9ISS5Zv0xl/rD/tD3tbGzWnrB2XrCUiynyBF/VB1qMg0GEekK+K1hURWdaiCWSZQiJj8P0/+iVre79RGKXy6PtIExFRJvWPNbS8VuwExIQBZdsDLh5aV0Zk0tI0DHL//v1pfsDw8HC1uAKZn582XYR/cCQK5nDFgDeLaV0OEZH1uHEAmNMYCHvwdN9rPRlkiTIqzHbp0gVNmjTB0qVLERYWluoxZ8+exddff40iRYrgyJEjaXlYMiFHbwTh933X1PUxbcrB2YFL1hIRGZ104dszGZj3FnDrILBtpNYVEVlmNwMJqtOnT8e3336Ld999F8WLF0fevHnh7OyMoKAgnD9/HqGhoWjTpg02bdqEcuXKGb9yyjAxcfEYsvyU+oSrXeX8qFU0p9YlERFZvrD7wMo+wOXN+u2y7YBGI7Suisgyw6yDg4Na7Usuhw8fxp49e3D9+nVERESgQoUKGDhwIOrXrw9PT04XYo5m7rqKC/dC4JnFEd80L6V1OURElu/af8DyHkDIXcDeGXjrB6ByV85WQJQZA8CqVq2qLmQZ/O6HYcrWS+r6d2+XUoGWiIiM6Ny/wN9dAF08kKMY0GE+4F1W66qIzBZnM7BiOp0O36w8hejYeNQplhOtK+bTuiQiIstXqA7gUQDweR1o/hPglFXriojMGsOsFVt+9Db2XnkAZwdbjG5djkvWEhEZi/9pIHcZfTcCZ3eg13bAJTu7FRBl1mwGZHkehEZh1Nqz6vqnDYujQA5XrUsiIrI88XHA9rHAjNrAodlP98uStAyyRBmCLbNWatTac3gUHoPSedzQs3YhrcshIrI8If7A8p7Atd367YBzWldEZJEYZq3QrouBWHnsNmSl2rFty8Hejg30REQZ6so2YEVvICwQcMgCvD0JqNBR66qIrDfM/vzzz2l+QJm+i0xXeHQsvll1Sl3vVrMQKvhwdRkiogwTFwvsGAvs/kmG2QK5ywLt5wG5imtdGZF1h9lJkyYl2Q4MDFTL1np46IPQo0eP4OrqCi8vL4ZZEzdlyyXcfBiBfB4u+Kwxf7kSEWWoe6eBPfJ/pg6o0h1oOhZwcNG6KiKLlqYw6+fnl3B90aJF+PXXXzFnzhyUKFFC7btw4QJ69eqFDz/80HiV0is7ffsxZu/Rn8uRrcsgixN7mRARZai8FYHGI4Fs3voVvYjI6NLdWfK7777D1KlTE4KskOvSeivL3ZJpiovXYciKU+pr8/J50KBkbq1LIiIyf3ExwNYRQOCFp/tqfMQgS2TKYfbu3buIjY1NsT8uLg737t3LqLoog83few2nbj9GNmd7DG1RWutyiIjM36ObwLxm+v6xS7vpgy0RmX6YffPNN1V3gqNHjybsO3LkCPr27YuGDRtmdH2UAW4FheOnTfpWg6+blYJXNmetSyIiMm/n1+nnjr11EHByB+p9Bdg5aF0VkVVKd5idO3cuvL29UbVqVTg5OalLtWrVkDt3bsyenWhCaDKZJWu//+cMwqPjUM3XEx2r+mhdEhGR+YqNBjYMARZ3AiIfAXkrA312AaVbaV0ZkdVK9wigXLlyYd26dbh48SLOnz+v9pUsWRLFi3NkvClae+outp0PgKOdLca0LQdbmVyWiIjSL+w+sLADcOfJJ5OvfwQ0HAbYO2pdGZFVe+nh7L6+vqrVr0iRIrC356h4U/Q4PAbDVuuXrP2oflEU9cqqdUlERObL2QOwd9Z/bT0dKNlM64qI6GW6Gcj8sj169FDzypYpUwY3btxQ+z/++GOMGzfOGDXSSxq7/hzuh0apENunXmGtyyEiMj+xUfquBcLOHmg/B+izm0GWyJzD7JAhQ3DixAns2LEDzs5PBxLJ4K8lS5ZkdH30kvZffYDFh26q67JkrZO9ndYlERGZlwdXgNkNgS1Dn+5zywt4FNCyKiJKJt39A1atWqVC6+uvvw4bm6f9L6WV9sqVK+l9ODKCyJg4fL1Sv2Ttu9UL4DVfT61LIiIyL6eXA6s/AaJDgODbQJ3PgSw5tK6KiDIizMpStrJsbXJhYWFJwi1p59cdV3A1MAy5sjnhy6YltS6HiMh8xEQAG74CjszXbxeoCbSbzSBLZEndDGRKrrVr1yZsGwKsTMtVo0aNjK2O0u3SvRBM33FZXR/esgzcXTjvIRFRmgReBGa9+STI2uhbY7uuAdzzaV0ZEWVky+yYMWPw1ltv4ezZs2olsClTpqjre/fuxc6dO9P7cJSB4p8sWRsTp0PDUl54q6y31iUREZnPQK8FrYCQO0CWXEDbmUCRBlpXRUTGaJmtXbu2GgAmQbZcuXLYtGmT6nawb98+VKlSJb0PRxnor0M3cPh6ELI42mFEq7Ls9kFElFb2TkDTMYBvHaDPHgZZIkttmY2JiVFL2X733XeYNWuW8aqidLsXHIlx6/SLWAxuUgJ5PVy0LomIyLQFnAPCHwK+tfTbZdoApVtL/zmtKyMiY7XMOjg4YPny5em5C2WS4WvOICQqFhV8PNClhq/W5RARmS6dDjj2JzCzPvD3+0CI/9PbGGSJLL+bQevWrdX0XGQ6Np+9h3Wn/GFva4NxbcvBjkvWEhGlLioUWNkH+OcjIDYC8C4H2HAebiKrGgBWrFgxjBgxAv/995/qI5slS5Yktw8YMCAj66MXCImMwXerTqvrvd4ojFJ53LQuiYjINPmfBpZ2Ax5cAmxsgfrfALUHAbbpbtchInMOs3PmzIGHhweOHDmiLonJgCOG2cz106aL8A+ORMEcrvjkzWJal0NEZJrdCmS6LZk/NjYSyJZXvyxtwZpaV0ZEWoRZPz+/jHheygDHbgTh933X1PXRrcvB2YEflRERpSD9YG8e0AfZoo2ANr9xEQQiaw6zZBpi4uLVnLLS4NC2cj7ULpZT65KIiEyL/II0DOhq9iPgUw2o3I3dCoisPcx+8MEHz7197ty5r1IPpdGs3Vdx3j8E2V0d8G3z0lqXQ0RkWiH20GzAbyfQYYE+vDplBao+//8vIrKSMBsUFJRi7tnTp0/j0aNHaNCAk0xnhmv3wzBlyyV1/bu3S8Mzi6PWJRERmYaIR8CaAcDZf/Tb59cApVtpXRURmVKYXblyZYp98fHx6Nu3L4oUKZJRddEz6HQ6fLPqFKJi41GnWE60qcQ1w4mIlNtHgKXdgUfXAVsHoNEIoFRLrasiIiPLkI5Dtra2GDRoECZNmpQRD0fPseLobfx3+QGcHWzVoC8uWUtEVk+6Fez7FZjTRB9kPQoAPTYCNfpxEQQiK5BhA8CuXLmC2NjYjHo4SsWD0CiMWntWXf+0YXEUyOGqdUlERNpb/wVwcKb+eqkWQMtfABcPrasiIlMNs9ICm/xj77t372Lt2rXo2rVrRtZGyYxaew5B4TFqYYQetQtpXQ4RkWmo8D/g+CKg4TDgtZ5sjSWyMukOs8eOHUvRxSBXrlz46aefXjjTAb28XRcDsfLYbfU7WpasdbDj1DJEZKXi44F7p4E85fXb+aoAn54CXD21royIzCHMbt++3TiV0DNFRMepQV+iW01fVPDhx2dEZKXCHgCr+gBXdwI9tzwNtAyyRFYr3c17Mv2WTMOVXHBwMKfmMpLJWy/i5sMI5HV3xmeNS2hdDhGRNq7vBWbUBi5t0m8/0E9RSETWLd0tszt27EB0dHSK/ZGRkdi9e3dG1UVPnLnzGLN365cQHtGqLLI6cdE2IrLCbgV7JgLbxwC6OCBHUaDD74B3Wa0rIyITkOZkdPLkyYTrZ8+ehb+/f8J2XFwcNmzYgHz5OOdpRoqL16kla+Vr83J50LB0bq1LIiLKXKGBwMrewJVt+u3yHYHmE/UrehERpSfMVqxYUc1pKpfUuhO4uLhg6tSpGV2fVft97zWcvPUY2ZztMbQll6wlIit0cok+yNq7AM1/BCp25mwFRPRyYdbPz09Nw1W4cGEcPHhQzWBg4OjoCC8vL9jZ2aX14egFbj+KwI+bLqjrXzcrBa9szlqXRESU+V7vBwT56afc8iqldTVEZM5htmDBgglL15JxyR8N3606jfDoOFTz9UTHqj5al0RElDlC/IGdPwBNxgAOLjL/I9D8J62rIiIT9lKjiS5cuKC6FJw7d05tlypVCv3790fJkiUzuj6rtPbUXWw7HwBHO1uMaVsWtrb8SI2IrIB0J1jRGwgLBGztgWYTtK6IiCxxaq7ly5ejbNmyOHLkCCpUqKAuR48eRbly5dRt9Goeh8dg2Gr9krX96hdBUa9sWpdERGRccbHA1pHAH231QdarDPBaL62rIiJLbZn94osvMGTIEIwYMSLJ/qFDh6rb2rVrl5H1WZ1xG87hfmgUiuTKgr71imhdDhGRcQXfAZb1AG7s1W9X6QY0HafvYkBEZIyW2bt37+L9999Psf+9995Tt9HLO3D1Af46eFNdH9u2PJzsOaCOiCzYjf36RRAkyDpmBdrNAVpMYZAlIuOG2Xr16qW6OMKePXtQp06d9D4cPREVG4chK/VL1naqVgDVCnFpRiKycO75AV084F0e+HAXUK691hURkTV0M2jZsiW+/PJL1Wf29ddfV/v279+PpUuXYvjw4Vi9enWSYyltft1+BVcDw5ArmxO+eosD6YjIQkU+Bpzdn4bZrmuAHMUAB04/SESZFGb79eunvv7666/qktptQhZXkJXB6MUuB4Tg1x2X1fXhLcvA3cVB65KIiDLehfXAqr5Aq1+Bks30+7zLaV0VEVlbNwOZZzYtFwbZtIl/smRtTJwODUt54a2y3lqXRESUsWKjgY3fAH/9D4gIAg7N1roiIrL2eWYp4yw+dBOHrgUhi6MdRrQqq1q0iYgsRtA1YNkHwO0jT1f0ajhc66qIyNrDbFhYGHbu3IkbN24gOjo6yW0DBgzIqNosXkBwJMau1y888XmTEsjrwRG8RGRBzq4G/ukPRD3pJ9t6OlCyudZVEZG1h9ljx46hWbNmCA8PV6HW09MT9+/fh6urK7y8vBhm02HYmjMIiYxFhfzueL+Gr9blEBFlnLsngL+76K/nfw1oPxfwKKB1VURkgdLdZ3bgwIFo0aIFgoKC4OLiomYyuH79OqpUqYIff/zROFVaoM1n72HdKX/Y2dqoOWXlKxGRxchTAajaA6g5AOi+nkGWiEwnzB4/fhyfffYZbG1tYWdnh6ioKPj4+GD8+PH4+uuv013AtGnT4OvrC2dnZ1SvXh0HDx587vGPHj3CRx99hDx58sDJyQnFixfHunXrYE5Co2Lx/T+n1fVedQqjdF43rUsiInplNudWAyH3nu5o/hPQeCRgxxlaiMiEwqyDg4MKskK6FUi/WeHu7o6bN/WrV6XVkiVLMGjQILUU7tGjR1GhQgU0adIEAQEBqR4v/XMbNWqEa9euYdmyZbhw4QJmzZqFfPnywZz8uPEC7j6ORAFPV3zyZjGtyyEiejUxESh/Yx7sV3wArOgJxD+ZzYYDWonIFPvMVqpUCYcOHUKxYsVQt25dfP/996rP7B9//IGyZcum67EmTpyIXr16oXv37mp7xowZWLt2LebOnYuvvvoqxfGy/+HDh9i7d68K1UJadZ9HWo7lYhAcHKy+xsTEqEtmO3HrMX7fd01dH9GyFOxt4hETEw9LZHh/tXifSRs851bowSXYLe+BQg/OQgcbxOepgviYaMCWk+VYMv6sW5+YTD7n6XkeG51Op0vPgx8+fBghISGoX7++akF9//33VbiUcCthU1pX00JaWWXQmLSwtm7dOmF/165dVVeCf/75J8V9ZOCZDDiT+8ntuXLlwrvvvqtWJJMuD6kZNmyYWpksuUWLFqnHyUxx8cCPp+xwJ9wGr+WKx3tFLTPEEpF1yP9wLyrcnAf7+ChE2WfDkYJ9EOjGRRCI6NXJRAOS8R4/fgw3t+d3x0z3n85Vq1ZNuC7dDDZs2PBSRUprriyskDt37iT7Zfv8+fOp3ufq1avYtm0bOnfurPrJXr58Wa06JulduiqkZsiQIaorQ+KWWenj27hx4xe+ORntt11+uBN+CdldHfBLj1rwzOIISybnZfPmzapriKElnSwbz7mViAmH3cYhsL2+UG3G+dTEDveOqNPsHZ53K8GfdesTk8nn3PBJelqkOcxGRESoFyEtstmyZUvxhDt27FD9XWVQlrHIymISoGfOnKlaYmUGhdu3b2PChAnPDLNST2o1yYkw9smIi9fhoN9DBIREQhrAf96mX7L2u7dLI7dHFliLzHivybTwnFu4eDvg9iH5cA+o+yXiaw5E5IaNPO9WiOfc+jhk0jlPz3OkOcxKgFy9ejVatmyZ4jZp4fz555/VADCZaSAtcubMqQLpvXuJRr4CatvbO/UlXWUGA3lxibsUlCpVCv7+/qrbgqOj6bR0bjh9F8PXnFUDvRIr6Z0NbSqZ14A1IiJFeqXJoC6nrECH+UBYIFC4njTZaF0ZEVmxNM9msHDhQnz66afPvF1u+/3339P8xBI8pWV169atSVpeZbtGjRqp3qdWrVqqa4EcZ3Dx4kUVck0tyPb982iKICvO+4dg4xl/TeoiInopUaHAyj7AvmlP9+Uuow+yRETmEmYvXbr03MFd5cuXV8ekh/Rllam1JASfO3cOffv2VauKGWY3kMFl0ufVQG6X2Qw++eQTFWJl5oMxY8akuTU4M0jXAmmRfdaoOpmoRm6X44iITN69M8Cs+sCJv4BtI4HQ1KdOJCLSSpq7GcTGxiIwMBAFCqS+iovcJsekR8eOHdX9ZHov6SpQsWJFNaDMMChM5rA1zGkrZODWxo0b1SpkEp5lflkJtjKbgamQPrKptcgaSISV2+W4GkVyZGptRETp6lJw9Hdg/ZdAbCSQLQ/Qbg6Q1UvryoiIXi7MlilTBlu2bFFdA1KzadMmdUx69e/fX11SI4PKkpMuCLKErqmSwV4ZeRwRUaaLDAb+/RQ4vVy/XbQh0OY3IEtOrSsjInr5bgYffPABRo4ciX///TfFbWvWrMHo0aPVMdbOK5tzhh5HRJSp4mKAOY30QdbGDmg4HHh3KYMsEZl/y2zv3r2xa9cuNZtByZIlUaJECbVf5oSV/qvvvPOOOsbaVSvkiTzuzvB/HJlqv1npM+vt7qyOIyIyOXYOQKUuwP7pQPu5QIHqWldERJQxLbPizz//xOLFi1G8eHEVYC9cuKBC7V9//aUuBNjZ2mBoi9LqevJVyQ3bcrscR0RkEiIfAw+uPN2u8RHQby+DLBGZhXSvACYtsHKhZ2taNg+mv1c5xTyz0iIrQVZuJyIyCbePAku76Vtke+8AnLLp55J1dte6MiIi44RZShsJrI1KeyesACZ9ZKVrAVtkichkZis4MAPY9B0QHwN4FACC7wK5kq7wSERk6hhmjUiCK6ffIiKTExEE/NMfOP9kQG/Jt4FW0wAXD60rIyJKN4ZZIiJrcvMQsOwD4PENwM4RaDwaqNZL37WAiMgMMcwSEVmTnT/og2z2QkCHeUDeSlpXRESUebMZpCY4OBirVq1Sy9ESEZGJk+4EVT8APtzFIEtE1hlmZSaDX375RV2PiIhA1apV1T5ZXnb58ierxRARkWm4vg/YNvrpdrbcwNuTAGc3LasiItIuzMrCCXXq1FHXV65cCZ1Oh0ePHuHnn3/GqFGjMq4yIiJ6efHxwO6fgPnNgV3jgXMpV28kIrLKMPv48WN4eupXr9qwYQPatWsHV1dXNG/eHJcuXTJGjURElB6hgcDCdsDWEYAuDijfEShcT+uqiIhMYwCYj48P9u3bpwKthFlZEUwEBQXB2dnZGDUSEVFa+e0GlvcEQv0Bexeg2QSg0nucrYCILFa6w+ynn36Kzp07I2vWrChYsCDq1auX0P2gXLlyxqiRiIjSYt80YNO3gC4eyFkCeOd3wKuU1lUREZlWmO3Xrx+qV6+OGzduoFGjRrC11fdUKFy4MEaPTjTIgIiIMpdnYX2QrdhZ3yLrmEXrioiITK/P7IgRI1CqVCm0adNGtc4aNGjQAFu2bMno+oiI6HkiHj29XuItoNd2oPWvDLJEZDXSHWaHDx+O0NDQFPvDw8PVbURElAniYoFto4CplYFHN5/uz1dZy6qIiEw/zMpUXDapDCQ4ceJEwiwHRERkRMF3gAUtgV0TgPAHwNl/tK6IiMj0+8xmz55dhVi5FC9ePEmgjYuLU621ffr0MVadREQkLm0BVvbWh1jHrECLKUC59lpXRURk+mF28uTJqlX2gw8+UN0J3N3dE25zdHSEr68vatSoYaw6iYisW1wMsH00sGeSftu7HNDhdyBHEa0rIyIyjzDbtWtX9bVQoUKoVasW7O3TPRECERG9rP3TnwbZ13oBjUcBDpzbm4go3X1mw8LCsHXr1hT7N27ciPXr12dUXURElFi1XkCBmvrW2OY/MsgSEb1smP3qq69UH9nkpAuC3EZERBkgNho4NAeIf/L71sEF6L4OKNNa68qIiExKuvsKXLp0CaVLl06xv2TJkrh8+XJG1UVEZL2CrgPLugO3j+gHetX9Qr+fS9ISEb16y6wM/Lp69WqK/RJks2ThJN1ERK/k3Brgtzr6IOvsDuQuo3VFRESWFWZbtWqFTz/9FFeuXEkSZD/77DO0bNkyo+sjIrIOsVHAui+AJe8BkY+B/K8BffYAJZtrXRkRkWWF2fHjx6sWWOlWIDMbyEWWt82RIwd+/PFH41RJRGTJHl4F5jQGDv6m3675MdB9PeBRQOvKiIgsr8+sdDPYu3cvNm/erFb9cnFxQfny5fHGG28Yp0IiIksXHQYEnANcsgNtfgOKN9G6IiIis/FSk8XK6l+NGzdWFyIiegk63dMBXWoBhHlAngqAe36tKyMisvwwK3PN7ty5Ezdu3EB0dHSS2wYMGJBRtRERWab7l4EVvYBmPwL5q+j3sW8sEVHmhNljx46hWbNmCA8PV6HW09MT9+/fh6urK7y8vBhmiYie5+RS4N9PgehQYP1goOdWTrlFRJSZA8AGDhyIFi1aICgoSPWX3b9/P65fv44qVapwABgR0bNEhwP/9AdW9NQHWd86wP8WMcgSEWV2mD1+/LiahsvW1hZ2dnaIioqCj4+PmuXg66+/ftV6iIgsT+AFYPabwLE/ZNQBUPcr4P1/gGzeWldGRGR93QwcHBxUkBXSrUD6zcrUXDLLwc2bN41RIxGR+ZJZCmY1AGLCgSxeQLvZQOG6WldFRGS9YbZSpUo4dOgQihUrhrp16+L7779XfWb/+OMPlC1b1jhVEhGZq1wlgUJvADERQNtZQLbcWldERGTd3QzGjBmDPHnyqOujR49G9uzZ0bdvXwQGBmLmzJnGqJGIyPxaY6NC9delT2y7OUCXlQyyRERat8zqdDrVtcDQAivXN2zYYIy6iIjMc+7YowuA9V8ApVvpF0CQMOuUVevKiIgslm16w2zRokXZN5aIKLmoEP3csWsGALGRQPgDIDZK66qIiCxeusKsDPySvrIPHjwwXkVERObm7kngt7rAqaWAjR3QcBjw7lLAwVnryoiILF66+8yOGzcOgwcPxunTp41TERGROXUrODQbmN0QeHgFcMsHdF8H1B4of/1rXR0RkVVI92wG77//vlr9q0KFCnB0dFQLJyT28OHDjKyPiMh0RQQBO8YBcVFA8beA1r8Crp5aV0VEZFXSHWYnTZoEG65YQ0SkD64y3VbAWeD1flzNi4jIHMJst27djFMJEZE5dCs48Jt+5a4yrfX7itTXX4iIyDzCrCxhe/fuXTUtV2IyKEz2xcXFZWR9RESm06Xgn/7A+X8Bx2yATzXALa/WVRERWb10h1mZnis1UVFRqg8tEZHFuXUYWNodeHwDsHME3vweyKZfPIaIiMwkzP7888/qq/SXnT17NrJmfToJuLTG7tq1CyVLljROlUREWoiPB/ZPA7YMA+JjgeyFgA7zgLyVtK6MiIjSG2Zl4JehZXbGjBmqu4GBtMj6+vqq/UREFiEuFljyHnBxvX67TBugxc+As5vWlRER0cuEWT8/P/W1fv36WLFiBbJnz57WuxIRmR87e8CzMGDnBLw1DqjSnbMVEBFZQp/Z7du3G6cSIiJT6FYQFQy4eOi3ZSWvyu8DXuxCRURkMWFW+sfOnz8fW7duRUBAAOLll38i27Zty8j6iIgyR9h9YOWHQFQo0O1fwM4BsHdkkCUisrQw+8knn6gw27x5c5QtW5YLKBCR+bu2B1jeEwi5C9i7AHdPAvmraF0VEREZI8wuXrwYf//9N5o1a5beuxIRmZb4OGD3T8COsYAuHshZAugwH8hdWuvKiIjIWGFWZi4oWrRoeu9GRGRaQu4BK3oBfjv12xU7A80mAI5ZtK6MiIjSwRbp9Nlnn2HKlCnPXDyBiMgsSP9YCbIOrkDrGUDrXxlkiYisoWV2z549akaD9evXo0yZMnBwcEhyu0zbRURk8t4aD/zzEdBqGpCruNbVEBFRZoVZDw8PtGnT5mWfj4hIG8F39QO9ynfQb0uA7bGJc8cSEVlbmJ03b55xKiEiMpbLW4AVvYGIIMAtL+BbS7+fQZaIyPrCrEFgYCAuXLigrpcoUQK5cuXKyLqIiDJmSdrto4A9+uW44V0OyJpb66qIiEjLAWBhYWH44IMPkCdPHrzxxhvqkjdvXvTo0QPh4eEZWRsR0ct7fAuY3/xpkH2tJ9BjC5CTs7EQEVl1mB00aBB27tyJNWvW4NGjR+ryzz//qH0y0wERkeYubgRm1AZu7gec3PRzxzb/CXBw1royIiLSupvB8uXLsWzZMtSrVy9hnyyg4OLignfeeQfTp0/P6BqJiNLn8U19/9g8FYEO8wDPwlpXREREphJmpStB7twp+5x5eXmxmwERaUfmvjYM6KraQ78sbbn2gL2T1pUREZEpdTOoUaMGhg4disjIyIR9ERERGD58uLqNiCjTnfsXmFkXiHik35ZQW6kzgywRkRVId8usrP7VpEkT5M+fHxUqVFD7Tpw4AWdnZ2zcuNEYNRIRpS42Ctg8FDjwpHvTvl+ABt9qXRUREZlymC1btiwuXbqEhQsX4vz582pfp06d0LlzZ9VvlogoUzy8CiztDtw9rt+u+TFQ90utqyIiInOYZ9bV1RW9evXK+GqIiNLizEpg9QAgKhhw8QTazACKN9G6KiIiMuU+s0eOHEH9+vURHByc4rbHjx+r26S7ARGRUR2eByztpg+yPq8DffYwyBIRWbE0h9mffvoJDRo0gJubW4rb3N3d0ahRI0yYMCGj6yMiSqpUS8AtP1B7ENBtLeCeT+uKiIjIHMLsgQMH0KpVq2fe3qJFC+zduzej6iIieurmwafXs+QAPtoPNBwK2L30itxERGRtYfb27dvIli3bM2/PmjUr7t69m1F1EREBMRHA6o+BOY2AYwuf7nd69u8iIiKyLmkOs7ly5cKFCxeeebvMbJAzZ86MqouIrF3gBWBWA+DoApk4Fgj117oiIiIy5zDbsGFDjB49OtXbdDqduk2OISJ6Zcf/AmbWAwLOAlm8gPdXAXU+07oqIiIyQWnucPbtt9+iSpUqqF69Oj777DOUKFEioUVWBoddvHgR8+fPN2atRGTposOAdYOB40+6FBSuB7SdBWT10royIiIy9zBbpEgRbNmyBd26dcP//vc/2DxZA11aZUuXLo3NmzejaNGixqyViCzdnWPA8UWAjS1Q72ugziDA1k7rqoiIyISlayhw1apVcfr0aRw/flytAiZBtnjx4qhYsaLxKiQi6+FbG2g8CshbUX+diIjoBV5qXhsJrwywRPTKokKATd8CtT4BPAvr99Xsr3VVRERkRjhJIxFpw/+UfiWvB5eBe2eAHpuBJ92XiIiI0ophlogyl04HHJ4LbBgCxEUBbvn0XQsYZImI6CUwzBJR5ol8DKz5BDizUr9dvCnQejrg6ql1ZUREZMnzzLZt2xbBwcHq+oIFCxAVFWXsuojI0gRdA36rqw+ytvZA49FAp8UMskREZPww+++//yIsLExd7969Ox4/fvxqz0pE1idbXsDFA3AvAHywUT/Qi10LiIgoM7oZlCxZEkOGDEH9+vXVdFx///033NzcUj32/ffff9WaiMhSRDwCHLMCdvaAvSPQ8U/AMQvgkl3ryoiIyJrC7IwZMzBo0CCsXbtWLZYgq4EZFk1ITPa9TJidNm0aJkyYAH9/f1SoUAFTp05FtWrVXni/xYsXo1OnTmjVqhVWrVqV7uclIiO6dRhY1h0o1wF483v9Pvf8WldFRETW2M2gZs2a2L9/PwIDA1XLrCxdGxQUlOLy8OHDdBewZMkSFZSHDh2Ko0ePqjDbpEkTBAQEPPd+165dw+eff446deqk+zmJyIh0OtjunwbMbQI8uqHvIyvL1BIREWkVZhPz8/NDrly5MqyAiRMnolevXqovriyLK63Arq6umDt37jPvExcXh86dO2P48OEoXPjJROtEpL3wh6h+dRLstg4F4mOB0q2B3jv0XQuIiIhMYWquggUL4tGjR5gzZw7OnTun9kkI7dGjB9zd3dP1WNHR0Thy5Ijqj2tga2uLhg0bYt++fc+834gRI+Dl5aWec/fu3c99Dpl5IfHsC4ZZGWJiYtSFjMfw/vJ9tg42tw7CbkVPeIfcgc7OCfGNRiK+cnf9IC9+D1g0/qxbH55z6xOTyec8Pc+T7jB7+PBh1Q3AxcUloV/rpEmTMGbMGGzatAmVK1dO82Pdv39ftbLmzp07yX7ZPn/+fKr32bNnjwrSx48fT9NzjB07VrXgJie1SgswGd/mzZu1LoGMzD4uHI3PDIJtXDhCnXLjkG9/BN/zBtav17o0ykT8Wbc+POfWZ3MmnfPw8HDjhdmBAweiZcuWmDVrFuzt9XePjY1Fz5498emnn2LXrl0wlpCQEHTp0kU9d86cOdN0H2n1lT65iVtmfXx80Lhx42fOyEAZ91eVfNM3atQIDg4OWpdDRmZTMBaxl7dip0NT1G/akufcivBn3frwnFufmEw+54ZP0o3WMps4yKoHsbfHF198gapVq6brsSSQ2tnZ4d69e0n2y7a3t3eK469cuaIGfrVo0SJhX3x8fEINFy5cQJEiRZLcx8nJSV2SkxPBH8DMwffaQl37T7/4QYHq+u0qXRBTriNi16/nObdSPO/Wh+fc+jhk0jlPz3OkewCYtGbeuHEjxf6bN28iW7Zs6XosR0dHVKlSBVu3bk0STmW7Ro0aqc53e+rUKdXFwHCRVmKZ/1auS4srERlZfBywcwLw+9vA0m5A2IOnt3ERBCIiymTpbpnt2LGjGnj1448/qim7xH///YfBgwerOV/TS7oAdO3aVbXqSh/cyZMnq9XGZHYDIfPW5suXT/V9dXZ2RtmyZZPc38PDQ31Nvp+IjCA0AFjRC7i6Q79duB7g4Kx1VUREZMXSHWYlxBoWR5C+soam4L59+2LcuHF4mXAs89d+//33atGEihUrYsOGDQmDwqQVWGY4ICKNXd0JLO8JhAUADq5A85+Aiu9qXRUREVm5dIdZ6RowZcoU1VIqfViF9FN9lZkB+vfvry6p2bHjSQvQM8yfP/+ln5eI0kD6pe8cB+wcLysiAF6lgQ7zgVwltK6MiIgo/WHWQMJruXLlMrYaIjI90g82UKbK0wGV3wea/gA4clo7IiIy8zBLRFbQIitdfCTMtpwKlGkLlGmtdVVERERJsDMqESUVFwtsGQYs6w7odPp9zu4MskREZJLYMktETz2+BSzrAdzcr9++/h/gW1vrqoiIiJ6JYZaI9C5uBFZ+CEQEAU5uQMufGWSJiMgyw+ylS5ewfft2BAQEJKzAZSBTbBGRGYmLAbYOB/ZO1W/nqQh0mAd4Fta6MiIioowPs7KUrcwpK0vRypKzMuesgVxnmCUyM8s+AM6t1l+v3gdoNAKwT7kENBERkUWE2VGjRmH06NH48ssvjVMREWWu1/vq+8a2+Bko9bbW1RARERk3zAYFBaFDhw7pvRsRmYrYKMD/FJC/qn67YE3g01OAYxatKyMiIjL+1FwSZDdt2pT+ZyIi7T30A+Y0Bn5vAQReeLqfQZaIiKylZbZo0aL47rvvsH//frUCmIODQ5LbBwwYkJH1EVFGObMKWP0xEBUMuGQHQvy5JC0REVlfmJ05cyayZs2KnTt3qktiMgCMYZbIxMREApu+AQ7N1m/7VAfazwXc82tdGRERUeaHWT8/v1d/ViLKHA+uAEu76vvIitoDgfrfAHZJP1EhIiKyykUTdE+Wukw8PRcRmZCTS/RB1jUH0GYmUKyh1hURERFpOwBMLFiwQPWXdXFxUZfy5cvjjz/+yNjKiOjVvfEF8PpHQJ89DLJERGSR0t0yO3HiRDUArH///qhVq5bat2fPHvTp0wf379/HwIEDjVEnEaVF4EVgz0SgxRT9wgd29kDTMVpXRUREZDphdurUqZg+fTref//9hH0tW7ZEmTJlMGzYMIZZIq0c/wtYOwiICQfc8gFvfqd1RURERKYXZu/evYuaNWum2C/75DYiymTRYcC6wcDxhfrtQnWBar21roqIiMg0+8zKPLN///13iv1LlixBsWLFMqouIkqLgHPArAb6IGtjq5+poMtKIFturSsjIiIyzZbZ4cOHo2PHjti1a1dCn9n//vsPW7duTTXkEpGRnF8LLOsBxEYAWb2B9nMA39paV0VERGTaYbZdu3Y4cOAAJk2ahFWrVql9pUqVwsGDB1GpUiVj1EhEqfEqpZ8vtmBNoM1vQNZcWldERERkHvPMVqlSBX/++WfGV0NEzxca+DS0ehYGem4BchQDbF9qlj0iIiKzl6b/AYODg5Ncf96FiIxAFig5NAeYXA64su3p/lwlGGSJiMiqpallNnv27GqmAi8vL3h4eKS64pesBib74+LijFEnkfWKfAys+QQ4s1K/fWoZUKSB1lURERGZT5jdtm0bPD091fXt27cbuyYiMrhzDFjaHQjyA2ztgYbD9Ct6ERERUdrDbN26dROuFypUCD4+PilaZ6Vl9ubNm2l5OCJKS7eCgzOBTd8CcdGAewGg/VzA5zWtKyMiIjIp6e5sJ2E2MDAwxf6HDx+q24goA/jtBNZ/oQ+yJd8G+uxikCUiIsqI2QwMfWOTCw0NhbOzc3ofjohSU7geULkr4FUaqP4hkMrPHBEREaUjzA4aNEh9lSD73XffwdXVNeE2GfQlc89WrFjROFUSWcVsBbOBMm2BLDn0+1r+rHVVRERElhNmjx07ltAye+rUKTg6OibcJtcrVKiAzz//3DhVElmy8IfAqr7AxQ3Apc1Ap8WcbouIiCijw6xhFoPu3btjypQpcHNzS+tdiehZbhwAln0ABN8C7JyA4o3ZpYCIiMiYfWYnT56M2NjYVAeA2dvbM+QSpUV8PLB3CrB1JKCLAzyLAB3mA3nKa10ZERGRWUn3Z5n/+9//sHjx4hT7//77b3UbEaWhW8GiDsCWYfogW7Y98OFOBlkiIqLMCLMy0Kt+/fop9terV0/dRkQvYGML3L8E2DsDLX4G2s0GnLJpXRUREZF1dDOIiopKtZtBTEwMIiIiMqouIsvrViB9YeXi4gG8swCwcwByl9G6MiIiIutqma1WrRpmzpyZYv+MGTNQpUqVjKqLyHKEBgB/tgEOz3m6L29FBlkiIiItWmZHjRqFhg0b4sSJE3jzzTfVvq1bt+LQoUPYtGlTRtREZDmu7gRW9AJC7wF3TwDlO7JLARERkZYts7Vq1cK+ffvg4+OjBn2tWbMGRYsWxcmTJ1GnTp2MrI3IfMXHAdvHAAta6YNsrlJA9w0MskRERFq3zApZ6WvhwoUZXQuRZQi+q2+NvbZbv12pC/DWeMDx6ap5REREpGGYNYiMjER0dHSSfZxnlqxaVCgwsx4Q6g84ZAFaTAbKv6N1VURERBYr3d0MwsPD0b9/f3h5eSFLlizInj17kguRVXPKClTrCeQuq587lkGWiIjItMLs4MGDsW3bNkyfPh1OTk6YPXs2hg8fjrx582LBggXGqZLIlD2+DTy48nS79iCg51YgZzEtqyIiIrIK6e5mIAO+JLTKIgndu3dXg75kAFjBggVVP9rOnTsbp1IiU3RxI7CyD5AtD9BrK+DgAtja6S9ERERkei2zDx8+ROHChRP6x8q2qF27Nnbt2pXxFRKZorgYYNO3wKJ3gIiHgJ09EBGkdVVERERWJ91hVoKsn5+ful6yZEk1PZehxdbDwyPjKyQyNY9uAPPeAvZO1W9X+xDosRlwy6t1ZURERFYn3d0MpGuBLJhQt25dfPXVV2jRogV++eUXtZztxIkTjVMlkak4vxZY1ReIfAw4uQOtfgFKt9S6KiIiIquV7jA7cODAhOuyEtj58+dx5MgR1W+2fPnyGV0fkemIj9e3xkqQzVsZ6DAPyO6rdVVERERWLV1hVlpfmzZtihkzZqBYMf1IbRn4JRcii2drC7SbDRyeC9T9CrB31LoiIiIiq5euPrMODg5q2Voiq3FmFbBt9NNt9/zAm98zyBIREZnrALD33nsPc+bMMU41RKYiJhJY+xmwtCuwazzgx5k6iIiILKLPbGxsLObOnYstW7agSpUqahWwxDgIjMyeLICwtBvg/+RTiFqfAgVqaF0VERERZUSYPX36NCpXrqyuX7x4McltNjY2GVcZkRZOLQPWfAJEhwKuOYA2M4FiDbWuioiIiF41zF69ehWFChXC9u3b03oXIvOy8Rtg3y/66wVr6Qd7ce5YIiIiy+gzK7MXBAYGJmx37NgR9+7dM1ZdRJkvXxX5fAF4YzDw/moGWSIiIksKszqdLsn2unXrEBYWZoyaiDJPaMDT62XbAh8dBBp8q1+eloiIiCxvNgMiixAdBqzqB0yvBYQk+oQhV3EtqyIiIiJjhVkZ3JV8gBcHfJFZCjgHzGoAHF8IhN8H/HZqXRERERG9JPv0dDPo1q0bnJyc1HZkZCT69OmTYmquFStWvGwtRMYlXWWO/QmsGwzERgBZvfWDvArV0boyIiIiMnaY7dq1a4rFE4jMRlQo8O9A4NTf+u0iDfTTbmXNpXVlRERElBlhdt68ea/yPETa2jVBH2Rt7IAG3wC1BgK27DJORERk7jhkm6yDTLd19zhQ9yugIFfzIiIishRsmiLLFBkM7J2q7ycrnLIC7//DIEtERGRh2DJLlufOcWBZd+DhVf12zY+1roiIiIiMhGGWLIe0wh6cBWz6BoiLBtx9AJ/Xta6KiIiIjIhhlixDxCNgdX/g3Br9donmQKtfAFdPrSsjIiIiI2KYJfN3+yiwtCvw6AZg6wA0HglU7yOremhdGRERERkZwyxZRveC4DuAR0GgwzwgXxWtKyIiIqJMwjBL5ik+DrC101/PXwXouBAo8Drg4qF1ZURERJSJODUXmZ8bB4Bp1QD/U0/3lWjKIEtERGSFGGbJfMTHA3smA/PeAh5cBraO0LoiIiIi0hi7GZB5CLsPrOwDXN6s3y7bDnh7stZVERERkcYYZsn0Xd8LLPsACLkL2DsDb/0AVO7K2QqIiIiIYZZM3PV9wPzmgC4eyFEM6DAf8C6rdVVERERkIhhmybT5VAN86wDZ8gDNfwKcsmpdEREREZkQhlkyPTf2A3kqAA4u+um33l2iv05ERESUDGczINOaO3b7WGBuU2DDkKf7GWSJiIjoGdgyS6YhxB9Y3hO4tlu/HR+TdGEEIiIiolQwzJL2Lm8FVvQGwu8DDlmAtycBFTpqXRURERGZAYZZ0k5cLLBjDLB7IgAdkLss0H4ekKu41pURERGRmWCYJe2EBQKH5+qDbJXuQNOx7B9LRERE6cIwS9pxywO0+Q2ICgHKtde6GiIiIjJDDLOUeeJigG0jgQI1gBJv6fcVb6J1VURERGTGTGJqrmnTpsHX1xfOzs6oXr06Dh48+MxjZ82ahTp16iB79uzq0rBhw+ceTybi0U1gXjPgvynAqr5AxCOtKyIiIiILoHmYXbJkCQYNGoShQ4fi6NGjqFChApo0aYKAgIBUj9+xYwc6deqE7du3Y9++ffDx8UHjxo1x+/btTK+d0sbm4npgRm3g1kHAyR1o8TPg4qF1WURERGQBNA+zEydORK9evdC9e3eULl0aM2bMgKurK+bOlYFBKS1cuBD9+vVDxYoVUbJkScyePRvx8fHYunVrptdOLxAXjbK3FsJ+aRcg8hGQtzLQZxdQuqXWlREREZGF0LTPbHR0NI4cOYIhQ56u9mRra6u6Dkira1qEh4cjJiYGnp6eqd4eFRWlLgbBwcHqq9xHLmQkMeGwXdASRQKPq8246n0RX/87wM5R3nytqyMjMfxM8WfLuvC8Wx+ec+sTk8nnPD3Po2mYvX//PuLi4pA7d+4k+2X7/PnzaXqML7/8Ennz5lUBODVjx47F8OHDU+zftGmTagEm46kQkx157bLgWMFe8I+uDGzconVJlEk2b96sdQmkAZ5368Nzbn02Z9I5l8ZKq5jNYNy4cVi8eLHqRyuDx1Ijrb7SJzdxy6yhn62bm1smVmsFYiOBmAjAJbvajAmvjR2bVqF2806o7OCgdXWUSX9Jyy+6Ro0awYHn3GrwvFsfnnPrE5PJ59zwSbrJh9mcOXPCzs4O9+7dS7Jftr29vZ973x9//FGF2S1btqB8+fLPPM7JyUldkpMTwR/ADPTgCrC0mz7IdlkJ2NoBrm6IcMzJ99oK8ZxbJ55368Nzbn0cMumcp+c5NB0A5ujoiCpVqiQZvGUYzFWjRo1n3m/8+PEYOXIkNmzYgKpVq2ZStfRMp5YBv9UF/E8C/qeAh35aV0RERERWQvNuBtIFoGvXriqUVqtWDZMnT0ZYWJia3UC8//77yJcvn+r7Kn744Qd8//33WLRokZqb1t/fX+3PmjWrulAmki4FG74CjszXb8tiCO3mAO75tK6MiIiIrITmYbZjx44IDAxUAVWCqUy5JS2uhkFhN27cUDMcGEyfPl3NgtC+fdLlT2We2mHDhmV6/Vbr/iV9t4J7p2UmWaDOZ0C9IYCd5t9SREREZEVMInn0799fXVIjg7sSu3btWiZVRc+k0wHLe+qDrGtOoN0soEgDrasiIiIiK6T5oglkhmxsgFa/AEUbAX3/Y5AlIiIizTDMUtoEnANOLHm67V0OeG8ZkO35s04QERERWXw3AzLxLgXHFwJrPwfiY4EcRYH8VbSuioiIiEhhmKVniwoF1n4GnFys3y5cH/AooHVVRERERAkYZil1/qf1sxU8uATY2AL1vwFqDwISzSxBREREpDWGWUrpyO/AusFAXBSQLS/Qfg5QsKbWVRERERGlwDBLKUUF64OszFbQ5jcgSw6tKyIiIiJKFcMs6cXFPl3woEZ/wD0/UKoVuxUQERGRSWNSsXYyW8HBWcDMevoBX4Z5ZMu0YZAlIiIik8e0Ys0iHgF/vw+s+xy4dwo49ofWFRERERGlC7sZWKvbR4Cl3YFH1wFbB6DRCKB6H62rIiIiIkoXhllr7Fawfzqw+XsgPkY/b2yH+UA+LoRARERE5odh1trsmgBsH62/XqoF0PIXwMVD66qIiIiIXgr7zFqbyl0Bdx+g2Y/AO38wyBIREZFZY8uspYuPB/x2AEUa6Lez5Qb6HwYcnLWujIiIiOiVsWXWkoU9AP7qCPzRBji94ul+BlkiIiKyEGyZtVTX9wLLegAhdwA7JyAmQuuKiIiIiDIcw6wldivYMxHYPgbQxQE5igIdfge8y2pdGREREVGGY5i1JKGBwIpewNXt+u3yHYHmEwGnrFpXRkRERGQUDLOWthCCBFl7F6D5j0DFzvqlaYmIiIgsFMOsJSnRFGg8Gij6JuBVSutqiIiIiIyOsxmYsxB/YEkX4PGtp/tq9meQJSIiIqvBlllzdWUbsKI3EBYIRIcBXRJNvUVERERkJRhmzU1cLLBjLLD7JwA6wKsM0HSc1lURERERaYJh1pw8vg0s7wnc2KvfrtJNH2QdXLSujIiIiEgTDLPm4u5JYEErIOIh4JgVaDEFKNde66qIiIiINMUway5k8YNs3oB7fqDDfCBHEa0rIiIiItIcw6ypz1aQxQuwtQUcXYHOSwHXnICDs9aVEREREZkETs1lqs6vA6ZVB/bIQK8npFWWQZaIiIgoAcOsqYmNBjZ8DSzuBEQ+Ai5u1M9gQEREREQpsJuBKQm6Biz7QL8srXi9H9BwOGDH00RERESUGqYkU3F2NfBPfyDqMeDsDrSeDpRsrnVVRERERCaNYdYUBN/Vzx8bFwXkfw1oPxfwKKB1VUREREQmj2HWFLjlAZqOBYL8gDeHAnYOWldEREREZBYYZrVyegWQvSCQr4p++7UeWldEREREZHY4m0Fmi4kA1nwKLOsOLO0ORD7WuiIiIiIis8WW2cx0/xKwtBtw7zQAG/1ytA5ZtK6KiIiIyGwxzGaWE0uAfwcCMWH6VbzazgSKvql1VURERERmjWHW2GKjgLWDgGN/6rd96wDtZgPZvLWujIiIiMjsMcwam60DEBqg71ZQ90ug7heArZ3WVRERERFZBIZZY7O1BVrPAALOAoXqaF0NERERkUXhbAaZIUsOBlkiIiIiI2CYJSIiIiKzxTBLRERERGaLYZaIiIiIzBbDLBERERGZLYZZIiIiIjJbDLNEREREZLYYZomIiIjIbDHMEhEREZHZYpglIiIiIrPFMEtEREREZothloiIiIjMFsMsEREREZkthlkiIiIiMlsMs0RERERkthhmiYiIiMhsMcwSERERkdlimCUiIiIis8UwS0RERERmyx5WRqfTqa/BwcFal2LxYmJiEB4ert5rBwcHrcuhTMBzbp143q0Pz7n1icnkc27IaYbc9jxWF2ZDQkLUVx8fH61LISIiIqIX5DZ3d/fnHQIbXVoirwWJj4/HnTt3kC1bNtjY2GhdjkWTv6rkj4abN2/Czc1N63IoE/CcWyeed+vDc259gjP5nEs8lSCbN29e2No+v1es1bXMyhuSP39+rcuwKvJNz1921oXn3DrxvFsfnnPr45aJ5/xFLbIGHABGRERERGaLYZaIiIiIzBbDLBmNk5MThg4dqr6SdeA5t04879aH59z6OJnwObe6AWBEREREZDnYMktEREREZothloiIiIjMFsMsEREREZkthlkiIiIiMlsMs/RKpk2bBl9fXzg7O6N69eo4ePDgM4+dNWsW6tSpg+zZs6tLw4YNn3s8mf85T2zx4sVq1b3WrVsbvUbS9pw/evQIH330EfLkyaNGPhcvXhzr1q3LtHpJm/M+efJklChRAi4uLmqlqIEDByIyMjLT6qVXs2vXLrRo0UKtuCW/q1etWvXC++zYsQOVK1dWP+dFixbF/PnzoQWGWXppS5YswaBBg9RUHUePHkWFChXQpEkTBAQEPPObvlOnTti+fTv27dunftk1btwYt2/fzvTaKXPOucG1a9fw+eefqz9myLLPeXR0NBo1aqTO+bJly3DhwgX1h2y+fPkyvXbKvPO+aNEifPXVV+r4c+fOYc6cOeoxvv7660yvnV5OWFiYOs/yR0xa+Pn5oXnz5qhfvz6OHz+OTz/9FD179sTGjRuR6WRqLqKXUa1aNd1HH32UsB0XF6fLmzevbuzYsWm6f2xsrC5btmy633//3YhVktbnXM5zzZo1dbNnz9Z17dpV16pVq0yqlrQ459OnT9cVLlxYFx0dnYlVktbnXY5t0KBBkn2DBg3S1apVy+i1UsaTeLhy5crnHvPFF1/oypQpk2Rfx44ddU2aNNFlNrbM0kuR1pcjR46orgIGtra2altaXdMiPDwcMTEx8PT0NGKlpPU5HzFiBLy8vNCjR49MqpS0POerV69GjRo1VDeD3Llzo2zZshgzZgzi4uIysXLK7PNes2ZNdR9DV4SrV6+qriXNmjXLtLopc8n3QuLvESGt92nNABnJPtOfkSzC/fv31X9O8p9VYrJ9/vz5ND3Gl19+qfrmJP9hIMs553v27FEfN8pHUGQd51xCzLZt29C5c2cVZi5fvox+/fqpP1zlI2iyzPP+7rvvqvvVrl1bPvFFbGws+vTpw24GFszf3z/V75Hg4GBERESovtOZhS2zpIlx48apAUErV65UgwvI8oSEhKBLly6qv2TOnDm1LocySXx8vGqJnzlzJqpUqYKOHTvim2++wYwZM7QujYxIxkRIC/yvv/6q+tiuWLECa9euxciRI7UujawAW2bppUg4sbOzw71795Lsl21vb+/n3vfHH39UYXbLli0oX768kSslrc75lStX1CAgGR2bOOgIe3t7NTCoSJEimVA5ZebPucxg4ODgoO5nUKpUKdWKIx9fOzo6Gr1uyvzz/t1336k/XmUAkChXrpwaUNS7d2/1x4x0UyDL4u3tner3iJubW6a2ygp+d9FLkf+QpNVl69atSYKKbEt/uWcZP368+kt9w4YNqFq1aiZVS1qc85IlS+LUqVOqi4Hh0rJly4SRrzKbBVnez3mtWrVU1wLDHy7i4sWLKuQyyFrueZcxEMkDq+EPGv14IrI0NWrUSPI9IjZv3vzcDGA0mT7kjCzG4sWLdU5OTrr58+frzp49q+vdu7fOw8ND5+/vr27v0qWL7quvvko4fty4cTpHR0fdsmXLdHfv3k24hISEaPgqyJjnPDnOZmD55/zGjRtqlpL+/fvrLly4oPv33391Xl5eulGjRmn4KsjY533o0KHqvP/111+6q1ev6jZt2qQrUqSI7p133tHwVVB6yP/Fx44dUxeJhxMnTlTXr1+/rm6X8y3n3UDOs6urq27w4MG6c+fO6aZNm6azs7PTbdiwQZfZGGbplUydOlVXoEABFVJlKpf9+/cn3Fa3bl0VXgwKFiyofkCSX+SXIFnmOU+OYdY6zvnevXt11atXV2FIpukaPXq0mqKNLPe8x8TE6IYNG6YCrLOzs87Hx0fXr18/XVBQkEbVU3pt37491f+jDedZvsp5T36fihUrqu8R+VmfN2+eTgs28k/mtwcTEREREb069pklIiIiIrPFMEtEREREZothloiIiIjMFsMsEREREZkthlkiIiIiMlsMs0RERERkthhmiYiIiMhsMcwSERERkdlimCUii7Jjxw7Y2Njg0aNHWpeC//77D+XKlYODgwNat24NU2FK75G5u3btmnovjx8/rnUpRFaLYZaIMkS3bt3Uf+rJL5cvXzbac9arVw+ffvppkn01a9bE3bt34e7uDq0NGjQIFStWhJ+fH+bPn5/m12AO5Lx2794d+fPnh5OTEwoVKoROnTrh8OHDGfo8vr6+mDx5coY+JgMokWVhmCWiDNO0aVMVJBNfJOQkFx0dbbQaHB0d4e3trcKK1q5cuYIGDRqowOfh4QFLIYG1SpUquHjxIn777TecPXsWK1euRMmSJfHZZ59pXR4RWRmGWSLKMNJCJ0Ey8cXOzk61Pvbv31+1QObMmRNNmjRRx0+cOFF9DJ8lSxb4+PigX79+CA0NTfFRvdzf1dUV2bNnV/cNCgpSLcE7d+7ElClTElqBpcUttY/Qly9fjjJlyqj6pKXvp59+SvIcsm/MmDH44IMPkC1bNhQoUAAzZ8587muNiorCgAED4OXlBWdnZ9SuXRuHDh1K0vL34MED9Zhy/Vktsy+yZ88e1KlTBy4uLuo9kucMCwtLuP2PP/5A1apVVd3yfr/77rsICAhI8hjr1q1D8eLF1WPUr19f1ZfY9evX0aJFC/X+yrmQ90rukxqdTqfe+2LFimH37t1o3rw5ihQpolqghw4din/++Sfh2FOnTqkwL8+bI0cO9O7dO8n5lceR7hc//vgj8uTJo4756KOPEBMTo26X8y61DRw4MOEcC3lfpRU4X7586vtCvof++uuvJHXGx8dj/PjxKFq0qDrvck5Hjx6tbjP8gVWpUiX1mPI8BrNnz0apUqXUOZVw/uuvvyZ53IMHD6r7ye3yvh87dizN55KIjERHRJQBunbtqmvVqlWqt9WtW1eXNWtW3eDBg3Xnz59XFzFp0iTdtm3bdH5+frqtW7fqSpQooevbt2/C/Y4dO6ZzcnJS+44fP647ffq0burUqbrAwEDdo0ePdDVq1ND16tVLd/fuXXWJjY3Vbd++XSe/2oKCgtRjHD58WGdra6sbMWKE7sKFC7p58+bpXFxc1FeDggUL6jw9PXXTpk3TXbp0STd27Fh1H0OdqRkwYIAub968unXr1unOnDmjXn/27Nl1Dx48UHVIPW5ubrrJkyer6+Hh4c98bz755JNUb7t8+bIuS5Ys6n26ePGi7r///tNVqlRJ161bt4Rj5syZo2q4cuWKbt++feo9eeuttxJuv3HjhnoPBw0apF7Pn3/+qcudO3eS96h58+a6Ro0a6U6ePKkeZ82aNbqdO3emWtPRo0fVfRctWqR7ntDQUF2ePHl0bdu21Z06dUqd30KFCqn3yUCuy3vUp08f3blz59Tzurq66mbOnKlul/cyf/786twZzrG4deuWbsKECer7Q+r9+eefdXZ2droDBw4kPPYXX3yhzsf8+fPV+7h7927drFmz1G0HDx5Ur2HLli3qMeV5hLw3UvPy5ct1V69eVV/l+0IeQ4SEhOhy5cqle/fdd9X3otRbuHBh9VhSCxFpg2GWiDKEBBMJFBK+DJf27dsnBDYJYS+ydOlSXY4cORK2O3XqpKtVq9Yzj08tCCYPsxI8JKglJqG6dOnSScLse++9l7AdHx+v8/Ly0k2fPv2ZQc3BwUG3cOHChH3R0dEq3I4fPz5hn7u7e5LQnNbXYNCjRw9d7969k+yTUCZBOyIiItX7HDp0SL1+CV5iyJAhSV6r+PLLL5O8R+XKldMNGzZMlxZLlixR95VQ+zwSSCVMyntlsHbtWlW7v79/wveMvPcS/g06dOig69ixY8K23C5h/kUkkH/22WfqenBwsArwhvCanPzxlFoALVKkSIqQPnLkSPUHgvjtt9/U92fi916+RxhmibRlb6wWXyKyPvIR9vTp0xO25SNrA+ljmdyWLVswduxYnD9/HsHBwYiNjUVkZCTCw8PVx8cyQKdDhw6vVNO5c+fQqlWrJPtq1aqlBhXFxcWpbhCifPnyCbfLR8/ykX3yj+sT94WVj8LlcQxkxoJq1aqp58soJ06cwMmTJ7Fw4cKEfdIIIR+hy6Ay+Tj8yJEjGDZsmDpWul/IbeLGjRsoXbq0qqd69epJHrdGjRpJtqXrQt++fbFp0yY0bNgQ7dq1S/J+JCbPnxbyvBUqVEjyPSDvl9R34cIF5M6dW+2TLg2GcyCku4F0T3geOW/SLeTvv//G7du3VR9s6fYh3zOG55btN998E2klXTfkvPbo0QO9evVK2C/fk4bBhPK48r5IF4NnvZdElPnYZ5aIMowEF+mjaLhIMEl8W2LSb/Ptt99W4UD6tEoomzZtWpIBYtLXMrNIGE1MAq0hGGpF+pd++OGHKtQbLhJaL126pPqpSgCTPsRubm4q8EqfXRmIld5Bdj179sTVq1fRpUsXFSSlL+jUqVNTPVb63gr5A0Sr933ChAmqr/SXX36J7du3q/dF3odX+b4x9OWdNWtWkvf79OnT2L9/f7ofj4gyD8MsEWlCwquEFhmM9frrr6uQdOfOnSTHSNDdunXrc2cukFa655HWSxlElphsy/MlbhFMDwmS8tyJH1daaiVMSmtoRqlcubKaKSDxHwiGizy/BEoZDDVu3Dg1SEwGLCVvTZbXL4OWEkstnMngsj59+mDFihVqRgIJdamRgV7yGuW8pRY6DQPv5HkleCcerCbvl62tLUqUKJHm9yC1cyyPI63t7733nmr9LVy4sJpZwUAGp0mgfdb3jjymSPy40lKcN29eFeqTv9eGAWPymqSlXD49MGDQJdIewywRaUJCggRAaQGUACGj8mfMmJHkmCFDhqiAKLMcSIiQ8CbdGO7fv58wC8GBAwdUK6/sSy1cSTCTUDNy5EgVeH7//Xf88ssv+Pzzz1+6dmlllo/lBw8ejA0bNqjAKR9NS/cI+Zg6vQIDA5O0Bsrl3r17quVx7969aiYI2SctsjJbgGwLGaEvwczwHq5evVq9zsQkoMr9pFb5eH/RokUpZlaQWSY2btyoui4cPXpUtXZKcEuNtJzOmzdPvZcSoGXWA3luOT8yW4ChS0fnzp3Vx/Fdu3ZVrZvymB9//LFq/TV0MUgLOce7du1S3QkM513C6ubNm9V7Ix/9S+u1vF8G8rzy3n3xxRdYsGCB6j4goXPOnDnqdpmBQsKunDu53+PHj9X+4cOHq24vP//8s3p90kotr1Vm3RAyU4S8fjnXcs7ltctMDESkMY377BKRlcxmkNogp4kTJ6rR4zK7QJMmTXQLFixIMjBJ7NixQ1ezZk01oMfDw0MdZ7hdZid4/fXX1f3lfjKwJ/kAMLFs2TI1CEoGbRUoUECNhE8stUFGFSpU0A0dOvSZr1cGAX388ce6nDlzqtpkoJqMkk8srQPApN7kFxl4JOQxZQCbzAYhg+rKly+vGz16dML9ZcCSr6+vqkEGKq1evTrFgCQZdV+0aFF1TJ06dXRz585N8h71799fDX6S22W0fpcuXXT3799/bt3y3r///vtq0Jujo6N6D2XAXuKBYTI7Qv369XXOzs5qVgCZecIwMO1Z3zPyfSLviYHM0CCvWWoz/Jclsw/I/eQ9kYF63377raol8WPFxcXpRo0apeoynPcxY8Yk3C6Dw3x8fNSAtMTPJ4P6KlasqF6TDGB74403dCtWrEhSj3xvyO1ynMx4wAFgRNqykX+0DtRERERERC+D3QyIiIiIyGwxzBIRERGR2WKYJSIiIiKzxTBLRERERGaLYZaIiIiIzBbDLBERERGZLYZZIiIiIjJbDLNEREREZLYYZomIiIjIbDHMEhEREZHZYpglIiIiIpir/wNc6eGNEAOdDgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ground truth and predicted final probability\n",
    "y_true = df['grosscontractsigned'].values\n",
    "y_score = p_final  # final combined probability from pipeline\n",
    "\n",
    "# Create dataframe for ranking\n",
    "results = pd.DataFrame({'y_true': y_true, 'y_score': y_score})\n",
    "results = results.sort_values('y_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Split into 10 equal groups (deciles)\n",
    "results['decile'] = pd.qcut(results.index, 10, labels=False)\n",
    "\n",
    "# Calculate lift\n",
    "decile_summary = results.groupby('decile').agg(\n",
    "    total=('y_true', 'count'),\n",
    "    positives=('y_true', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "decile_summary['cum_positives'] = decile_summary['positives'].cumsum()\n",
    "decile_summary['cum_total'] = decile_summary['total'].cumsum()\n",
    "decile_summary['cum_recall'] = decile_summary['cum_positives'] / results['y_true'].sum()\n",
    "\n",
    "# Baseline (random expectation)\n",
    "decile_summary['baseline_recall'] = decile_summary['cum_total'] / len(results)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(decile_summary['cum_total']/len(results), decile_summary['cum_recall'], marker='o', label='Model')\n",
    "plt.plot(decile_summary['cum_total']/len(results), decile_summary['baseline_recall'], linestyle='--', label='Random')\n",
    "plt.xlabel(\"Fraction of Leads Contacted\")\n",
    "plt.ylabel(\"Fraction of Contracts Captured (Recall)\")\n",
    "plt.title(\"Lift / Gains Chart\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831341b1",
   "metadata": {},
   "source": [
    "🔹 How to Read It\n",
    "\n",
    "X-axis = % of leads contacted (from highest-scored down).\n",
    "\n",
    "Y-axis = % of actual signed contracts captured.\n",
    "\n",
    "Random line = what you’d expect with no model (diagonal).\n",
    "\n",
    "Model curve = should be far above diagonal if useful.\n",
    "\n",
    "Example interpretation:\n",
    "\n",
    "At 20% of leads contacted, model captures ~60% of contracts (vs 20% for random).\n",
    "\n",
    "That’s a 3× lift.\n",
    "\n",
    "🔹 Why This is Powerful\n",
    "\n",
    "Non-technical stakeholders can see the business value: “By calling the top-ranked leads, we close X contracts instead of Y.”\n",
    "\n",
    "It justifies the model even if precision is modest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d988fdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decile  total_leads  contracts  cum_leads  cum_contracts  precision  \\\n",
      "9       1         1796      0.000       1796          0.000      0.000   \n",
      "8       2         1795      0.000       3591          0.000      0.000   \n",
      "7       3         1796      0.000       5387          0.000      0.000   \n",
      "6       4         1795      0.000       7182          0.000      0.000   \n",
      "5       5         1795      2.000       8977          2.000      0.001   \n",
      "4       6         1796     24.000      10773         26.000      0.013   \n",
      "3       7         1795     40.000      12568         66.000      0.022   \n",
      "2       8         1796     53.000      14364        119.000      0.030   \n",
      "1       9         1795    125.000      16159        244.000      0.070   \n",
      "0      10         1796    346.000      17955        590.000      0.193   \n",
      "\n",
      "   recall  lift  \n",
      "9   0.000 0.000  \n",
      "8   0.000 0.000  \n",
      "7   0.000 0.000  \n",
      "6   0.000 0.000  \n",
      "5   0.003 0.034  \n",
      "4   0.044 0.407  \n",
      "3   0.112 0.678  \n",
      "2   0.202 0.898  \n",
      "1   0.414 2.119  \n",
      "0   1.000 5.863  \n"
     ]
    }
   ],
   "source": [
    "# Sort by predicted probability\n",
    "results = pd.DataFrame({'y_true': y_true, 'y_score': y_score})\n",
    "results = results.sort_values('y_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Create deciles (0 = top 10%, 9 = bottom 10%)\n",
    "results['decile'] = pd.qcut(results.index, 10, labels=False)\n",
    "\n",
    "# Aggregate stats per decile\n",
    "decile_summary = results.groupby('decile').agg(\n",
    "    total_leads=('y_true', 'count'),\n",
    "    contracts=('y_true', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Order deciles top-down (so 0 is top decile)\n",
    "decile_summary['decile'] = 10 - decile_summary['decile']\n",
    "\n",
    "# Cumulative values\n",
    "decile_summary = decile_summary.sort_values('decile')\n",
    "decile_summary['cum_leads'] = decile_summary['total_leads'].cumsum()\n",
    "decile_summary['cum_contracts'] = decile_summary['contracts'].cumsum()\n",
    "\n",
    "# Totals\n",
    "total_contracts = results['y_true'].sum()\n",
    "total_leads = len(results)\n",
    "\n",
    "# Metrics\n",
    "decile_summary['precision'] = decile_summary['contracts'] / decile_summary['total_leads']\n",
    "decile_summary['recall'] = decile_summary['cum_contracts'] / total_contracts\n",
    "decile_summary['lift'] = decile_summary['precision'] / (total_contracts / total_leads)\n",
    "\n",
    "# Display neatly\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "print(decile_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e6a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decile (1=Top)  total_leads  contracts  cum_leads  cum_contracts  \\\n",
      "0               1         1796        346       1796            346   \n",
      "1               2         1795        125       3591            471   \n",
      "2               3         1796         53       5387            524   \n",
      "3               4         1795         40       7182            564   \n",
      "4               5         1796         24       8978            588   \n",
      "5               6         1795          2      10773            590   \n",
      "6               7         1795          0      12568            590   \n",
      "7               8         1796          0      14364            590   \n",
      "8               9         1795          0      16159            590   \n",
      "9              10         1796          0      17955            590   \n",
      "\n",
      "   precision  recall  lift  Cumulative % Leads  \n",
      "0      0.193   0.586 5.863               0.100  \n",
      "1      0.070   0.798 2.119               0.200  \n",
      "2      0.030   0.888 0.898               0.300  \n",
      "3      0.022   0.956 0.678               0.400  \n",
      "4      0.013   0.997 0.407               0.500  \n",
      "5      0.001   1.000 0.034               0.600  \n",
      "6      0.000   1.000 0.000               0.700  \n",
      "7      0.000   1.000 0.000               0.800  \n",
      "8      0.000   1.000 0.000               0.900  \n",
      "9      0.000   1.000 0.000               1.000  \n"
     ]
    }
   ],
   "source": [
    "# more intuitive representation; top percentile on top \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# y_true = df['grosscontractsigned'].values\n",
    "# y_score = p_final  # final combined probability from the pipeline\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'y_true': pd.Series(y_true, dtype=int),\n",
    "    'y_score': pd.Series(y_score, dtype=float)\n",
    "})\n",
    "\n",
    "# 1) Rank scores so 1 = highest score (break ties by order of appearance)\n",
    "rank_desc = results['y_score'].rank(method='first', ascending=False)\n",
    "\n",
    "# 2) Deciles from rank: 1..10 where 1 = top 10%, 10 = bottom 10%\n",
    "results['decile'] = pd.qcut(rank_desc, 10, labels=range(1, 11)).astype(int)\n",
    "\n",
    "# 3) Aggregate per decile (already top→bottom order when sorted by decile)\n",
    "decile_summary = (results\n",
    "    .groupby('decile', as_index=False)\n",
    "    .agg(total_leads=('y_true', 'size'),\n",
    "         contracts=('y_true', 'sum'))\n",
    "    .sort_values('decile')  # 1..10\n",
    ")\n",
    "\n",
    "# 4) Cumulatives and metrics\n",
    "total_leads = len(results)\n",
    "total_contracts = results['y_true'].sum()\n",
    "base_rate = total_contracts / total_leads\n",
    "\n",
    "decile_summary['cum_leads'] = decile_summary['total_leads'].cumsum()\n",
    "decile_summary['cum_contracts'] = decile_summary['contracts'].cumsum()\n",
    "decile_summary['precision'] = decile_summary['contracts'] / decile_summary['total_leads']\n",
    "decile_summary['recall'] = decile_summary['cum_contracts'] / total_contracts\n",
    "decile_summary['lift'] = decile_summary['precision'] / base_rate\n",
    "decile_summary['population_frac'] = decile_summary['cum_leads'] / total_leads\n",
    "\n",
    "# 5) Pretty columns\n",
    "decile_summary = decile_summary[[\n",
    "    'decile', 'total_leads', 'contracts',\n",
    "    'cum_leads', 'cum_contracts',\n",
    "    'precision', 'recall', 'lift', 'population_frac'\n",
    "]].rename(columns={\n",
    "    'decile': 'Decile (1=Top)',\n",
    "    'population_frac': 'Cumulative % Leads'\n",
    "})\n",
    "\n",
    "print(decile_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d962e",
   "metadata": {},
   "source": [
    "deciles are top to bottom. \n",
    "\n",
    "total leads; subset in each tier (total/10)\n",
    "\n",
    "this was generalized to the whole dataste. now lets see on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb67be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 probabilities on test set\n",
    "p_sc_test = stage1_model.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "# Stage 2 probabilities only for SC test rows\n",
    "p_contract_given_sc_test = np.zeros(len(X_test2))\n",
    "p_contract_given_sc_test = stage2_model.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "# For the final probability:\n",
    "#   P(contract) = P(SC) * P(contract | SC)\n",
    "# Here we need to align indices correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c65c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final contract probability for Stage 2 test set\n",
    "# (since Stage 2 test set already includes only SC rows)\n",
    "p_final_test = p_contract_given_sc_test  # <-- conditioned on SC\n",
    "y_true_test = y_test2.values             # ground truth labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4f20b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decile  total_leads  contracts  cum_leads  cum_contracts  precision  \\\n",
      "0       1          321     71.000        321         71.000      0.221   \n",
      "1       2          321     24.000        642         95.000      0.075   \n",
      "2       3          321     17.000        963        112.000      0.053   \n",
      "3       4          321     17.000       1284        129.000      0.053   \n",
      "4       5          321     11.000       1605        140.000      0.034   \n",
      "5       6          321     13.000       1926        153.000      0.040   \n",
      "6       7          321      9.000       2247        162.000      0.028   \n",
      "7       8          321      6.000       2568        168.000      0.019   \n",
      "8       9          321      5.000       2889        173.000      0.016   \n",
      "9      10          321      4.000       3210        177.000      0.012   \n",
      "\n",
      "   recall  lift  cum_frac_leads  \n",
      "0   0.401 4.011           0.100  \n",
      "1   0.537 1.356           0.200  \n",
      "2   0.633 0.960           0.300  \n",
      "3   0.729 0.960           0.400  \n",
      "4   0.791 0.621           0.500  \n",
      "5   0.864 0.734           0.600  \n",
      "6   0.915 0.508           0.700  \n",
      "7   0.949 0.339           0.800  \n",
      "8   0.977 0.282           0.900  \n",
      "9   1.000 0.226           1.000  \n"
     ]
    }
   ],
   "source": [
    "def decile_summary(y_true, y_score, n_bins=10):\n",
    "    results = pd.DataFrame({'y_true': y_true, 'y_score': y_score})\n",
    "    results = results.sort_values('y_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Rank → deciles (1=top, n_bins=bottom)\n",
    "    rank_desc = results['y_score'].rank(method='first', ascending=False)\n",
    "    results['decile'] = pd.qcut(rank_desc, n_bins, labels=range(1, n_bins+1)).astype(int)\n",
    "\n",
    "    # Aggregate\n",
    "    summary = (results.groupby('decile', as_index=False)\n",
    "               .agg(total_leads=('y_true', 'size'),\n",
    "                    contracts=('y_true', 'sum')))\n",
    "\n",
    "    # Cumulative\n",
    "    summary = summary.sort_values('decile')\n",
    "    summary['cum_leads'] = summary['total_leads'].cumsum()\n",
    "    summary['cum_contracts'] = summary['contracts'].cumsum()\n",
    "\n",
    "    total_contracts = results['y_true'].sum()\n",
    "    total_leads = len(results)\n",
    "    base_rate = total_contracts / total_leads\n",
    "\n",
    "    summary['precision'] = summary['contracts'] / summary['total_leads']\n",
    "    summary['recall'] = summary['cum_contracts'] / total_contracts\n",
    "    summary['lift'] = summary['precision'] / base_rate\n",
    "    summary['cum_frac_leads'] = summary['cum_leads'] / total_leads\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Run it\n",
    "decile_summary_test = decile_summary(y_true_test, p_final_test)\n",
    "print(decile_summary_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "296de8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(decile_summary_test['cum_frac_leads'], decile_summary_test['recall'],\n",
    "         marker='o', label='Model (test set)')\n",
    "plt.plot(decile_summary_test['cum_frac_leads'], decile_summary_test['cum_frac_leads'],\n",
    "         linestyle='--', label='Random baseline')\n",
    "plt.xlabel(\"Fraction of Leads Contacted\")\n",
    "plt.ylabel(\"Fraction of Contracts Captured (Recall)\")\n",
    "plt.title(\"Gains Chart (Test Set)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaea373",
   "metadata": {},
   "source": [
    "## same structure but now xgbooost and nn (previously was gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f16f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\elifyilmaz\\onedrive - enpal b.v\\desktop\\new folder\\project\\.venv\\lib\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elifyilmaz\\onedrive - enpal b.v\\desktop\\new folder\\project\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp311-cp311-win_amd64.whl (241.4 MB)\n",
      "   ---------------------------------------- 0.0/241.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/241.4 MB 11.2 MB/s eta 0:00:22\n",
      "    --------------------------------------- 3.7/241.4 MB 9.5 MB/s eta 0:00:26\n",
      "    --------------------------------------- 5.0/241.4 MB 8.4 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 6.6/241.4 MB 8.2 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 8.4/241.4 MB 8.1 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 10.0/241.4 MB 8.1 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 11.5/241.4 MB 8.1 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 13.1/241.4 MB 8.0 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 14.9/241.4 MB 8.0 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 17.0/241.4 MB 8.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 19.1/241.4 MB 8.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 21.2/241.4 MB 8.5 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 23.1/241.4 MB 8.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 25.2/241.4 MB 8.7 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 27.3/241.4 MB 8.8 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 28.8/241.4 MB 8.7 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 30.4/241.4 MB 8.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 31.7/241.4 MB 8.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 33.0/241.4 MB 8.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 33.3/241.4 MB 8.3 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 33.8/241.4 MB 7.8 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 34.1/241.4 MB 7.7 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 34.6/241.4 MB 7.3 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 35.4/241.4 MB 7.1 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 36.4/241.4 MB 7.0 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 38.0/241.4 MB 7.0 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 39.1/241.4 MB 6.9 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 40.1/241.4 MB 6.9 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 41.9/241.4 MB 6.9 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 42.7/241.4 MB 6.8 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 43.8/241.4 MB 6.8 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 45.4/241.4 MB 6.7 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 46.9/241.4 MB 6.8 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 48.2/241.4 MB 6.8 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 49.8/241.4 MB 6.8 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 51.4/241.4 MB 6.8 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 53.5/241.4 MB 6.9 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 55.1/241.4 MB 6.9 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 56.9/241.4 MB 7.0 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 59.0/241.4 MB 7.1 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 61.1/241.4 MB 7.1 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 63.7/241.4 MB 7.2 MB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 65.8/241.4 MB 7.3 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 68.4/241.4 MB 7.4 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 70.0/241.4 MB 7.4 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 71.8/241.4 MB 7.5 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 73.9/241.4 MB 7.5 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 75.5/241.4 MB 7.5 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 76.8/241.4 MB 7.5 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 77.6/241.4 MB 7.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 78.1/241.4 MB 7.3 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 79.2/241.4 MB 7.3 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 80.2/241.4 MB 7.2 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 81.8/241.4 MB 7.2 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 83.6/241.4 MB 7.3 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 84.4/241.4 MB 7.2 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 86.5/241.4 MB 7.2 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 88.6/241.4 MB 7.3 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 90.7/241.4 MB 7.3 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 92.8/241.4 MB 7.4 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 95.2/241.4 MB 7.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 96.2/241.4 MB 7.5 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 96.7/241.4 MB 7.3 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 97.5/241.4 MB 7.3 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 98.3/241.4 MB 7.2 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 99.9/241.4 MB 7.2 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 101.4/241.4 MB 7.2 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 103.5/241.4 MB 7.3 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 104.1/241.4 MB 7.2 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 105.1/241.4 MB 7.2 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 106.7/241.4 MB 7.2 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 108.0/241.4 MB 7.2 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 109.1/241.4 MB 7.1 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 110.1/241.4 MB 7.1 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 110.6/241.4 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 111.7/241.4 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 113.0/241.4 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 114.6/241.4 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 116.4/241.4 MB 7.0 MB/s eta 0:00:18\n",
      "   ------------------- -------------------- 118.5/241.4 MB 7.1 MB/s eta 0:00:18\n",
      "   ------------------- -------------------- 119.8/241.4 MB 7.1 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 120.8/241.4 MB 7.0 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 122.7/241.4 MB 7.0 MB/s eta 0:00:17\n",
      "   -------------------- ------------------- 124.5/241.4 MB 7.1 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 126.9/241.4 MB 7.1 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 129.2/241.4 MB 7.2 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 131.6/241.4 MB 7.2 MB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 134.0/241.4 MB 7.3 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 135.8/241.4 MB 7.3 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 137.4/241.4 MB 7.3 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 138.9/241.4 MB 7.3 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 139.7/241.4 MB 7.3 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 141.0/241.4 MB 7.2 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 142.1/241.4 MB 7.2 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 142.9/241.4 MB 7.2 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 144.2/241.4 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 145.8/241.4 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 147.6/241.4 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 149.7/241.4 MB 7.2 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 151.3/241.4 MB 7.2 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 153.1/241.4 MB 7.2 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 155.2/241.4 MB 7.3 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 157.3/241.4 MB 7.3 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 159.6/241.4 MB 7.3 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 161.7/241.4 MB 7.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 163.1/241.4 MB 7.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 164.9/241.4 MB 7.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 167.0/241.4 MB 7.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 168.6/241.4 MB 7.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 170.9/241.4 MB 7.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 172.8/241.4 MB 7.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 174.6/241.4 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 176.4/241.4 MB 7.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 177.7/241.4 MB 7.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 178.0/241.4 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 178.8/241.4 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 179.8/241.4 MB 7.3 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 181.1/241.4 MB 7.3 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 182.7/241.4 MB 7.3 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 183.2/241.4 MB 7.3 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 183.2/241.4 MB 7.3 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 184.8/241.4 MB 7.2 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 186.4/241.4 MB 7.2 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 188.2/241.4 MB 7.3 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 190.3/241.4 MB 7.3 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 192.7/241.4 MB 7.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 193.5/241.4 MB 7.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 194.0/241.4 MB 7.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 194.8/241.4 MB 7.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 195.8/241.4 MB 7.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 197.4/241.4 MB 7.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 198.7/241.4 MB 7.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 200.8/241.4 MB 7.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 202.9/241.4 MB 7.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 205.0/241.4 MB 7.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 207.6/241.4 MB 7.3 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 209.7/241.4 MB 7.3 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 212.1/241.4 MB 7.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 214.2/241.4 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 215.7/241.4 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 217.6/241.4 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 218.4/241.4 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 218.6/241.4 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 218.6/241.4 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 219.2/241.4 MB 7.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 219.9/241.4 MB 7.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 221.0/241.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 222.6/241.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 224.1/241.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 226.2/241.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 226.5/241.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 227.3/241.4 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 228.1/241.4 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 229.6/241.4 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 231.2/241.4 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 232.8/241.4 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 234.9/241.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  236.5/241.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  237.0/241.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  237.2/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  237.8/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  238.6/241.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  239.6/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  239.9/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  240.1/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.4/241.4 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 4.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.3/6.3 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/6.3 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.4/6.3 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.4/6.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 699.0 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 699.0 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 699.0 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 699.0 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 699.0 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 376.9 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.8/2.0 MB 376.9 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.0/2.0 MB 430.2 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 1.0/2.0 MB 430.2 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.3/2.0 MB 456.5 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.3/2.0 MB 456.5 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.3/2.0 MB 456.5 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.6/2.0 MB 443.9 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 2.0/2.0 MB 556.1 kB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, jinja2, fsspec, filelock, torch\n",
      "\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------------- ----------- 5/7 [filelock]\n",
      "   ---------------------------- ----------- 5/7 [filelock]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------------- 7/7 [torch]\n",
      "\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 22.3 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install xgboost\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9746d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 XGBoost AUC: 0.6468157614940678\n",
      "Stage 2 XGBoost AUC: 0.7362412706928122\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'net_sc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'net_sc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m p_final_test = np.zeros(\u001b[38;5;28mlen\u001b[39m(X_test1))\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# SC mask on test set (same definition as when you split data)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m sc_mask_test = \u001b[43mX_test1\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnet_sc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m > \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# or whatever column you use for SC check\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Multiply only for SC rows\u001b[39;00m\n\u001b[32m     49\u001b[39m p_final_test[sc_mask_test] = (\n\u001b[32m     50\u001b[39m     p_sc_test[sc_mask_test] * p_contract_given_sc_test\n\u001b[32m     51\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'net_sc'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "# ---- Stage 1: Engagement ----\n",
    "xgb_stage1 = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(y_train1.value_counts()[0] / y_train1.value_counts()[1]),\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_stage1.fit(X_train1, y_train1)\n",
    "p_sc_train = xgb_stage1.predict_proba(X_train1)[:,1]\n",
    "p_sc_test = xgb_stage1.predict_proba(X_test1)[:,1]\n",
    "\n",
    "print(\"Stage 1 XGBoost AUC:\", roc_auc_score(y_test1, p_sc_test))\n",
    "\n",
    "# ---- Stage 2: Contract ----\n",
    "xgb_stage2 = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(y_train2.value_counts()[0] / y_train2.value_counts()[1]),\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_stage2.fit(X_train2, y_train2)\n",
    "p_contract_given_sc_test = xgb_stage2.predict_proba(X_test2)[:,1]\n",
    "\n",
    "print(\"Stage 2 XGBoost AUC:\", roc_auc_score(y_test2, p_contract_given_sc_test))\n",
    "import numpy as np\n",
    "\n",
    "# Final probability for all Stage 1 test rows\n",
    "p_final_test = np.zeros(len(X_test1))\n",
    "\n",
    "# SC mask on test set (same definition as when you split data)\n",
    "sc_mask_test = X_test1['net_sc'] > 0  # or whatever column you use for SC check\n",
    "\n",
    "# Multiply only for SC rows\n",
    "p_final_test[sc_mask_test] = (\n",
    "    p_sc_test[sc_mask_test] * p_contract_given_sc_test\n",
    ")\n",
    "\n",
    "# Now evaluate against ground truth (Stage 1 test labels mapped to contracts)\n",
    "y_true_final = y_test1.copy()  # start from Stage 1 test labels\n",
    "# But replace with actual contract outcome where SC happened\n",
    "y_true_final = df.loc[X_test1.index, 'grosscontractsigned'].values\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "print(\"Final pipeline ROC AUC:\", roc_auc_score(y_true_final, p_final_test))\n",
    "print(\"Final pipeline PR AUC:\", average_precision_score(y_true_final, p_final_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f20b409",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# nn \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#model architecture\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\torch\\__init__.py:416\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    415\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSymInt\u001b[39;00m:\n\u001b[32m    420\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[33;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[33;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# nn \n",
    "#model architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 NN\n",
    "stage1_nn = train_nn(X_train1, y_train1, X_test1, y_test1, input_dim=X_train1.shape[1])\n",
    "with torch.no_grad():\n",
    "    p_sc_test_nn = stage1_nn(torch.tensor(X_test1.values, dtype=torch.float32)).numpy().flatten()\n",
    "\n",
    "# Stage 2 NN\n",
    "stage2_nn = train_nn(X_train2, y_train2, X_test2, y_test2, input_dim=X_train2.shape[1])\n",
    "with torch.no_grad():\n",
    "    p_contract_given_sc_test_nn = stage2_nn(torch.tensor(X_test2.values, dtype=torch.float32)).numpy().flatten()\n",
    "\n",
    "# Final Funnel Probability\n",
    "p_final_test_nn = p_sc_test_nn * p_contract_given_sc_test_nn\n",
    "print(\"NN Final ROC AUC:\", roc_auc_score(y_test2, p_final_test_nn))\n",
    "print(\"NN Final PR AUC:\", average_precision_score(y_test2, p_final_test_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71cd62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e7b8402",
   "metadata": {},
   "source": [
    "\n",
    "# third attempt scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f47fb",
   "metadata": {},
   "source": [
    "## logistic regression: base model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b980cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because why nott\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Features / target\n",
    "X = df.drop(columns=[\"grosscontractsigned\"])\n",
    "y = df[\"grosscontractsigned\"]\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Scale only numeric features\n",
    "num_cols = X_train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Handle imbalance with SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a57b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1784  238]\n",
      " [ 204  230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.88      0.89      2022\n",
      "         1.0       0.49      0.53      0.51       434\n",
      "\n",
      "    accuracy                           0.82      2456\n",
      "   macro avg       0.69      0.71      0.70      2456\n",
      "weighted avg       0.83      0.82      0.82      2456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with balanced classes\n",
    "clf = LogisticRegression(max_iter=500, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3ba1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1784  238]\n",
      " [ 204  230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.897     0.882     0.890      2022\n",
      "         1.0      0.491     0.530     0.510       434\n",
      "\n",
      "    accuracy                          0.820      2456\n",
      "   macro avg      0.694     0.706     0.700      2456\n",
      "weighted avg      0.826     0.820     0.823      2456\n",
      "\n",
      "Average Precision (PR-AUC): 0.5836055259008011\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    auc\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# Precision-Recall AUC\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "print(\"Average Precision (PR-AUC):\", ap)\n",
    "\n",
    "# Plot PR Curve\n",
    "prec, rec, thresh = precision_recall_curve(y_test, y_proba)\n",
    "plt.plot(rec, prec, label=f'PR curve (AP={ap:.2f})')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420d3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.769     0.871     0.817      8087\n",
      "         1.0      0.851     0.738     0.791      8087\n",
      "\n",
      "    accuracy                          0.805     16174\n",
      "   macro avg      0.810     0.805     0.804     16174\n",
      "weighted avg      0.810     0.805     0.804     16174\n",
      "\n",
      "Train Average Precision (PR-AUC): 0.912287812229633\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "\n",
    "# Predictions on train\n",
    "y_train_pred = clf.predict(X_train_res)\n",
    "y_train_proba = clf.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train_res, y_train_pred, digits=3))\n",
    "print(\"Train Average Precision (PR-AUC):\", average_precision_score(y_train_res, y_train_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec6dda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.897     0.882     0.890      2022\n",
      "         1.0      0.491     0.530     0.510       434\n",
      "\n",
      "    accuracy                          0.820      2456\n",
      "   macro avg      0.694     0.706     0.700      2456\n",
      "weighted avg      0.826     0.820     0.823      2456\n",
      "\n",
      "Test Average Precision (PR-AUC): 0.5836055259008011\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "# Predictions on test\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "print(\"Test Average Precision (PR-AUC):\", average_precision_score(y_test, y_test_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb5eea",
   "metadata": {},
   "source": [
    "## random forest: base model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4eee5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 17955\n",
      "Total positives: 590.0\n",
      "Train size: 14364 with positives: 472.0\n",
      "Test size: 3591 with positives: 118.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"grosscontractsigned\"])\n",
    "y = df[\"grosscontractsigned\"]\n",
    "\n",
    "# Stratified split to preserve ~5% positives in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Dataset size:\", len(df))\n",
    "print(\"Total positives:\", y.sum())\n",
    "print(\"Train size:\", len(X_train), \"with positives:\", y_train.sum())\n",
    "print(\"Test size:\", len(X_test), \"with positives:\", y_test.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "013b7ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.987     0.994     13892\n",
      "         1.0      0.727     1.000     0.842       472\n",
      "\n",
      "    accuracy                          0.988     14364\n",
      "   macro avg      0.864     0.994     0.918     14364\n",
      "weighted avg      0.991     0.988     0.989     14364\n",
      "\n",
      "Train PR-AUC: 0.9054196533244968\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.972     0.988     0.980      3473\n",
      "         1.0      0.328     0.178     0.231       118\n",
      "\n",
      "    accuracy                          0.961      3591\n",
      "   macro avg      0.650     0.583     0.605      3591\n",
      "weighted avg      0.951     0.961     0.955      3591\n",
      "\n",
      "Test PR-AUC: 0.22059070432873998\n"
     ]
    }
   ],
   "source": [
    "# lets do random forest instead \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,      # number of trees\n",
    "    max_depth=None,        # let it grow fully (can tune later)\n",
    "    min_samples_split=10,  # avoid overfitting tiny splits\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # use all cores\n",
    ")\n",
    "\n",
    "# Fit on training (original, no SMOTE here)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_train_proba = rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Train metrics\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train, y_train_pred, digits=3))\n",
    "print(\"Train PR-AUC:\", average_precision_score(y_train, y_train_proba))\n",
    "\n",
    "# Test metrics\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "print(\"Test PR-AUC:\", average_precision_score(y_test, y_test_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8938210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC scores: [0.21860454 0.19333925 0.2274299  0.15467475 0.17516585]\n",
      "Mean PR-AUC: 0.1938428569965209\n",
      "Std dev: 0.026923798922018075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Stratified KFold ensures class balance in each fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate using PR-AUC (average_precision)\n",
    "cv_scores = cross_val_score(\n",
    "    rf, X, y,\n",
    "    cv=cv,\n",
    "    scoring=\"average_precision\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"PR-AUC scores:\", cv_scores)\n",
    "print(\"Mean PR-AUC:\", np.mean(cv_scores))\n",
    "print(\"Std dev:\", np.std(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ead75",
   "metadata": {},
   "source": [
    "put SMOTE inside cross-validation with a constrained Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1da6e",
   "metadata": {},
   "source": [
    "SMOTENC avoids creating fractional values on categorical/binary fields during oversampling.\n",
    "\n",
    "Oversampling is done inside CV folds, preventing leakage.\n",
    "\n",
    "We regularize the forest to reduce overfitting.\n",
    "\n",
    "We tune the threshold using out-of-fold predictions, which is much closer to real deployment behavior than using the training fit alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "232e4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features for SMOTENC (16): ['aggregated_missing', 'desiredinstallationend_encoded', 'desiredinstallationend_missing', 'electricitybill_missing', 'evaluationtime_missing', 'first_bc_outcome_encoded', 'heatingbill_missing', 'last_bc_outcome_encoded', 'mktg_High', 'mktg_Low', 'mktg_Medium', 'region_High_Performer', 'region_Large_Solid', 'region_Lower', 'region_Medium', 'zipregion_missing']\n",
      "CV PR-AUC (SMOTENC + RF) folds: [0.1102 0.2167 0.1595 0.1668 0.15  ]\n",
      "Mean PR-AUC: 0.16065375263029016 Std: 0.034188954886205214\n",
      "Test PR-AUC (probas, default 0.5 threshold not applied): 0.1651\n",
      "Best threshold by OOF F1: 0.327 | Train OOF Precision: 0.143 | Train OOF Recall: 0.479 | Train OOF F1: 0.220\n",
      "\n",
      "Test classification report @best threshold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.980     0.902     0.939      3473\n",
      "         1.0      0.139     0.466     0.214       118\n",
      "\n",
      "    accuracy                          0.887      3591\n",
      "   macro avg      0.559     0.684     0.576      3591\n",
      "weighted avg      0.953     0.887     0.915      3591\n",
      "\n",
      "Confusion matrix @best threshold\n",
      "[[3131  342]\n",
      " [  63   55]]\n",
      "\n",
      "Top 15 features by importance:\n",
      "net_SC: 0.1735\n",
      "electricitybill: 0.1216\n",
      "region_Lower: 0.0795\n",
      "selfipa_done: 0.0789\n",
      "time_first_sc_to_first_net_fu: 0.0747\n",
      "electricitybill_missing: 0.0732\n",
      "gross_FU: 0.0538\n",
      "net_FU: 0.0504\n",
      "heatingbill_missing: 0.0381\n",
      "desiredinstallationend_encoded: 0.0357\n",
      "lead_to_first_bc_days: 0.0350\n",
      "region_Medium: 0.0316\n",
      "heatingbill: 0.0219\n",
      "region_Large_Solid: 0.0132\n",
      "bc_frequency: 0.0129\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 — SMOTENC + RandomForest inside CV, then threshold tuning\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import (average_precision_score, precision_recall_curve,\n",
    "                             classification_report, confusion_matrix)\n",
    "import numpy as np\n",
    "\n",
    "# --- Identify categorical/binary columns for SMOTENC ---\n",
    "# (booleans, *_missing flags, and encoded categorical columns you listed)\n",
    "cat_cols = []\n",
    "cat_cols += list(X_train.select_dtypes(include=[\"bool\"]).columns)\n",
    "cat_cols += [c for c in X_train.columns if c.endswith(\"_missing\")]\n",
    "cat_cols += [c for c in [\n",
    "    \"desiredinstallationend_encoded\",\n",
    "    \"last_bc_outcome_encoded\",\n",
    "    \"first_bc_outcome_encoded\",\n",
    "] if c in X_train.columns]\n",
    "\n",
    "# unique & keep only those that exist\n",
    "cat_cols = sorted(set([c for c in cat_cols if c in X_train.columns]))\n",
    "cat_idx = [X_train.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "print(f\"Categorical features for SMOTENC ({len(cat_idx)}): {cat_cols}\")\n",
    "\n",
    "# --- Build pipeline (moderate oversampling; avoid double-counting with class_weight) ---\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"smote\", SMOTENC(\n",
    "        categorical_features=cat_idx,\n",
    "        sampling_strategy=0.30,   # target pos/neg ratio after resampling (e.g., 30%)\n",
    "        random_state=42\n",
    "    )),\n",
    "    (\"rf\", RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=15,             # limit depth to reduce overfitting\n",
    "        min_samples_leaf=30,      # more regularization\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "        # class_weight=None because we handle imbalance via SMOTENC\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- Cross-validation on TRAIN ONLY (keep test as untouched holdout) ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    pipe, X_train, y_train,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=cv, n_jobs=-1\n",
    ")\n",
    "print(\"CV PR-AUC (SMOTENC + RF) folds:\", np.round(cv_scores, 4))\n",
    "print(\"Mean PR-AUC:\", cv_scores.mean(), \"Std:\", cv_scores.std())\n",
    "\n",
    "# --- Fit on all training data and evaluate PR-AUC on TEST ---\n",
    "pipe.fit(X_train, y_train)\n",
    "y_test_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "print(\"Test PR-AUC (probas, default 0.5 threshold not applied):\",\n",
    "      round(average_precision_score(y_test, y_test_proba), 4))\n",
    "\n",
    "# --- Choose a better decision threshold using OOF predictions on TRAIN ---\n",
    "oof_proba = cross_val_predict(pipe, X_train, y_train, cv=cv,\n",
    "                              method=\"predict_proba\", n_jobs=-1)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_train, oof_proba)\n",
    "f1 = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "best_idx = np.nanargmax(f1)\n",
    "best_thr = thr[best_idx] if best_idx < len(thr) else 0.5\n",
    "print(f\"Best threshold by OOF F1: {best_thr:.3f} | \"\n",
    "      f\"Train OOF Precision: {prec[best_idx]:.3f} | \"\n",
    "      f\"Train OOF Recall: {rec[best_idx]:.3f} | \"\n",
    "      f\"Train OOF F1: {f1[best_idx]:.3f}\")\n",
    "\n",
    "# --- Apply chosen threshold on TEST and report metrics ---\n",
    "y_test_pred = (y_test_proba >= best_thr).astype(int)\n",
    "print(\"\\nTest classification report @best threshold\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "print(\"Confusion matrix @best threshold\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Optional: quick peek at top features from the fitted RF\n",
    "rf_fitted = pipe.named_steps[\"rf\"]\n",
    "importances = rf_fitted.feature_importances_\n",
    "top_idx = np.argsort(importances)[::-1][:15]\n",
    "print(\"\\nTop 15 features by importance:\")\n",
    "for i in top_idx:\n",
    "    print(f\"{X_train.columns[i]}: {importances[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0455cbe",
   "metadata": {},
   "source": [
    "Cross-validation PR-AUC ≈ 0.16\n",
    "That’s still quite low. It means the model struggles to distinguish positives from negatives reliably.\n",
    "\n",
    "Test PR-AUC ≈ 0.165\n",
    "Consistent with CV → confirms the model generalizes (no leakage now), but the signal is weak.\n",
    "\n",
    "Threshold tuning helped\n",
    "\n",
    "At default 0.5, recall would have been almost zero.\n",
    "\n",
    "At 0.327, recall = 0.47 (big improvement), precision = 0.14 (low, but expected with rare positives).\n",
    "\n",
    "So the model can find ~half of positives, but also returns a lot of false alarms.\n",
    "\n",
    "👉 This is normal for extremely imbalanced data: improving recall means trading precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "820fc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 29.43\n",
      "CV PR-AUC (XGB) folds: [0.1248 0.2149 0.1334 0.2087 0.1807]\n",
      "Mean PR-AUC: 0.17252221046761534 Std: 0.03734918395699598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ElifYilmaz\\OneDrive - Enpal B.V\\Desktop\\New folder\\Project\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:50:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PR-AUC (XGB, probs): 0.1786\n",
      "Best threshold by OOF F1: 0.402 | Train OOF Precision: 0.155 | Train OOF Recall: 0.390 | Train OOF F1: 0.222\n",
      "\n",
      "Test classification report @best threshold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.979     0.906     0.941      3473\n",
      "         1.0      0.136     0.432     0.206       118\n",
      "\n",
      "    accuracy                          0.891      3591\n",
      "   macro avg      0.557     0.669     0.574      3591\n",
      "weighted avg      0.951     0.891     0.917      3591\n",
      "\n",
      "Confusion matrix @best threshold\n",
      "[[3148  325]\n",
      " [  67   51]]\n",
      "\n",
      "Top 15 features by importance (XGB):\n",
      "net_SC: 0.5236\n",
      "selfipa_done: 0.0532\n",
      "region_Lower: 0.0190\n",
      "region_High_Performer: 0.0180\n",
      "last_bc_outcome_encoded: 0.0164\n",
      "heatingbill_missing: 0.0157\n",
      "desiredinstallationend_missing: 0.0156\n",
      "efficiency_score: 0.0140\n",
      "time_first_sc_to_first_net_fu: 0.0136\n",
      "net_FU: 0.0135\n",
      "mktg_Medium: 0.0131\n",
      "outcome_trend: 0.0131\n",
      "gross_FU: 0.0130\n",
      "electricitybill_missing: 0.0130\n",
      "engagement_score: 0.0129\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 — XGBoost with imbalance handling\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import (average_precision_score, precision_recall_curve,\n",
    "                             classification_report, confusion_matrix)\n",
    "import numpy as np\n",
    "\n",
    "# --- imbalance ratio ---\n",
    "n_pos = y_train.sum()\n",
    "n_neg = len(y_train) - n_pos\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "print(f\"scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# --- build model ---\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# --- cross-validation on train ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    xgb, X_train, y_train,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=cv, n_jobs=-1\n",
    ")\n",
    "print(\"CV PR-AUC (XGB) folds:\", np.round(cv_scores, 4))\n",
    "print(\"Mean PR-AUC:\", cv_scores.mean(), \"Std:\", cv_scores.std())\n",
    "\n",
    "# --- fit on all training data ---\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# --- test PR-AUC (probabilities only, no threshold) ---\n",
    "y_test_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "print(\"Test PR-AUC (XGB, probs):\",\n",
    "      round(average_precision_score(y_test, y_test_proba), 4))\n",
    "\n",
    "# --- threshold tuning using OOF predictions ---\n",
    "oof_proba = cross_val_predict(xgb, X_train, y_train, cv=cv,\n",
    "                              method=\"predict_proba\", n_jobs=-1)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_train, oof_proba)\n",
    "f1 = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "best_idx = np.nanargmax(f1)\n",
    "best_thr = thr[best_idx] if best_idx < len(thr) else 0.5\n",
    "print(f\"Best threshold by OOF F1: {best_thr:.3f} | \"\n",
    "      f\"Train OOF Precision: {prec[best_idx]:.3f} | \"\n",
    "      f\"Train OOF Recall: {rec[best_idx]:.3f} | \"\n",
    "      f\"Train OOF F1: {f1[best_idx]:.3f}\")\n",
    "\n",
    "# --- apply chosen threshold on TEST ---\n",
    "y_test_pred = (y_test_proba >= best_thr).astype(int)\n",
    "print(\"\\nTest classification report @best threshold\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "print(\"Confusion matrix @best threshold\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# --- feature importance ---\n",
    "importances = xgb.feature_importances_\n",
    "top_idx = np.argsort(importances)[::-1][:15]\n",
    "print(\"\\nTop 15 features by importance (XGB):\")\n",
    "for i in top_idx:\n",
    "    print(f\"{X_train.columns[i]}: {importances[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314df7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
